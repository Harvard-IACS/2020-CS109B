var tipuesearch = {"pages":[{"title":"Calendars","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Select full calendar or weekly schedule tab from the spreadsheet below.","tags":"pages","url":"pages/calendars.html"},{"title":"FAQ","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } General Do I have access to the video recorded materials if I am not an Extension School student? Yes. All CS109B students have access to all recorded videos (lectures, labs, & advanced sections) as well as streaming video for labs. Extension School students also have access to live-streaming of lectures due to the nature of some members of the student body of that school. If you have any issues accessing the video content, please send an email to our helpline with your name and HUID. Can I access live streaming? Only Harvard Extension School students have access to live-streaming of CS109B lectures, and advanced sections. Can I make-up quizzes? No. Only 50% of quiz grades will count towards your final grade. This policy is to reduce stress and is in place so that missing a quiz on occasion should not affect your final grade. Auditors Can I audit this course? What can I and cannot do? Yes, you are welcome to audit this course and attend lecture, sections and lab. However, auditors should not submit HWs or participate in projects, and should refrain from using any course TF resources that are destined and created for our registered students like Ed or JupyterHub. Extension School I am an Extension School Student, can I take the quizzes? And do they count towards my grade? All CS109B students have access to quizzes. If you are a Harvard Extension School student, the quizzes will not be considered towards your final grade. The official quiz will be closed 30 minutes after lecture. After this a duplicate marked \"[Extension Students Only]\" will be launched. This is to allow students in different time zones to attempt the quiz if they choose. Note: only the original quiz will count towards the grade of non-extension students. I am an Extension School student, can I attend lectures and OH in person? Yes, as a student from a Harvard School you are welcome to attend all learning instances (lecture, OH, advanced sections, and labs) in person. Given the distance nature of the student body of Harvard Extension School, we also provide live streaming and video capture of our learning instances.","tags":"pages","url":"pages/faq.html"},{"title":"Homework Policies & Submission Instructions","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } V. Jan 29, 2020 General Policies Colaboration Except for HW2 and HW6 which will be done by each student individually , you're allowed and encouraged to work with a fellow student on the homework. This does not mean that you are to divide and conquer. In the spirit of learning and getting the most out of this course and out of collaborating with your peer, you should solve each problem on your own, compare with your partner, and decide on a common solution. Importing Libraries As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list. You are allowed to use other libraries such as seaborn. Submitting HW Late Submissions will not be accepted. Extensions are provided only for medical reasons with a doctor's note. If there are issues, send an email to the course email: cs109b2020@gmail.com . Homework assignments will be done in Python in the Jupyter Notebook environment. When you are finished editing your notebook, re-run all the cells to make sure they work . Normally, you need only submit the .ipynb file with one caveat: If your notebook references other files such as images which are necessary for interpreting your work, they must be uploaded as well. You may also choose to \"attach\" the images to the notebook itself. See the section on markdown attachments under \"other additions\" here for details. Please do not submit .zip or .rar files. File Naming Convention Do not include your name in the paper or the filename as we try to keep grading as anonymous as possible. Making a HW Group in Canvas DO NOT join a group if you are submitting the assignment alone. DO NOT make new groups. Look for an empty group among the pre-made groups for each assignment and join it. Follow instructions below. Click \"People\" in the navbar Click the \"Groups\" tab Type in the search box: \"HW#\" (replace # with the homework number, e.g. HW3) Choose an empty group and have both members in your pair click \"Join\". Again, this must be done before you submit and before the homework deadline. If you haven't joined a group before the homework deadline, we will assume you are working alone. Groups do not persist across assignments. You need to make a group for every assignment. Warning: If you are submitting in a pair: both members must join a Canvas group BEFORE they submit and BEFORE the homework deadline, whichever is earlier. If your group is not in place when you submit or if you submit after the assignment deadline, then you are submitting alone. This is a Canvas limitation. Making a HW Group in Canvas Video","tags":"pages","url":"pages/hw.html"},{"title":"CS109b: Advanced Topics in Data Science","text":"Spring 2020 Pavlos Protopapas , Mark Glickman , & Chris Tanner Lab Leaders: Chris Tanner & Eleni Kaxiras Head TF: Chris Gumb Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models, and unsupervised learning. Lectures: Mon and Wed 1:30‐2:45pm in NW B103 Labs: Monday 4:30-5:45pm & 6:00-7:15pm in Pierce Hall 301 (identical material at both times) Advanced Sections: Wed 4:30-5:45pm in Maxwell-Dworkin G115 (starting 3/4) Office Hours: See weekly calendar for times and locations Prerequisites: CS 109a, AC 209a, Stat 121a, or CSCI E-109a or the equivalent. Course Email: cs109b2020@gmail.com Previous Material 2019 2018","tags":"pages","url":"pages/index.html"},{"title":"Modules","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } ol { list-style-type: upper-alpha; } Predicting Fine Particulate Matter Pollution We introduce the data setting and provide a high-level overview of the most important data science methods for estimating the health risks of air pollution and climate change related exposures. Given the strong evidence that the presence of fine particulate matter in the atmosphere increases mortality and hospitalization rates, it is important that we can track and predict these pollution levels. One of the main challenges in this work is that the fine particulate matter detectors are sparsely located across the US, meaning that many areas do not have quality data. In this project, you will build a model to predict fine particulate matter pollution in the untracked regions of the US, given data from the tracked areas. This data includes meteorological readings, land use data, and satellite data. Francesca Dominici is the Clarence James Gamble Professor of Biostatistics, Population and Data Science at Harvard T.H. Chan School of Public Health and Director of the Data Science Initiative at Harvard University. Dr. Dominici is an international leader at the interface of statistics, data science, causal inference and and public health. Dr. Dominici has stellar leadership in education and mentoring, and the promotion of diversity and gender equality. Dr. Dominici's team has provided the scientific community and policy makers with robust evidence on the adverse health effects of air pollution, and climate change. Her studies have directly and routinely impacted air quality policy, leading to more stringent ambient air quality standards in the US. Room Labelling and Object Arrangement Floor plans play an invaluable role in the architectural world - they tell us the shape and size of a built environment , and also convey the architect ' s vision for the style and feel of the final product. Much of this work is currently done with 3D renderings, but in the past, a 2D floor plan was the standard. Many of these floor plans exist as essentially unstructured data, such as images. In this project, you will be working with a data set of approximately 1000 floor plans. While it is easy for a human to look at one of these images and understand the purpose of each room, a computer has a harder time understanding this. Your goal is to build a system to identify the different types of rooms (living room, bed room, etc.) in each floor plan, and extract relevant metadata from their properties. Such metadata could be recognizing furniture symbols with size and location, and/or drawing hard boundaries between rooms. A wonderful stretch-goal could be for the system to automatically populate rooms with furniture appropriate to its use. Jose Luis García del Castillo y López is an architect, computational designer, and educator. He advocates for a future where programming and code are tools as natural to artists as paper and pencil. In his work, he explores creative opportunities at the intersection of design, technology, fabrication, data and art. He is currently a Lecturer in Architectural Technology at the Harvard Graduate School of Design. Data Science for Case Law This project will challenge you to read case law, and generate automatic summarizations of the cases. Headnotes are brief case summary statements often generated by commercial third parties. They are under copyright protection, and so are not always available or are subject to many usage restrictions. In this project, you will reconstruct these headnotes for a variety of cases, using historical court cases as a training set. We will use the Caselaw Access Project, a recently-released dataset of all United States case law from the Harvard Law School Library. Jack Cushman is a Lecturer at the Harvard Law School. Jack teaches Computer Programming for Lawyers at Harvard Law School and is a senior developer at the Harvard Library Innovation Lab. He previously practiced as an appellate lawyer at the firm of Stern, Shapiro, Weissberg and Garin. Kelly Fitzpatrick is a Research Associate at the Harvard Law School Library. Kelly runs outreach and communications for the Caselaw Access Project at the Harvard Library Innovation Lab. She holds a masters in library science and worked previously on the Harvard Open Access Project. Predicting Disease Activity This project involves applying machine learning techniques and novel Internet-based data sources for real-time monitoring and short-term forecasting of population-level disease activity. In this project, you will learn how to design and deploy predictive models to track and forecast epidemic outbreaks in real time. For this, you will gain access to epidemiological data of ongoing and historical disease outbreaks in the US and other countries. Diseases of interest include Influenza (USA), Dengue fever (Puerto Rico and Peru), Ebola (DRC), Coronavirus 2019-nCoV (China and the world). Given that most epidemiological monitoring systems in the world provide lagged information about disease activity (case counts of infected people are known to decision-makers weeks after the fact due to lab testing and data collection delays), you will learn how to design and implement time-series based prediction models to estimate the likely disease activity in current time and future weeks. You will learn how to utilize data sources that were not originally designed to be indicators of disease activity to complement time-series predictive models. These data sources include: disease-related Google search activity, disease-related Twitter microblogs, air travel, and weather patterns. Dr. Mauricio Santillana is a physicist and applied mathematician with expertise in mathematical modeling and scientific computing. He has worked in multiple research areas frequently analyzing big data sets to understand and predict the behavior of complex systems. His research modeling population growth patterns has informed policy makers in Mexico and Texas. His research in numerical analysis and computational fluid dynamics has been used to improve models of coastal floods due to hurricanes, and to improve the performance of global atmospheric chemistry models. Mauricio received a B.S. in physics with highest honors from the Universidad Nacional Autonoma de Mexico in Mexico City, and a master's and PhD in computational and applied mathematics from the University of Texas at Austin. Mauricio first joined Harvard as a postdoctoral fellow at the Harvard Center for the Environment and has been a lecturer in applied mathematics at the Harvard SEAS, receiving two awards for excellence in teaching. Predicting Project Success Data Science has become a core function in many firms today, driving innovation and new data-intensive business and operating models. This project will demonstrate how data and data science offers unprecedented opportunities to organizations in running their business, focusing on project planning capabilities. In this project, you will be exposed to concepts related to business operations and an in depth understanding of the role of data and predictions in these operations. In particular, can project success or failure (defined by budgetary or temporal constraints) be predicted ahead of time, given a variety of project features? Many businesses operate without a reliable predictor of project success, and therefore waste time and money due to mismanagement. This project addresses a real-world business need with data, and will help managers better plan their business operations. Dr. Yael Grushka-Cockayne is Visiting Associate Professor of Business Administration, Harvard Business School. Associate Professor Grushka-Cockayne's research and teaching activities focus on data science, analytics, forecasting, decision analysis, project management, and behavioral decision-making. Yael is an award-winning teacher and in 2014 was named one of \"21 Thought-Leader Professors\" in Data Science. At HBS Yael teaches the required Technology and Operations Management course and an elective course on Business Analytics. She has been teaching in the Harvard Business Analytics Program, powered by 2U, since 2018. Previously, Yael taught courses on Decision Analysis, Project Management, and Data Science in Business. Yael's \"Fundamentals of Project Planning and Management\" Coursera MOOC had over 200,000 enrolled, across 200 countries worldwide. Before starting her academic career, she worked in San Francisco as a marketing director of an ERP company. As an expert in the areas of project management, she has served as a consultant to international firms in the aerospace and pharmaceutical industries. Yael is an Associate Editor at Management Science, Operation Research, and Decision Analysis. Education: B.Sc., Ben-Gurion University; MSc, London School of Economics; Ph.D., MRes, London Business School Measuring the shape and brightness of galaxies with neural networks For decades, astronomers have scanned the sky with increasingly powerful telescopes and cameras, collecting millions of digital images of billions of stars, galaxies, and other objects. These \"sky surveys\" collect so much data that no human could ever look at it all directly, so we rely on automated software to detect objects, isolate them from their neighbors, and determine their properties. Traditionally this has been done by model fitting. For example, to characterize a galaxy, we use a parametric generative model for the galaxy that outputs an image (values in a grid of pixels) as a function of the location, size, shape, orientation, and brightness of the galaxy. A common choice is the Sérsic profile (https://en.wikipedia.org/wiki/Sersic_profile). One can define an objective function (or loss function) given the model and a noise model, and run an optimizer or Markov chain Monte Carlo to estimate the parameters and their uncertainty. Much of modern astronomy is built on this approach, even though the Sérsic model is not a terribly good fit for many galaxies. A more modern approach would be to use neural networks. This would allow us to specify our concept of what galaxies look like by using many training examples (real or simulated) rather than a functional form. The neural network can be trained with those input examples, and desired output parameters, and then applied to new data. For this module we will use the galsim software (https://github.com/GalSim-developers/GalSim) to generate mock data with known parameters and noise. We will then train a neural net on the mock data, and quantify its performance. By showing that modern data-driven approaches can succeed on this problem, we open the door to future work on real galaxies, including edge cases such as merging systems of galaxies, or galaxies that overlap along the line of sight -- situations that traditional methods sometimes handle poorly. Dr. Douglas Finkbeiner has a joint appointment in the Department of Astronomy and Department of Physics, working on topics ranging from dark matter to interstellar dust. He is currently excited about the Dark Energy Spectroscopic Instrument (DESI), a 5000-fiber spectrograph on the 4m telescope at Kitt Peak, AZ.","tags":"pages","url":"pages/modules.html"},{"title":"Resources","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } FAQ GitHub Repo Ed Guides Homework Policies & Submission Instructions JupyterHub (requires Canvas access)","tags":"pages","url":"pages/resources.html"},{"title":"Schedule","text":"Week Lecture (Mon) Lecture (Weds) Lab (Mon) Advanced Section (Weds) Assignment (R:Released Weds - D:Due Thurs) 1 Lecture 1: Introduction + Smoothers and Additive 1/3 Lecture 2: Smoothers and Additive 2/3 Lab 1: Getting Started HW1 - R: 1/29 D: 2/6 2 Lecture 3: Smoothers and GAM 3/3 Lecture 4: Unsupervised learning/clustering 1 Lab 2: Smoothers+GAM HW2 - R: 2/5 D: 2/20 3 Lecture 5: Unsupervised learning/clustering 2 Lecture 6: Bayesian 1/3 Lab 3: Clustering No New Assignment 4 No Lecture (Presidents' Day) Lecture 7: Bayesian 2/3 No Lab (President's Day) HW3 - R: 2/19 D: 3/5 5 Lecture 8: Bayesian 3/3 Lecture 9: ML/NN Roadmap Lab 4: Bayesian No New Assignment 6 Lecture 10: CNN-1 Lecture 11: CNN-2 Lab 5: CNNs-1 A-Sec 1: ResNet, Dense-Net, res-Next and Inception and transfer learning HW4 - R: 3/4 D: 3/12 7 Lecture 12: Autoencoders + Unet Lecture 13: RNN1 Lab 6: CNNs-2 A-Sec 2: Segmentation Techniques, YOLO, Unet and M-RCNN HW5 - R: 3/11 D: 3/26 8 No Lecture (Spring Break) No Lecture No Lab No A-Sec No New Assignment 9 Lecture 14: RNN2 + Text1 Lecture 15: Text2 Lab 7: AE A-Sec 3: RNN, echo state HW6 - R: 3/25 D: 4/9 10 Lecture 16: Text3 Lecture 17: VAE + Generative models Lab 8: RNNS A-Sec 4: Variational Inference No New Assignment 11 Lecture 18: GANS 1 Lecture 19: GANS 2 Lab 9: Text A-Sec 5: GANS. Bicylcle GANS etc HW7 - R: 4/8 D: 4/16 12 Lecture 20: Reinforcement Learning Basics Lecture 21: Deep Reinforcement Learning Lab 10: VAE+GANS A-Sec 6: RL HW8 - R: 4/15 D: 4/23 13 MODULE: LECTURE DOMAIN MODULE: PROBLEM BACKGROUND Lab 11: RL 14 MODULE PROJECT WORK 15 PROJECT WORK PROJECT WORK","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"Advanced Topics in Data Science (Spring 2020) CS 109b, AC 209b, Stat 121b, or CSCI E-109b Instructors Pavlos Protopapas (SEAS), Mark Glickman (Statistics), & Chris Tanner (SEAS) Lab Leaders: Chris Tanner & Eleni Kaxiras Lectures: Mon and Wed 1:30‐2:45pm in NW B103 Labs: Monday 4:30-5:45pm & 6:00-7:15pm in Pierce Hall 301 (identical material at both times) Advanced Sections: Wed 4:30-5:45pm in Maxwell-Dworkin G115 Office Hours: See weekly calendar for times and locations Prerequisites: CS 109a, AC 209a, Stat 121a, or CSCI E-109a or the equivalent. Course description Tentative Course Topics Course Objectives Course Components Lectures Labs In-class Quizzes Advanced Sections Exams Projects Homework Assignments Course Resources Online Materials Recommended Textbooks Getting Help Course Policies and Expectations Grading Collaboration Policy Late or Wrongly Submitted Assignments Re-grade Requests Auditing the Class Academic Integrity Accommodations for students with disabilities Diversity and Inclusion Statement Course Description Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models, and unsupervised learning. The programming language will be Python. Tentative Course Topics Smoothing and Additive Models Unsupervised Learning, Clustering Bayesian Modeling Convolutional Neural Networks Autoencoders Recurrent Neural Networks NLP / Text Analysis Variational AutoEncoders & Generative Models Generative Adversarial Networks (Deep) Reinforcement Learning Course Objectives Upon successful completion of this course, you should feel comfortable with the material mentioned above, and you will have gained experience working with others on real-world problems. The content knowledge, the project, and teamwork will prepare you for the professional world or further studies. Course Components There will be live video feed available only to continuing education students for lectures, labs, and advanced sections. Recordings for all other students will be available within 24 hrs. Video streams and recordings can be accessed from the Videos section on Canvas. Lectures The class meets twice a week for lectures. Attending lectures is a crucial component of learning the material presented in this course. Labs Lectures are supplemented by weekly lab sections that include additional discussion of the course material, hands-on programming exercises, and group activities. In-Class Quizzes At the end of each lecture, we will ask you to take a short, graded quiz on the material presented in class; there will be no AC209b content in the quizzes. 50% of the quizzes will be dropped from your grade. DCE students' quizzes will not count toward their final grade. Advanced Sections The course will include advanced sections for 209b students and will cover a different topic per week. These are 75 min lectures and they will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the advanced sections is required for all AC209b students. Tentative topics are: ResNet, Dense-Net, res-Next and Inception and transfer learning Segmentation Techniques, YOLO, Unet and M-RCNN RNN, Echo State Variational Inference GANS. Cycle GANS, etc. RL Exams There are no exams in this course. Projects Non-DCE Students During the final four (4) weeks of the course, students will be divided in break-out thematic sections where they will study topics. These topics are tentative at the moment but may include medicine, law, astronomy, e-commerce, and government. Each section will include lectures by Harvard faculty, experts on the field, followed by project work also led by that faculty. You will get to present your projects in the SEAS Design Fair at the end of the semester. DCE Students The goal of the project is to have a complete end-to-end data science process encompassing both semesters of subject material while working as a 3-4 person team. We will supply a small set of project choices within the thematic categories. Teams may propose a different project with sufficient notice and will be subject to approval by the course staff. Homework Assignments There will be eight graded homework assignments. Some of them will be due one week after being assigned and some will be due two weeks after being assigned. For six assignments, you have the option to work and submit in pairs, the two remaining are to be completed individually. Course Resources Online Materials All course materials, including lecture notes, lab notes, and section notes will be published on the course GitHub repo as well as the public site's Materials section . Note: Lecture content for weeks 1-3 is only available to registered students through the Materals section. Assignments will only be posted on Canvas. Working Environment You will be working in Jupyter Notebooks which you can run in your own machine or in the SEAS JupyterHub cloud (see lab 1 for details). Recommended Textbooks ISLR: An Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani (Springer: New York, 2013) DL: Deep Learning by Goodfellow, Bengio and Courville. (The MIT Press: Cambridge, 2016) Free electronic versions are available ( ISLR , DL ) or hard copy through Amazon ( ISLR , DL ). Getting Help For questions about homework, course content, package installation, the process is: try to troubleshoot yourself by reading the lecture, lab, and section notes, and looking up online resources. go to office hours this is the best way to get help. post on the class Ed forum; we want you and your peers to engage in helping each other. TFs also monitor Ed and will respond within 24 hours. Note that Ed questions are visible to everyone. If you are citing homework solution code you must post privately so that only the staff sees your message. watch for official announcements via Canvas so make sure you have your Canvas notifications turned on. Ed should always be your first resource for seeking answers to your content questions. send an email to the Helpline cs109b2020@gmail.com for administrative issues, regrade requests, and non-content specific questions. for personal matters that you do not feel comfortable sharing with the TFs, you may send an email to either or both of the instructors. Course Policies and Expectations Grading for CS109b, STAT121b, and CS209b (tentative): Your final score for the course will be computed using the following weights: Non-DCE Students Assignment Final Grade Weight Paired Homework (6) 47% Individual Homework (2) 21% Quizzes 8% Ed Exercises 4% Project 20% Total 100% Note: Regular homework (for everyone) counts as 5 points. 209b extra homework counts as 1 point. DCE Students Assignment Final Grade Weight Paired Homework (6) 51% Individual Homework (2) 23% Ed Exercises 4% Project 22% Total 100% Collaboration Policy We expect you to adhere to the Harvard Honor Code at all times. Failure to adhere to the honor code and our policies may result in serious penalties, up to and including automatic failure in the course and reference to the ad board. If you work with a partner on an assignment make sure both parties solve all the problems. Do not divide and conquer. You are expected to be intellectually honest and give credit where credit is due. In particular: if you work with a fellow student but decide to submit different papers, include the name of each other in the designated area of the submission paper. if you work with a fellow student and want to submit the same paper you need to form a group prior to the submission. Details in the assignment. Not all assignments will permit group submissions. you need to write your solutions entirely on your own or with your collaborator you are welcome to take ideas from code presented in labs, lecture, or sections but you need to change it, adapt it to your style, and ultimately write your own. We do not want to see code copied verbatim from the above sources. if you use code found on the internet, books, or other sources you need to cite those sources. you should not view any written materials or code created by other students for the same assignment; you may not provide or make available solutions to individuals who take or may take this course in the future. if the assignment allows it you may use third-party libraries and example code, so long as the material is available to all students in the class and you give proper attribution. Do not remove any original copyright notices and headers. Late or Wrongly Submitted Assignments There are no late days in homework submission. We will accept late submissions only for medical reasons and if accompanied by a doctor's note. To submit after Canvas has closed or to ask for an extension , send an email to the Helpline with subject line \"Submit HW1: Reason=the flu\" replacing 'HW1' with the name of the current assignment and \"the flu\" with your reason. You need to attach the note from your medical provider otherwise we will not accept the request. If you forgot to join a Group with your peer and are asking for the same grade we will accept this with no penalty up to HW3. For homeworks beyond that we feel that you should be familiar with the process of joining groups. After that there will be a penalty of -1 point for both members of the group provided the submission was on time. Re-grade Requests Our graders and instructors make every effort in grading accurately and in giving you a lot of feedback. If you discover that your answer to a homework problem was correct but it was marked as incorrect, send an email to the Helpline with a description of the error. Please do not submit regrade requests based on what you perceive is overly harsh grading . The points we take off are based on a grading rubric that is being applied uniformly to all assignments. If you decide to send a regrade request , send an email to the Helpline with subject line \"Regrade HW1: Grader=johnsmith\" replacing 'HW1' with the current assignment and 'johnsmith' with the name of the grader within 48 hours of the grade release . Auditing the Class If you would like to audit the class, please send an email to the Helpline indicating who you are and why you want to audit the class. You need a HUID to be included to Canvas. Please note that auditors may not submit assignments for grading or make use of other limited student resources such as office hours. Academic Integrity Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109b we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Collaborations section above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with the professor by the end of the second week of the term, (fill in specific date). Failure to do so may result in the Course Head's inability to respond in a timely manner. All discussions will remain confidential, although Faculty are invited to contact AEO to discuss appropriate implementation. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made w/ Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this: If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion . We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates.","tags":"pages","url":"pages/syllabus.html"},{"title":"Advanced Sections 04:","text":"Slides","tags":"a-sections","url":"a-sections/a-section04/"},{"title":"Advanced Sections 05:","text":"Slides","tags":"a-sections","url":"a-sections/a-section05/"},{"title":"Lab 08:","text":"Slides","tags":"labs","url":"labs/lab08/"},{"title":"Lab 09:","text":"Slides","tags":"labs","url":"labs/lab09/"},{"title":"Lab 10:","text":"Slides","tags":"labs","url":"labs/lab10/"},{"title":"Lab 11:","text":"Slides","tags":"labs","url":"labs/lab11/"},{"title":"Lab 12:","text":"Slides","tags":"labs","url":"labs/lab12/"},{"title":"Lecture 16:","text":"Slides","tags":"lectures","url":"lectures/lecture16/"},{"title":"Lecture 17:","text":"Slides","tags":"lectures","url":"lectures/lecture17/"},{"title":"Lecture 18:","text":"Slides","tags":"lectures","url":"lectures/lecture18/"},{"title":"Lecture 19:","text":"Slides","tags":"lectures","url":"lectures/lecture19/"},{"title":"Lecture 20:","text":"Slides","tags":"lectures","url":"lectures/lecture20/"},{"title":"Lecture 21:","text":"Slides","tags":"lectures","url":"lectures/lecture21/"},{"title":"Lecture 22:","text":"Slides","tags":"lectures","url":"lectures/lecture22/"},{"title":"Lecture 23:","text":"Slides","tags":"lectures","url":"lectures/lecture23/"},{"title":"Lecture 24:","text":"Slides","tags":"lectures","url":"lectures/lecture24/"},{"title":"Lecture 25:","text":"Slides","tags":"lectures","url":"lectures/lecture25/"},{"title":"Lecture 26:","text":"Slides","tags":"lectures","url":"lectures/lecture26/"},{"title":"Lecture 15: Text 2","text":"Slides Lecture 15 Slides [PPTX] Lecture 15 Slides [PDF]","tags":"lectures","url":"lectures/lecture15/"},{"title":"A-Sec 3: RNN, Echo State","text":"Slides A-Sec 3: RNN, Echo State [PDF]","tags":"a-sections","url":"a-sections/a-section03/"},{"title":"Lecture 14: RNNs 2 + Text 1","text":"Slides Lecture 14 Slides [PPTX] Lecture 14 Slides [PDF]","tags":"lectures","url":"lectures/lecture14/"},{"title":"Lab 7: AE","text":"Notebook Lab7","tags":"labs","url":"labs/lab07/"},{"title":"Lab 7: AE","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS-109B Data Science 2: Advanced Topics in Data Science Lab 7: Autoencoders Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras, Vivek Hv, Cedric Flamant, and Pavlos Protopapas In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Welcome to our New Virtual Classroom!! Chris Tanner, myself, and the lab TFs, have very much enjoyed your participation during our previous on-campus lab meetings, and will try to maintain interactivity via this new medium as best as we can. You can also do your part by: - using your real name, if possible, so as to recreate a classroom feeling :) - turning off your video to conserve bandwith - muting your microphone unless you are invited to speak - **raising your hand** in the Chat when we invite questions - writing comments and questions in the Chat If you have any questions after the lab is done, please post them on **Ed**, in the Lab7 section. Learning Goals By the end of this lab, you should be able to: Connect the representation that Principal Component Analysis produces to the that of an autoencoder (AE). Add tf.keras Functional API into your machine learning arsenal. Implement an autoencoder using tf.keras : build the encoder network/model build the decoder network/model decide on the latent/bottleneck dimension train your AE predict on unseen data Note: To see solutions, uncomment and run the following: # %load solutions/exercise2.py First time you run will load solution, then you need to run the cell again to actually run the code. Table of Contents Part 1 : Autoencoders and their connection to Principal Component Analysis . Part 2 : Denoising Images using AEs . Part 3 : Visualizing Intermediate Layers of an AE . In [ ]: from __future__ import annotations import numpy as np import seaborn as sns import os import datetime import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) % matplotlib inline In [ ]: import tensorflow as tf from tensorflow import keras from tensorflow.keras.models import Sequential , Model from tensorflow.keras.layers import Dense , Conv2D , Conv1D , MaxPooling2D , MaxPooling1D , \\ Dropout , Flatten , Activation , Input , UpSampling2D from tensorflow.keras.optimizers import Adam , SGD , RMSprop from tensorflow.keras.utils import to_categorical from tensorflow.keras.metrics import AUC , Precision , Recall , FalsePositives , \\ FalseNegatives , TruePositives , TrueNegatives from tensorflow.keras.preprocessing import image from tensorflow.keras.regularizers import l2 In [ ]: tf . keras . backend . clear_session () # For easy reset of notebook state. print ( tf . __version__ ) # You should see a > 2.0.0 here! from tf_keras_vis.utils import print_gpus print_gpus () In [ ]: # set the seed for reproducability of results seed = 109 np . random . seed ( seed ) tf . random . set_seed ( seed ) In [ ]: # install this if you want to play around with Tensorboard #!pip install tf-keras-vis tensorflow % load_ext tensorboard In [ ]: # remove old logs ! rm -rf ./logs/ Part 1: Autoencoders and the connection to Principal Component Analysis Principal Component Analysis (PCA) PCA decomposes a multivariate dataset in a set of eigenvectors - successive orthogonal coeefficients that explain a large amount of the variance. By using only a number of the highest valued vectors, let's say $N$ of them, we effectively reduce the dimensionality of our data to $N$ with minimal loss of information as measured by RMS (Root Mean Squared) Error. PCA in sklearn is a transformer that learns those $N$ components via its .fit method. It can then be used to project a new data object in these components. Remember from 109a that we always .fit only to the training set and .transform both training and test set. from sklearn.decomposition import PCA k = 2 # number of components that we want to keep X_train, X_test = load_data() pca = PCA(n_components=k) principal_components = pca.fit_transform(X_train) principal_components = pca.transform(X_test) Autoencoders (AE) image source: Deep Learning by Francois Collet An AE maps its input, usually an image, to a latent vector space via an encoder function, and then decodes it back to an output that is the same as the input, via a decoder function. It's effectively being trained to reconstruct the original input. By trying to minimize the reconstruction MSE error, on the output of the encoder, you can get the autoencoder to learn interesting latent representations of the data. Historically, autoencoders have been used for tasks such as dimentionality reduction, feature learning, and outlier detection. One type of architecture for an AE is to have the decoder network be a 'mirror image' of the encoder. It makes more sense this way but it is not necessary. We can say that AEs are self-supervised learning networks! Understandind the connection between PCA and AEs If the hidden and output layers of an autoencoder are linear, the autoencoder will learn hidden units that are linear representations of the data, just like PCA does. If we have $M$ hidden units in our AE, those will span the same space as the $M$ first principal components. The hidden layers of the AE will not produce orthogonal representations of the data as PCA would but if we add non-linear components in our encoder-decoder networks we can represent a non-linear space/manifold; Fashion-MNIST We will use the dataset of clothing article images (created by Zalando ), consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28 x 28 grayscale image, associated with a label from 10 classes . The names of the classes corresponding to numbers 0-9 are: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', and 'Ankle boot' The creators intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. Each pixel is 8 bits so its value ranges from 0 to 255. Let's load and look at it! In [ ]: # get the data from keras - how convenient! fashion_mnist = tf . keras . datasets . fashion_mnist # load the data splitted in train and test! how nice! ( X_train , y_train ),( X_test , y_test ) = fashion_mnist . load_data () # normalize the data by dividing with pixel intensity # (each pixel is 8 bits so its value ranges from 0 to 255) X_train , X_test = X_train / 255.0 , X_test / 255.0 print ( f 'X_train shape: {X_train.shape} , X_test shape: {X_test.shape} ' ) print ( f 'y_train shape: {y_train.shape} , and y_test shape: {y_test.shape} ' ) # classes are named 0-9 so define names for plotting clarity class_names = [ 'T-shirt/top' , 'Trouser' , 'Pullover' , 'Dress' , 'Coat' , 'Sandal' , 'Shirt' , 'Sneaker' , 'Bag' , 'Ankle boot' ] plt . figure ( figsize = ( 10 , 10 )) for i in range ( 25 ): plt . subplot ( 5 , 5 , i + 1 ) plt . xticks ([]) plt . yticks ([]) plt . grid ( False ) plt . imshow ( X_train [ i ], cmap = plt . cm . binary ) plt . xlabel ( class_names [ y_train [ i ]]) plt . show () In [ ]: # choose one image to look at i = 5 plt . imshow ( X_train [ i ], cmap = 'gray' ); plt . xlabel ( class_names [ y_train [ i ]]); Exercise 1: Calculate the dimensionality of the Fashion dataset. Then flatten it to prepare for PCA. In [ ]: ## your code here In [ ]: # %load solutions/exercise1.py In [ ]: from sklearn.decomposition import PCA Exercise 2: Find the 2 first principal components by fitting on the train set. Print the shape of the components matrix. In [ ]: # your code here In [ ]: # %load solutions/exercise2.py In [ ]: # print the variance explained by those components pca . explained_variance_ Note: The first two components explain ~19+12 = 31% of the variance. Discussion: Comment on what you see here. In [ ]: # transform the train and test set X_train_pca = pca . transform ( X_train_flat ) X_test_pca = pca . transform ( X_test_flat ) In [ ]: X_train_pca . shape , X_train_pca [ 1 : 5 , 0 ] . shape In [ ]: class_names = [ 'T-shirt/top' , 'Trouser' , 'Pullover' , 'Dress' , 'Coat' , 'Sandal' , 'Shirt' , 'Sneaker' , 'Bag' , 'Ankle boot' ] fig , ax1 = plt . subplots ( 1 , 1 , figsize = ( 9 , 9 )) sns . scatterplot ( x = X_train_pca [:, 0 ], y = X_train_pca [:, 1 ], hue = y_train , palette = sns . color_palette ( \"deep\" , 10 ), ax = ax1 ) ax1 . set_title ( \"FASHION MNIST, First 2 principal components\" ); Part 2: Denoise Images using AEs We will create an autoencoder which will accept \"noisy\" images as input and try to produce the original images. Since we do not have noisy images to start with, we will add random noise to our Fashion-MNIST images. To do this we will use the image augmentation library imgaug docs . From this library we will use SaltAndPepper , an augmenter which replaces pixels in images with salt/pepper noise (white/black-ish colors), randomly with probability passed as parameter p . Use the code below to install the library in your virtual environment. In [ ]: # !conda install imgaug # ### OR # !pip install imgaug In [ ]: from imgaug import augmenters In [ ]: # NNs want the inputs to be 4D X_train = X_train . reshape ( - 1 , h , w , 1 ) X_test = X_test . reshape ( - 1 , h , w , 1 ) # Lets add sample noise - Salt and Pepper noise = augmenters . SaltAndPepper ( p = 0.1 , seed = seed ) seq_object = augmenters . Sequential ([ noise ]) # Augment the data (add the noise) X_train_n = seq_object . augment_images ( X_train * 255 ) / 255 X_test_n = seq_object . augment_images ( X_test * 255 ) / 255 In [ ]: f , ax = plt . subplots ( 1 , 5 , figsize = ( 20 , 10 )) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( X_train_n [ i , :, :, 0 ] . reshape ( 28 , 28 ), cmap = plt . cm . binary ) ax [ i - 5 ] . set_xlabel ( 'Noisy ' + class_names [ y_train [ i ]]) f , ax = plt . subplots ( 1 , 5 , figsize = ( 20 , 10 )) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( X_train [ i , :, :, 0 ] . reshape ( 28 , 28 ), cmap = plt . cm . binary ) ax [ i - 5 ] . set_xlabel ( 'Clean ' + class_names [ y_train [ i ]]) tf.keras.Sequential API This is what we have been using so far for building our models. Its pros are: it's simple to use, it allows you to create models layer-by-layer. Its basic con is: it is not very flexible, and although it includes layers such as Merge, Concatenate, and Add that allow for a combination of models, it is difficult to make models with many inputs or shared-layers. All layers, as the name implies, are connected sequentially. Intro to tf.keras.Functional API https://www.tensorflow.org/guide/keras/functional . In this API, layers are built as graphs, with each layer indicating to which layer it is connected. Functional API helps us make more complex models which include non-sequential connections and multiple inputs or outputs. Let's say we have an image input with a shape of (28, 28, 1) and a classification task: num_classes = 10 inputs = keras.Input(shape=(h, w, 1)) x = Dense(64, activation='relu')(inputs) x = layers.Dense(64, activation='relu')(x) outputs = Dense(num_classes, activation='softmax', name='output')(x) ae_model = Model(inputs=inputs, outputs=outputs, name='autoencoder') ae_model.summary() Create the Encoder In [ ]: # input layer input_layer = Input ( shape = ( h , w , 1 )) Exercise 3: Create your \"encoder\" as a 2D CNN a follows: Use the Functional API Create a pair of layers consisting of a Conv2D and a MaxPool layer which takes in our input_layer . Choose the number of filters. Stack 3 of these layers, one after the other. Give this model the name latent_model (it's not your final model). In [ ]: # your code here In [ ]: # %load solutions/exercise3.py Exercise 4: Create your \"decoder\" as a 2D CNN as follows: repeat the structure of your encoder but in \"reverse\". What is the output layer activation function? What are the dimensions of the output? In [ ]: # your code here In [ ]: # %load solutions/exercise4.py Exercise 5: Connect the two parts (encoder, decoder) to create your autoencoder. Compile and then train your autoencoder. Choose an optimizer and a loss function. Use Early Stopping. To get good results you will need to run this about 20 epochs and this will take a long time depending on your machine. For the purposes of this lab run only for 2 epochs . (Optional: add Tensorboard). Here is how to connect the two models: In [ ]: # create the model ae_model = Model ( input_layer , output_layer , name = 'ae_model' ) ae_model . summary () In [ ]: # your code here In [ ]: # %load solutions/exercise5-1.py In [ ]: # %load solutions/exercise5-2.py In [ ]: # Let's see how our AE did fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( history . history [ 'loss' ], label = 'Train' ) ax . plot ( history . history [ 'val_loss' ], label = 'Val' ) ax . set_xlabel ( \"Epoch\" , fontsize = 20 ) ax . set_ylabel ( \"Loss\" , fontsize = 20 ) ax . legend () ax . set_title ( 'Autoencoder Loss' ) In [ ]: # start Tensorboard - requires grpcio>=1.24.3 #%tensorboard --logdir logs In [ ]: # save your model ae_model . save_weights ( 'ae_model.h5' ) Part 3: Visualizing Intermediate Layers of AE Exercise 6: Let's now visualize the latent layer of our encoder network. This is our \"encoder\" model which we have saved as: encoder = Model(input_layer, latent_view, name='encoder_model') In [ ]: # your code here In [ ]: # %load solutions/exercise6.py Discussion : What do you see in the little images above? Could we have included Dense layers as bottleneck instead of just Conv2D and MaxPoool/upsample? possible answers We can have bottleneck layers in convolutional autoencoders that are not dense but simply a few stacked featuremaps such as above. They might have better generalizability due to only using shared weights. One interesting consequence is that without the dense layer you'll force translational equivariance on the latent representation (a particular feature in the top right corner will appear as an activation in the top right corner of the featuremaps at the level of the bottleneck, and if the feature is moved in the original image the activation in the bottleneck will move proportionally in the same direction). This isn't necessarily a problem, but you are enforcing some constraints on the relationships between the latent space directions that you wouldn't be with the presence of a dense layer. Visualize Samples reconstructed by our AE In [ ]: n = np . random . randint ( 0 , len ( X_test ) - 5 ) In [ ]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( X_test [ a , :, :, 0 ] . reshape ( 28 , 28 ), cmap = 'gray' ) In [ ]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( X_test_n [ a , :, :, 0 ] . reshape ( 28 , 28 ), cmap = 'gray' ) In [ ]: preds = ae_model . predict ( X_test_n [ n : n + 5 ]) f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( preds [ i ] . reshape ( 28 , 28 ), cmap = 'gray' ) plt . show () Discussion: Comment on the predictions. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab07/notebook/"},{"title":"Lecture 13: RNNs 1","text":"Slides Lecture 13 Slides [PPTX] Lecture 13 Slides [PDF]","tags":"lectures","url":"lectures/lecture13/"},{"title":"A-Sec 2: Segmentation Techniques, YOLO, Unet and M-RCNN","text":"Slides A-Sec 2: Semantic Segmentation [PDF]","tags":"a-sections","url":"a-sections/a-section02/"},{"title":"Lab 6: CNNs-2","text":"Notebook Lab6","tags":"labs","url":"labs/lab06/"},{"title":"Lab 6: CNNs-2","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS-109B Introduction to Data Science Lab 6: Convolutional Neural Networks 2 Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras, Cedric Flamant, Pavlos Protopapas In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will continue with Convolutional Neural Networks (CNNs), will look into the tf.data interface which enables us to build complex input pipelines for our data. We will also touch upon visualization techniques to peak into our CNN's hidden layers. By the end of this lab, you should be able to: know how a CNN works from start to finish use tf.data.Dataset to import and, if needed, transform, your data for feeding into the network. Transformations might include normalization, scaling, tilting, resizing, or applying other data augmentation techniques. understand how saliency maps are implemented with code. Table of Contents Part 1 : Beginning-to-end Convolutional Neural Networks . Part 2 : Image Pipelines with tf.data.Dataset . Part 3 : Hidden Layer Visualization, Saliency Maps . In [2]: import numpy as np from scipy.optimize import minimize from sklearn.utils import shuffle import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) % matplotlib inline In [3]: import tensorflow as tf from tensorflow import keras from tensorflow.keras.models import Sequential , Model from tensorflow.keras.layers import Dense , Conv2D , Conv1D , MaxPooling2D , MaxPooling1D , \\ Dropout , Flatten , Activation , Input from tensorflow.keras.optimizers import Adam , SGD , RMSprop from tensorflow.keras.utils import to_categorical from tensorflow.keras.metrics import AUC , Precision , Recall , FalsePositives , \\ FalseNegatives , TruePositives , TrueNegatives from tensorflow.keras.preprocessing import image from tensorflow.keras.regularizers import l2 In [4]: from __future__ import absolute_import , division , print_function , unicode_literals tf . keras . backend . clear_session () # For easy reset of notebook state. print ( tf . __version__ ) # You should see a > 2.0.0 here! from tf_keras_vis.utils import print_gpus print_gpus () 2.1.0 0 GPUs In [5]: ## Additional Packages required if you don't already have them # While in your conda environment, # imageio # Install using \"conda install imageio\" # pillow # Install using \"conda install pillow\" # tensorflow-datasets # Install using \"conda install tensorflow-datasets\" # tf-keras-vis # Install using \"pip install tf-keras-vis\" # tensorflow-addons # Install using \"pip install tensorflow-addons\" In [6]: from tf_keras_vis.saliency import Saliency from tf_keras_vis.utils import normalize import tf_keras_vis.utils as utils from matplotlib import cm from tf_keras_vis.gradcam import Gradcam In [7]: np . random . seed ( 109 ) tf . random . set_seed ( 109 ) Part 0: Running on SEAS JupyterHub PLEASE READ : Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE: The AWS platform is funded by SEAS and FAS for the purposes of the class. It is FREE for you - not running against your personal AWS credit. For this reason you are only allowed to use it for purposes related to this course, and with prudence. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Your instance will terminate after 30 min of inactivity. source: CS231n Stanford, Google Cloud Tutorial Part 1: Beginning-to-end Convolutional Neural Networks image source We will go through the various steps of training a CNN, including: difference between cross-validation and validation specifying a loss, metrics, and an optimizer, performing validation, using callbacks, specifically EarlyStopping , which stops the training when training is no longer improving the validation metrics, learning rate significance Table Exercise : Use the whiteboard next to your table to draw a CNN from start to finish as per the instructions. We will then draw it together in class. Back to Table of Contents Part 2: Image Preprocessing: Using tf.data.Dataset In [9]: import tensorflow_addons as tfa import tensorflow_datasets as tfds tf.data API in tensorflow enables you to build complex input pipelines from simple, reusable pieces. For example, the pipeline for an image model might aggregate data from files in a distributed file system, apply random perturbations to each image, and merge randomly selected images into a batch for training. The pipeline for a text model might involve extracting symbols from raw text data, converting them to embedding identifiers with a lookup table, and batching together sequences of different lengths. The tf.data API makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations. The tf.data API introduces a tf.data.Dataset that represents a sequence of elements , consistινγ of one or more components . For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label. To create an input pipeline, you must start with a data source . For example, to construct a Dataset from data in memory, you can use tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices() . Alternatively, if your input data is stored in a file in the recommended TFRecord format, you can use tf.data.TFRecordDataset() . The Dataset object is a Python iterable. You may view its elements using a for loop: In [10]: dataset = tf . data . Dataset . from_tensor_slices ( tf . random . uniform ([ 4 , 10 ], minval = 1 , maxval = 10 , dtype = tf . int32 )) for elem in dataset : print ( elem . numpy ()) [4 3 1 9 7 4 8 9 4 6] [9 6 2 2 6 4 7 2 9 8] [5 7 5 4 8 5 6 4 8 4] [6 2 2 2 6 6 4 2 2 2] Once you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the tf.data.Dataset object. For example, you can apply per-element transformations such as Dataset.map() , and multi-element transformations such as Dataset.batch() . See the documentation for tf.data.Dataset for a complete list of transformations. The map function takes a function and returns a new and augmented dataset. In [11]: dataset = dataset . map ( lambda x : x * 2 ) for elem in dataset : print ( elem . numpy ()) [ 8 6 2 18 14 8 16 18 8 12] [18 12 4 4 12 8 14 4 18 16] [10 14 10 8 16 10 12 8 16 8] [12 4 4 4 12 12 8 4 4 4] Datasets are powerful objects because they are effectively dictionaries that can store tensors and other data such as the response variable. We can also construct them by passing small sized numpy arrays, such as in the following example. Tensorflow has a plethora of them: In [12]: # uncomment to see available datasets #tfds.list_builders() mnist dataset In [13]: # load mnist ( x_train , y_train ), ( x_test , y_test ) = keras . datasets . mnist . load_data () x_train . shape , y_train . shape Out[13]: ((60000, 28, 28), (60000,)) In [14]: # take only 10 images for simplicity train_dataset = tf . data . Dataset . from_tensor_slices (( x_train , y_train )) test_dataset = tf . data . Dataset . from_tensor_slices (( x_test , y_test )) In [15]: # In case you want to retrieve the images/numpy arrays for element in iter ( train_dataset . take ( 1 )): image = element [ 0 ] . numpy () print ( image . shape ) print ( image . shape ) plt . figure () plt . imshow ( image , cmap = 'gray' ) plt . show () (28, 28) (28, 28) Once you have your Model, you may pass a Dataset instance directly to the methods fit() , evaluate() , and predict() . The difference with the way we have been previously using these methods is that we are not passing the images and labels separately. They are now both in the Dataset object. model.fit(train_dataset, epochs=3) model.evaluate(test_dataset) Data Augmentation In [16]: fig , axes = plt . subplots ( 1 , 6 , figsize = ( 10 , 3 )) for i , ( image , label ) in enumerate ( train_dataset . take ( 4 )): axes [ i ] . imshow ( image ) axes [ i ] . set_title ( f ' {label:.2f} ' ) image_flip_up = tf . image . flip_up_down ( np . expand_dims ( image , axis = 2 )) . numpy () image_rot_90 = tf . image . rot90 ( np . expand_dims ( image , axis = 2 ), k = 1 ) . numpy () axes [ 4 ] . imshow ( image_flip_up . reshape ( 28 , - 1 )) axes [ 4 ] . set_title ( f ' {label:.2f} -flip' ) axes [ 5 ] . imshow ( image_rot_90 . reshape ( 28 , - 1 )) axes [ 5 ] . set_title ( f ' {label:.2f} -rot90' ) plt . show (); Note: The tf.data API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable. You also have the option to use the keras ImageDataGenerator , that accepts numpy arrays, instead of the Dataset. We think it's good for you to learn to use Datasets. As a general rule, for input to NNs, Tensorflow recommends that you use numpy arrays if your data is small and fit in memory, and tf.data.Datasets otherwise. References: tf.data.Dataset Documentation . Import numpy arrays in Tensorflow The Street View House Numbers (SVHN) Dataset We will play with the SVHN real-world image dataset. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images. All digits have been resized to a fixed resolution of 32-by-32 pixels. The original character bounding boxes are extended in the appropriate dimension to become square windows, so that resizing them to 32-by-32 pixels does not introduce aspect ratio distortions. Nevertheless this preprocessing introduces some distracting digits to the sides of the digit of interest. Loading the .mat files creates 2 variables: X which is a 4-D matrix containing the images, and y which is a vector of class labels. To access the images, $X(:,:,:,i)$ gives the i-th 32-by-32 RGB image, with class label $y(i)$. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. In [17]: # Will take some time but will only load once train_svhn_cropped , test_svhn_cropped = tfds . load ( 'svhn_cropped' , split = [ 'train' , 'test' ], shuffle_files = False ) In [18]: isinstance ( train_svhn_cropped , tf . data . Dataset ) Out[18]: True In [19]: # # convert to numpy if needed features = next ( iter ( train_svhn_cropped )) images = features [ 'image' ] . numpy () labels = features [ 'label' ] . numpy () images . shape , labels . shape Out[19]: ((32, 32, 3), ()) In [20]: for i , element in enumerate ( train_svhn_cropped ): if i == 1 : break ; image = element [ 'image' ] label = element [ 'label' ] print ( label ) tf.Tensor(5, shape=(), dtype=int64) In [21]: # batch_size indicates that the dataset should be divided in batches # each consisting of 4 elements (a.k.a images and their labels) # take_size chooses a number of these batches, e.g. 3 of them for display batch_size = 4 take_size = 3 # Plot fig , axes = plt . subplots ( take_size , batch_size , figsize = ( 10 , 10 )) for i , element in enumerate ( train_svhn_cropped . batch ( batch_size ) . take ( take_size )): for j in range ( 4 ): image = element [ 'image' ][ j ] label = element [ 'label' ][ j ] axes [ i ][ j ] . imshow ( image ) axes [ i ][ j ] . set_title ( f 'true label= {label:d} ' ) Here we convert from a collection of dictionaries to a collection of tuples. We will still have a tf.data.Dataset In [22]: def normalize_image ( img ): return tf . cast ( img , tf . float32 ) / 255. def normalize_dataset ( element ): img = element [ 'image' ] lbl = element [ 'label' ] return normalize_image ( img ), lbl In [23]: train_svhn = train_svhn_cropped . map ( normalize_dataset ) test_svhn = test_svhn_cropped . map ( normalize_dataset ) In [24]: isinstance ( train_svhn , tf . data . Dataset ) Out[24]: True Define our CNN model In [55]: n_filters = 16 input_shape = ( 32 , 32 , 3 ) svhn_model = Sequential () svhn_model . add ( Conv2D ( n_filters , ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) svhn_model . add ( MaxPooling2D (( 2 , 2 ))) svhn_model . add ( Conv2D ( n_filters * 2 , ( 3 , 3 ), activation = 'relu' )) svhn_model . add ( MaxPooling2D (( 2 , 2 ))) svhn_model . add ( Conv2D ( n_filters * 4 , ( 3 , 3 ), activation = 'relu' )) svhn_model . add ( Flatten ()) svhn_model . add ( Dense ( n_filters * 2 , activation = 'relu' )) svhn_model . add ( Dense ( 10 , activation = 'softmax' )) svhn_model . summary () Model: \"sequential_5\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_15 (Conv2D) (None, 30, 30, 16) 448 _________________________________________________________________ max_pooling2d_10 (MaxPooling (None, 15, 15, 16) 0 _________________________________________________________________ conv2d_16 (Conv2D) (None, 13, 13, 32) 4640 _________________________________________________________________ max_pooling2d_11 (MaxPooling (None, 6, 6, 32) 0 _________________________________________________________________ conv2d_17 (Conv2D) (None, 4, 4, 64) 18496 _________________________________________________________________ flatten_5 (Flatten) (None, 1024) 0 _________________________________________________________________ dense_10 (Dense) (None, 32) 32800 _________________________________________________________________ dense_11 (Dense) (None, 10) 330 ================================================================= Total params: 56,714 Trainable params: 56,714 Non-trainable params: 0 _________________________________________________________________ In [41]: loss = keras . losses . sparse_categorical_crossentropy # we use this because we did not 1-hot encode the labels optimizer = Adam ( lr = 0.001 ) metrics = [ 'accuracy' ] # Compile model svhn_model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) With Early Stopping In [42]: %%time batch_size = 64 epochs = 15 callbacks = [ keras . callbacks . EarlyStopping ( # Stop training when `val_accuracy` is no longer improving monitor = 'val_accuracy' , # \"no longer improving\" being further defined as \"for at least 2 epochs\" patience = 2 , verbose = 1 ) ] history = svhn_model . fit ( train_svhn . batch ( batch_size ), #.take(50), # change 50 only epochs = epochs , callbacks = callbacks , validation_data = test_svhn . batch ( batch_size )) #.take(50)) Epoch 1/15 1145/1145 [==============================] - 30s 26ms/step - loss: 1.0362 - accuracy: 0.6684 - val_loss: 0.6124 - val_accuracy: 0.8285 Epoch 2/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.5177 - accuracy: 0.8515 - val_loss: 0.5254 - val_accuracy: 0.8519 Epoch 3/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.4393 - accuracy: 0.8739 - val_loss: 0.4789 - val_accuracy: 0.8639 Epoch 4/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.3956 - accuracy: 0.8865 - val_loss: 0.4440 - val_accuracy: 0.8750 Epoch 5/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.3654 - accuracy: 0.8951 - val_loss: 0.4233 - val_accuracy: 0.8816 Epoch 6/15 1145/1145 [==============================] - 29s 25ms/step - loss: 0.3412 - accuracy: 0.9014 - val_loss: 0.4168 - val_accuracy: 0.8846 Epoch 7/15 1145/1145 [==============================] - 29s 25ms/step - loss: 0.3215 - accuracy: 0.9072 - val_loss: 0.4084 - val_accuracy: 0.8871 Epoch 8/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.3055 - accuracy: 0.9124 - val_loss: 0.4026 - val_accuracy: 0.8888 Epoch 9/15 1145/1145 [==============================] - 31s 27ms/step - loss: 0.2916 - accuracy: 0.9163 - val_loss: 0.4100 - val_accuracy: 0.8887 Epoch 10/15 1145/1145 [==============================] - 30s 26ms/step - loss: 0.2780 - accuracy: 0.9200 - val_loss: 0.4217 - val_accuracy: 0.8861 Epoch 00010: early stopping CPU times: user 20min 1s, sys: 8min 31s, total: 28min 33s Wall time: 4min 58s In [45]: def print_history ( history ): fig , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 4 )) ax . plot (( history . history [ 'accuracy' ]), 'b' , label = 'train' ) ax . plot (( history . history [ 'val_accuracy' ]), 'g' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) fig , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 4 )) ax . plot (( history . history [ 'loss' ]), 'b' , label = 'train' ) ax . plot (( history . history [ 'val_loss' ]), 'g' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) plt . show (); print_history ( history ) In [46]: svhn_model . save ( 'svhn_good.h5' ) Too High Learning Rate In [47]: loss = keras . losses . sparse_categorical_crossentropy optimizer = Adam ( lr = 0.5 ) # really big learning rate metrics = [ 'accuracy' ] # Compile model svhn_model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) In [48]: %%time batch_size = 64 epochs = 10 history = svhn_model . fit ( train_svhn . batch ( batch_size ), #.take(50), # change 50 to see the difference epochs = epochs , validation_data = test_svhn . batch ( batch_size )) #.take(50)) Epoch 1/10 1145/1145 [==============================] - 29s 25ms/step - loss: 1518.9293 - accuracy: 0.1763 - val_loss: 2.2455 - val_accuracy: 0.1594 Epoch 2/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2719 - accuracy: 0.1741 - val_loss: 2.2437 - val_accuracy: 0.1594 Epoch 3/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2734 - accuracy: 0.1745 - val_loss: 2.2431 - val_accuracy: 0.1959 Epoch 4/10 1145/1145 [==============================] - 29s 26ms/step - loss: 2.2737 - accuracy: 0.1743 - val_loss: 2.2429 - val_accuracy: 0.1959 Epoch 5/10 1145/1145 [==============================] - 29s 26ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 Epoch 6/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 Epoch 7/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 Epoch 8/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 Epoch 9/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 Epoch 10/10 1145/1145 [==============================] - 29s 25ms/step - loss: 2.2738 - accuracy: 0.1743 - val_loss: 2.2428 - val_accuracy: 0.1959 CPU times: user 19min 22s, sys: 8min 17s, total: 27min 40s Wall time: 4min 50s In [49]: print_history ( history ) fig . savefig ( '../images/train_high_lr.png' ) Too Low Learning Rate Experiment with the learning rate using a small sample of the training set by using .take(num) which takes only num number of samples. history = svhn_model.fit(train_svhn.batch(batch_size).take(50)) In [51]: #loss = keras.losses.categorical_crossentropy loss = keras . losses . sparse_categorical_crossentropy # we use this because we did not 1-hot encode the labels optimizer = Adam ( lr = 1e-5 ) # very low learning rate metrics = [ 'accuracy' ] # Compile model svhn_model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) In [52]: %%time batch_size = 32 epochs = 10 history = svhn_model . fit ( train_svhn . batch ( batch_size ) . take ( 50 ), epochs = epochs , validation_data = test_svhn . batch ( batch_size )) #.take(50)) Epoch 1/10 2290/2290 [==============================] - 37s 16ms/step - loss: 2.2603 - accuracy: 0.1707 - val_loss: 2.2314 - val_accuracy: 0.1957 Epoch 2/10 2290/2290 [==============================] - 34s 15ms/step - loss: 2.2295 - accuracy: 0.1894 - val_loss: 2.2119 - val_accuracy: 0.1970 Epoch 3/10 2290/2290 [==============================] - 35s 15ms/step - loss: 2.2046 - accuracy: 0.2012 - val_loss: 2.1738 - val_accuracy: 0.2342 Epoch 4/10 2290/2290 [==============================] - 35s 15ms/step - loss: 2.1504 - accuracy: 0.2458 - val_loss: 2.0987 - val_accuracy: 0.2948 Epoch 5/10 2290/2290 [==============================] - 36s 16ms/step - loss: 2.0492 - accuracy: 0.3008 - val_loss: 1.9756 - val_accuracy: 0.3434 Epoch 6/10 2290/2290 [==============================] - 37s 16ms/step - loss: 1.9201 - accuracy: 0.3507 - val_loss: 1.8509 - val_accuracy: 0.3832 Epoch 7/10 2290/2290 [==============================] - 38s 16ms/step - loss: 1.7967 - accuracy: 0.3975 - val_loss: 1.7373 - val_accuracy: 0.4274 Epoch 8/10 2290/2290 [==============================] - 35s 15ms/step - loss: 1.6818 - accuracy: 0.4490 - val_loss: 1.6338 - val_accuracy: 0.4714 Epoch 9/10 2290/2290 [==============================] - 34s 15ms/step - loss: 1.5778 - accuracy: 0.4939 - val_loss: 1.5412 - val_accuracy: 0.5111 Epoch 10/10 2290/2290 [==============================] - 35s 15ms/step - loss: 1.4837 - accuracy: 0.5307 - val_loss: 1.4577 - val_accuracy: 0.5436 CPU times: user 20min 26s, sys: 9min 2s, total: 29min 28s Wall time: 5min 56s In [53]: print_history ( history ) fig . savefig ( '../images/train_50.png' ) Changing the batch size In [56]: #loss = keras.losses.categorical_crossentropy loss = keras . losses . sparse_categorical_crossentropy # we use this because we did not 1-hot encode the labels optimizer = Adam ( lr = 0.001 ) metrics = [ 'accuracy' ] # Compile model svhn_model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) In [57]: %%time batch_size = 2 epochs = 5 history = svhn_model . fit ( train_svhn . batch ( batch_size ), epochs = epochs , validation_data = test_svhn . batch ( batch_size )) Epoch 1/5 36629/36629 [==============================] - 175s 5ms/step - loss: 0.8544 - accuracy: 0.7295 - val_loss: 0.5765 - val_accuracy: 0.8363 Epoch 2/5 36629/36629 [==============================] - 135s 4ms/step - loss: 0.5045 - accuracy: 0.8494 - val_loss: 0.5326 - val_accuracy: 0.8511 Epoch 3/5 36629/36629 [==============================] - 134s 4ms/step - loss: 0.4520 - accuracy: 0.8649 - val_loss: 0.5270 - val_accuracy: 0.8584 Epoch 4/5 36629/36629 [==============================] - 141s 4ms/step - loss: 0.4209 - accuracy: 0.8744 - val_loss: 0.5106 - val_accuracy: 0.8614 Epoch 5/5 36629/36629 [==============================] - 126s 3ms/step - loss: 0.4007 - accuracy: 0.8811 - val_loss: 0.5079 - val_accuracy: 0.8617 CPU times: user 19min 36s, sys: 10min 1s, total: 29min 37s Wall time: 11min 50s In [59]: print_history ( history ) Back to Table of Contents Part 3: Hidden Layer Visualization, Saliency Maps Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps It is often said that Deep Learning Models are black boxes. But we can peak into these boxes. Let's train a small model on MNIST In [408]: from tensorflow.keras.datasets import mnist # load MNIST data ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data () In [409]: x_train . min (), x_train . max () Out[409]: (0, 255) In [410]: x_train = x_train . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension x_test = x_test . reshape (( 10000 , 28 , 28 , 1 )) x_train = x_train . astype ( 'float32' ) / 255 # Normalize between 0 and 1 x_test = x_test . astype ( 'float32' ) / 255 # Convert labels to categorical data y_train = to_categorical ( y_train ) y_test = to_categorical ( y_test ) In [411]: x_train . min (), x_train . max () Out[411]: (0.0, 1.0) In [412]: # (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data( # path='mnist.npz') x_train . shape Out[412]: (60000, 28, 28, 1) In [413]: class_idx = 0 indices = np . where ( y_test [:, class_idx ] == 1. )[ 0 ] # pick some random input from here. idx = indices [ 0 ] img = x_test [ idx ] In [414]: # pick some random input from here. idx = indices [ 0 ] # Lets sanity check the picked image. from matplotlib import pyplot as plt % matplotlib inline plt . rcParams [ 'figure.figsize' ] = ( 18 , 6 ) #plt.imshow(test_images[idx][..., 0]) img = x_test [ idx ] * 255 img = img . astype ( 'float32' ) img = np . squeeze ( img ) # trick to reduce img from (28,28,1) to (28,28) plt . imshow ( img , cmap = 'gray' ); In [415]: input_shape = ( 28 , 28 , 1 ) num_classes = 10 model = Sequential () model . add ( Conv2D ( 32 , kernel_size = ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( Dropout ( 0.25 )) model . add ( Flatten ()) model . add ( Dense ( 128 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( num_classes , activation = 'softmax' , name = 'preds' )) model . summary () Model: \"sequential_10\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_29 (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ conv2d_30 (Conv2D) (None, 24, 24, 64) 18496 _________________________________________________________________ max_pooling2d_19 (MaxPooling (None, 12, 12, 64) 0 _________________________________________________________________ dropout_2 (Dropout) (None, 12, 12, 64) 0 _________________________________________________________________ flatten_10 (Flatten) (None, 9216) 0 _________________________________________________________________ dense_19 (Dense) (None, 128) 1179776 _________________________________________________________________ dropout_3 (Dropout) (None, 128) 0 _________________________________________________________________ preds (Dense) (None, 10) 1290 ================================================================= Total params: 1,199,882 Trainable params: 1,199,882 Non-trainable params: 0 _________________________________________________________________ In [416]: model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . Adam (), metrics = [ 'accuracy' ]) In [417]: num_samples = x_train . shape [ 0 ] num_samples Out[417]: 60000 In [418]: %%time batch_size = 32 epochs = 10 model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_split = 0.2 , shuffle = True ) Train on 48000 samples, validate on 12000 samples Epoch 1/10 48000/48000 [==============================] - 60s 1ms/sample - loss: 0.2007 - accuracy: 0.9381 - val_loss: 0.0620 - val_accuracy: 0.9823 Epoch 2/10 48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0851 - accuracy: 0.9741 - val_loss: 0.0476 - val_accuracy: 0.9871 Epoch 3/10 48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.0414 - val_accuracy: 0.9890 Epoch 4/10 48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.0438 - val_accuracy: 0.9875 Epoch 5/10 48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.0335 - val_accuracy: 0.9902 Epoch 6/10 48000/48000 [==============================] - 63s 1ms/sample - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.0359 - val_accuracy: 0.9907 Epoch 7/10 48000/48000 [==============================] - 65s 1ms/sample - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0385 - val_accuracy: 0.9903 Epoch 8/10 48000/48000 [==============================] - 65s 1ms/sample - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0396 - val_accuracy: 0.9904 Epoch 9/10 48000/48000 [==============================] - 65s 1ms/sample - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0427 - val_accuracy: 0.9901 Epoch 10/10 48000/48000 [==============================] - 67s 1ms/sample - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0456 - val_accuracy: 0.9894 CPU times: user 33min 28s, sys: 24min 14s, total: 57min 42s Wall time: 10min 33s Out[418]: In [419]: score = model . evaluate ( x_test , y_test , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) Test loss: 0.03391535646364073 Test accuracy: 0.9909 Let's look at the layers with tf.keras.viz https://pypi.org/project/tf-keras-vis/ And an example: https://github.com/keisen/tf-keras-vis/blob/master/examples/visualize_conv_filters.ipynb We can identify layers by their layer id: In [638]: # Alternatively we can specify layer_id as -1 since it corresponds to the last layer. layer_id = 0 model . layers [ layer_id ] . name , model . layers [ - 2 ] . name Out[638]: ('conv2d_29', 'dropout_3') Or you may look at their output In [639]: output = [ model . layers [ layer_id ] . output ] output Out[639]: [ ] In [640]: # # You may also replace part of your NN with other parts, # # e.g. replace the activation function of the last layer # # with a linear one # model.layers[-1].activation = tf.keras.activations.linear Generate Feature Maps In [641]: def get_feature_maps ( model , layer_id , input_image ): \"\"\"Returns intermediate output (activation map) from passing an image to the model Parameters: model (tf.keras.Model): Model to examine layer_id (int): Which layer's (from zero) output to return input_image (ndarray): The input image Returns: maps (List[ndarray]): Feature map stack output by the specified layer \"\"\" model_ = Model ( inputs = [ model . input ], outputs = [ model . layers [ layer_id ] . output ]) return model_ . predict ( np . expand_dims ( input_image , axis = 0 ))[ 0 ,:,:,:] . transpose (( 2 , 0 , 1 )) In [664]: # Choose an arbitrary image image_id = 67 img = x_test [ image_id ,:,:,:] img . shape Out[664]: (28, 28, 1) In [665]: img_to_show = np . squeeze ( img ) plt . imshow ( img_to_show , cmap = 'gray' ) Out[665]: In [666]: # Was this successfully predicted? img_batch = ( np . expand_dims ( img , 0 )) print ( img_batch . shape ) predictions_single = model . predict ( img_batch ) print ( f 'Prediction is: {np.argmax(predictions_single[0])}' ) (1, 28, 28, 1) Prediction is: 4 In [667]: # layer id should be for a Conv layer, a Flatten will not do maps = get_feature_maps ( model , layer_id , img ) # [0:10] maps . shape Out[667]: (32, 26, 26) In [668]: # Plot just a subset maps = get_feature_maps ( model , layer_id , img )[ 0 : 10 ] fig , ax = plt . subplots () img = np . squeeze ( img ) ax . imshow ( img + 0.5 ) label = y_test [ image_id ,:] label = int ( np . where ( label == 1. )[ 0 ]) ax . set_title ( f 'true label = {label} ' ) f , ax = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) for i , axis in enumerate ( ax . ravel ()): axis . imshow ( maps [ i ], cmap = 'gray' ) tf_keras_vis.gradcam.Gradcam Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization In [669]: #from tensorflow.keras import backend as K # Define modifier to replace a softmax function of the last layer to a linear function. def model_modifier ( m ): m . layers [ - 1 ] . activation = tf . keras . activations . linear In [670]: #img_batch = (np.expand_dims(img,0)) # Define modifier to replace a softmax function of the last layer to a linear function. def model_modifier ( m ): m . layers [ - 1 ] . activation = tf . keras . activations . linear # Create Saliency object saliency = Saliency ( model , model_modifier ) # Define loss function. Pass it the correct class label. loss = lambda output : tf . keras . backend . mean ( output [:, tf . argmax ( y_test [ image_id ])]) In [671]: # Generate saliency map print ( img_batch . shape ) (1, 28, 28, 1) In [679]: saliency_map = saliency ( loss , img_batch ) saliency_map = normalize ( saliency_map ) f , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 10 , 5 )) #, subplot_kw={'xticks': [], 'yticks': []}) ax [ 0 ] . imshow ( saliency_map [ i ], cmap = 'jet' ) ax [ 1 ] . imshow ( img ); In [686]: # from matplotlib import cm # from tf_keras_vis.gradcam import Gradcam # Create Gradcam object gradcam = Gradcam ( model , model_modifier ) # Generate heatmap with GradCAM cam = gradcam ( loss , img_batch ) cam = normalize ( cam ) f , ax = plt . subplots ( nrows = 1 , ncols = 1 , figsize = ( 10 , 5 ), subplot_kw = { 'xticks' : [], 'yticks' : []}) for i in range ( len ( cam )): heatmap = np . uint8 ( cm . jet ( cam [ i ])[ ... , : 3 ] * 255 ) ax . imshow ( img ) ax . imshow ( heatmap , cmap = 'jet' , alpha = 0.5 ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab06/notebook/"},{"title":"Lecture 12: Autoencoders + Unet","text":"Slides Lecture 12 Slides [PPTX] Lecture 12 Slides [PDF]","tags":"lectures","url":"lectures/lecture12/"},{"title":"A-Sec 1: ResNet, Dense-Net, res-Next and Inception and transfer learning","text":"Slides A-Sec 1: Transfer Learning [PDF]","tags":"a-sections","url":"a-sections/a-section01/"},{"title":"Lecture 11: CNNs 2/2","text":"Slides Lecture 11 Slides [PPTX] Lecture 11 Slides [PDF]","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lab 4: Bayesian Analysis (Extended)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 4 - Bayesian Analysis - EXTENDED Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras Additions in this EXTENDED version Cleaner code in Bayesian Linear Regression . <---- Edited material Cleaner code in defining the Model <--- Edited Material Hierarchical Models . <----- New material Some info on Bayesian Logistic Regression with PyMC3 <-- New material In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import pymc3 as pm from pymc3 import summary #import arviz as az from matplotlib import gridspec In [53]: import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats import pandas as pd import seaborn as sns % matplotlib inline import warnings warnings . filterwarnings ( 'ignore' ) In [4]: print ( 'Running on PyMC3 v {} ' . format ( pm . __version__ )) Running on PyMC3 v3.8 In [5]: %% javascript IPython . OutputArea . auto_scroll_threshold = 20000 ; var element = $('#8478492d-2f5d-4340-9b5d-62fd20bdc754'); IPython.OutputArea.auto_scroll_threshold = 20000; In [6]: #pandas trick pd . options . display . max_columns = 50 # None -> No Restrictions pd . options . display . max_rows = 200 # None -> Be careful with this pd . options . display . max_colwidth = 100 pd . options . display . precision = 3 Learning Objectives By the end of this lab, you should be able to: Apply Bayes Rule in calculating probabilities. Practice how to apply Bayesian analysis using PyMC3 Avoid getting fired when talking to your Bayesian employer. This lab corresponds to Lectures 6, 7, and 8, and maps to Homework 3. Table of Contents The Bayesian Way of Thinking or Is this a Fair Coin? Intro to pyMC3 . Bayesian Linear Regression . 1. The Bayesian way of Thinking Here is my state of knowledge about the situation. Here is some data, I am now going to revise my state of knowledge. Table Exercise : Discuss the statement above with your table mates and make sure everyone understands what it means and what constitutes Bayesian way of thinking. Finally, count the Bayesians among you. A. Bayes Rule \\begin{equation} \\label{eq:bayes} P(A|\\textbf{B}) = \\frac{P(\\textbf{B} |A) P(A) }{P(\\textbf{B})} \\end{equation} $P(A|\\textbf{B})$ is the posterior distribution, prob(hypothesis | data) $P(\\textbf{B} |A)$ is the likelihood function, how probable is my data B for different values of the parameters $P(A)$ is the marginal probability to observe the data, called the prior , this captures our belief about the data before observing it. $P(\\textbf{B})$ is the marginal distribution (sometimes called marginal likelihood) Table Exercise : Solve the Monty Hall Paradox using Bayes Rule. The problem we are about to solve gained fame as part of a game show \"Let's Make A Deal\" hosted by Monty Hall, hence its name. It was first raised by Steve Selvin in American Statistician in 1975. The game is as follows: there are 3 doors behind one of which are the keys to a new car. There is a goat behind each of the other two doors. Let's assume your goal is to get the car and not a goat. You are asked to pick one door, and let's say you pick Door1 . The host knows where the keys are. Of the two remaining closed doors, he will always open the door that has a goat behind it. He'll say \"I will do you a favor and open Door2 \". So he opens Door2 inside which there is, of course, a goat. He now asks you, do you want to open the initial Door you chose or change to Door3 ? Generally, in this game, when you are presented with this choice should you swap the doors? Initial Steps: Start by defining the events of this probabilities game. One definition is: $A_i$: car is behind door $i$ $B_i$ host opens door $i$ $i\\in[1,2,3]$ In more math terms, the question is: is the probability of the price is behind Door 1 higher than the probability of the price is behind Door2 , given that an event has occured ? B. Bayes Rule Revisited We have data that we believe come from an underlying distribution of unknown parameters. If we find those parameters, we know everything about the process that generated this data and we can make inferences (create new data). \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} But what is $\\theta \\;$? $\\theta$ is an unknown yet fixed set of parameters. In Bayesian inference we express our belief about what $\\theta$ might be and instead of trying to guess $\\theta$ exactly, we look for its probability distribution . What that means is that we are looking for the parameters of that distribution. For example, for a Poisson distribution our $\\theta$ is only $\\lambda$. In a normal distribution, our $\\theta$ is often just $\\mu$ and $\\sigma$. C. A review of Common Probability Distributions Discrete Distributions The random variable has a probability mass function (pmf) which measures the probability that our random variable will take a specific value $y$, denoted $P(Y=y)$. Bernoulli (binary outcome, success has probability $\\theta$, $one$ trial): $ P(Y=k) = \\theta&#94;k(1-\\theta)&#94;{1-k} $ Binomial (binary outcome, success has probability $\\theta$, $k$ sucesses, $n$ trials): \\begin{equation} P(Y=k) = {{n}\\choose{k}} \\cdot \\theta&#94;k(1-\\theta)&#94;{n-k} \\end{equation} Note : Binomial(1,$p$) = Bernouli($p$) Negative Binomial Poisson (counts independent events occurring at a rate $\\lambda$) \\begin{equation} P\\left( Y=y|\\lambda \\right) = \\frac{{e&#94;{ - \\lambda } \\lambda &#94;y }}{{y!}} \\end{equation} y = 0,1,2,... Discrete Uniform Categorical, or Multinulli (random variables can take any of K possible categories, each having its own probability; this is a generalization of the Bernoulli distribution for a discrete variable with more than two possible outcomes, such as the roll of a die) Dirichlet-multinomial (a generalization of the beta distribution for many variables) Continuous Distributions The random variable has a probability density function (pdf) . Uniform (variable equally likely to be near each value in interval $(a,b)$) \\begin{equation} P(X = x) = \\frac{1}{b - a} \\end{equation} anywhere within the interval $(a, b)$, and zero elsewhere. Normal (a.k.a. Gaussian) \\begin{equation} X \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} A Normal distribution can be parameterized either in terms of precision $\\tau$ or variance $\\sigma&#94;{2}$. The link between the two is given by \\begin{equation} \\tau = \\frac{1}{\\sigma&#94;{2}} \\end{equation} Expected mean $\\mu$ Variance $\\frac{1}{\\tau}$ or $\\sigma&#94;{2}$ Parameters: mu: float , sigma: float or tau: float Beta (where the variable ($\\theta$) takes on values in the interval $[0,1]$, and is parametrized by two positive parameters, $\\alpha$ and $\\beta$ that control the shape of the distribution. Note that Beta is a good distribution to use for priors (beliefs) because its range is $[0,1]$ which is the natural range for a probability and because we can model a wide range of functions by changing the $\\alpha$ and $\\beta$ parameters. \\begin{equation} \\label{eq:beta} P(\\theta|a,b) = \\frac{1}{B(\\alpha, \\beta)} {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\propto {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\end{equation} where the normalisation constant, $B$, is a beta function of $\\alpha$ and $\\beta$, \\begin{equation} B(\\alpha, \\beta) = \\int_{t=0}&#94;1 t&#94;{\\alpha - 1} (1 - t)&#94;{\\beta - 1} dt. \\end{equation} Exponential Gamma Code Resources: Statistical Distributions in numpy/scipy: scipy.stats Statistical Distributions in pyMC3: distributions in PyMC3 (we will see those below). Exercise: Discrete Probability Distributions Plots Poisson Change the value of $\\lambda$ in the Poisson PMF and see how the plot changes. Remember that the y-axis in a discrete probability distribution shows the probability of the random variable having a specific value in the x-axis. \\begin{equation} P\\left( X=y \\right|\\lambda) = \\frac{{e&#94;{ - \\lambda } \\lambda &#94;y }}{{y!}} \\end{equation} for $y \\ge0$. Routine is stats.poisson.pmf(x, lambda) . $\\lambda$ is our $\\theta$ in this case. $\\lambda$ is also the mean in this distribution. In [7]: plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 60 ) for lam in [ 0.5 , 3 , 8 ]: pmf = stats . poisson . pmf ( x , lam ) plt . plot ( x , pmf , alpha = 0.5 , label = '$\\lambda$ = {} ' . format ( lam )) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . ylim = ( - 0.1 ) plt . show () Binomial In [8]: plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 50 ) ns = [ 10 , 17 ] ps = [ 0.5 , 0.7 ] for n , p in zip ( ns , ps ): pmf = stats . binom . pmf ( x , n , p ) plt . plot ( x , pmf , alpha = 0.5 , label = 'n = {} , p = {} ' . format ( n , p )) plt . xlabel ( 'x' , fontsize = 14 ) plt . ylabel ( 'f(x)' , fontsize = 14 ) plt . legend ( loc = 1 ) plt . show () Exercise: Continuous Distributions Plot Uniform Change the value of $\\mu$ in the Uniform PDF and see how the plot changes. Remember that the y-axis in a continuous probability distribution does not shows the actual probability of the random variable having a specific value in the x-axis because that probability is zero!. Instead, to see the probability that the variable is within a small margin we look at the integral below the curve of the PDF. The uniform is often used as a noninformative prior. Uniform - numpy.random.uniform(a=0.0, b=1.0, size) $\\alpha$ and $\\beta$ are our parameters. size is how many tries to perform. Our $\\theta$ is basically the combination of the parameters a,b. We can also call it \\begin{equation} \\mu = (a+b)/2 \\end{equation} In [9]: from scipy.stats import uniform r = uniform . rvs ( size = 1000 ) plt . plot ( r , uniform . pdf ( r ), 'r-' , lw = 5 , alpha = 0.6 , label = 'uniform pdf' ) plt . hist ( r , density = True , histtype = 'stepfilled' , alpha = 0.2 ) plt . ylabel ( r 'probability density' ) plt . xlabel ( f 'random variable' ) plt . legend ( loc = 'best' , frameon = False ) plt . show () Beta If we apply the formula we can see why we get these plots for the various values of $a$ and $b$. Notice that for $a=b=1.$ we get a constant. From then on, as the values increase, we get a curve that looks more and more like a Gaussian. In [10]: from scipy.stats import beta alphas = [ 0.5 , 0.5 , 1. , 3. , 6. ] betas = [ 0.5 , 1. , 1. , 3. , 6. ] x = np . linspace ( 0 , 1 , 1000 ) colors = [ 'red' , 'green' , 'blue' , 'black' , 'pink' ] fig , ax = plt . subplots ( figsize = ( 8 , 5 )) for a , b , colors in zip ( alphas , betas , colors ): dist = beta ( a , b ) plt . plot ( x , dist . pdf ( x ), c = colors , label = f 'a= {a} , b= {b} ' ) ax . set_ylim ( 0 , 3 ) ax . set_xlabel ( r '$\\theta$' ) ax . set_ylabel ( r '$p(\\theta|\\alpha,\\beta)$' ) ax . set_title ( 'Beta Distribution' ) ax . legend ( loc = 'best' ) fig . show (); Gaussian In [11]: plt . style . use ( 'seaborn-darkgrid' ) x = np . linspace ( - 5 , 5 , 1000 ) mus = [ 0. , 0. , 0. , - 2. ] sigmas = [ 0.4 , 1. , 2. , 0.4 ] for mu , sigma in zip ( mus , sigmas ): pdf = stats . norm . pdf ( x , mu , sigma ) plt . plot ( x , pdf , label = r '$\\mu$ = ' + f ' {mu} ,' + r '$\\sigma$ = ' + f ' {sigma} ' ) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability density' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () D. Is this a Fair Coin? Let's say you visit the casino in Monte Carlo . You want to test your theory that casinos are dubious places where coins have been manipulated to have a larger probability for tails. So you will try to estimate how fair a coin is based on a certain amount of flips. You have no prior opinion on the coin's fairness (i.e. what $p$ might be), and begin flipping the coin. You get either Heads ($H$) or Tails ($T$) as our observed data and want to see if your posterior probabilities change as you obtain more data, that is, more coin flips. A nice way to visualize this is to plot the posterior probabilities as we observe more flips (data). We will be using Bayes rule. $\\textbf{D}$ is our data. \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} In the case of a coin toss when we observe $k$ heads in $n$ tosses: \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{k}) = Beta(\\alpha + \\textbf{k}, \\beta + n - \\textbf{k}) \\end{equation} we can say that $\\alpha$ and $\\beta$ play the roles of a \"prior number of heads\" and \"prior number of tails\". In [12]: # play with the priors - here we manually set them but we could be sampling from a separate Beta trials = np . array ([ 0 , 1 , 3 , 5 , 10 , 15 , 20 , 100 , 200 , 300 ]) heads = np . array ([ 0 , 1 , 2 , 4 , 8 , 10 , 10 , 50 , 180 , 150 ]) x = np . linspace ( 0 , 1 , 100 ) # for simplicity we set a,b=1 plt . figure ( figsize = ( 10 , 8 )) for k , N in enumerate ( trials ): sx = plt . subplot ( len ( trials ) / 2 , 2 , k + 1 ) posterior = stats . beta . pdf ( x , 1 + heads [ k ], 1 + trials [ k ] - heads [ k ]) plt . plot ( x , posterior , alpha = 0.5 , label = f ' {trials[k]} tosses \\n {heads[k]} heads' ); plt . fill_between ( x , 0 , posterior , color = \"#348ABD\" , alpha = 0.4 ) plt . legend ( loc = 'upper left' , fontsize = 10 ) plt . legend () plt . autoscale ( tight = True ) plt . suptitle ( \"Posterior probabilities for coin flips\" , fontsize = 15 ); plt . tight_layout () plt . subplots_adjust ( top = 0.88 ) Top 2. Introduction to pyMC3 PyMC3 is a Python library for programming Bayesian analysis, and more specifically, data creation, model definition, model fitting, and posterior analysis. It uses the concept of a model which contains assigned parametric statistical distributions to unknown quantities in the model. Within models we define random variables and their distributions. A distribution requires at least a name argument, and other parameters that define it. You may also use the logp() method in the model to build the model log-likelihood function. We define and fit the model. PyMC3 includes a comprehensive set of pre-defined statistical distributions that can be used as model building blocks. Although they are not meant to be used outside of a model , you can invoke them by using the prefix pm , as in pm.Normal . Markov Chain Monte Carlo (MCMC) Simulations PyMC3 uses the No-U-Turn Sampler (NUTS) and the Random Walk Metropolis , two Markov chain Monte Carlo (MCMC) algorithms for sampling in posterior space. Monte Carlo gets into the name because when we sample in posterior space, we choose our next move via a pseudo-random process. NUTS is a sophisticated algorithm that can handle a large number of unknown (albeit continuous) variables. In [13]: #help(pm.Poisson) Top 3. Bayesian Linear Regression Defining the Problem Our problem is the following: we want to perform multiple linear regression to predict an outcome variable $Y$ which depends on variables $\\bf{x}_1$ and $\\bf{x}_2$. We will model $Y$ as normally distributed observations with an expected value $mu$ that is a linear function of the two predictor variables, $\\bf{x}_1$ and $\\bf{x}_2$. \\begin{equation} Y \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} \\begin{equation} \\mu = \\beta_0 + \\beta_1 \\bf{x}_1 + \\beta_2 x_2 \\end{equation} where $\\sigma&#94;2$ represents the measurement error (in this example, we will use $\\sigma&#94;2 = 10$) We also choose the parameters to have normal distributions with those parameters set by us. \\begin{eqnarray} \\beta_i \\sim \\mathcal{N}(0,\\,10) \\\\ \\sigma&#94;2 \\sim |\\mathcal{N}(0,\\,10)| \\end{eqnarray} We will artificially create the data to predict on. We will then see if our model predicts them correctly. Artificially creating some data to test our model. In [14]: np . random . seed ( 123 ) # True parameter values < --- our model does not see these sigma = 1 beta0 = 1 beta = [ 1 , 2.5 ] # Size of dataset size = 100 # Predictor variable x1 = np . linspace ( 0 , 1. , size ) x2 = np . linspace ( 0 , 2. , size ) # Simulate outcome variable Y = beta0 + beta [ 0 ] * x1 + beta [ 1 ] * x2 + np . random . randn ( size ) * sigma In [15]: from mpl_toolkits.mplot3d import Axes3D fig = plt . figure () fontsize = 14 labelsize = 8 title = 'Observed Data (created artificially by ' + r '$Y(x_1,x_2)$)' ax = fig . add_subplot ( 111 , projection = '3d' ) ax . scatter ( x1 , x2 , Y ) ax . set_xlabel ( r '$x_1$' , fontsize = fontsize ) ax . set_ylabel ( r '$x_2$' , fontsize = fontsize ) ax . set_zlabel ( r '$Y$' , fontsize = fontsize ) ax . tick_params ( labelsize = labelsize ) fig . suptitle ( title , fontsize = fontsize ) fig . tight_layout ( pad =. 1 , w_pad = 10.1 , h_pad = 2. ) #fig.subplots_adjust(); #top=0.5 plt . tight_layout plt . show () Now let's see if our model will correctly predict the values for our unknown parameters, namely $b_0$, $b_1$, $b_2$ and $\\sigma$. Defining a Model in PyMC3 In [16]: from pymc3 import Model , Normal , HalfNormal , model_to_graphviz from pymc3 import NUTS , sample , find_MAP from scipy import optimize Building the model Step1: We choose the probability model for our experiment. Y_obs = Normal('Y_obs', mu=mu, sd=sigma, observed=Y) Step2: Choose a prior distributions of the two rates, what we believe the rates were before we observed the data, and the switchpoint. beta0 = Normal('beta0', mu=0, sd=10) # Note: betas is a vector of two variables, b1 and b2, (denoted by shape=2) # so, in array notation, our beta1 = betas[0], and beta2=betas[1] betas = Normal('betas', mu=0, sd=10, shape=2) sigma = HalfNormal('sigma', sd=1) Note: Watch for missing values. Missing values are handled transparently by passing a MaskedArray or a pandas.DataFrame. Behind the scenes, another random variable, disasters.missing_values is created to model the missing values. If you pass a np.array with missing values you will get an error. In [17]: with Model () as my_linear_model : # Priors for unknown model parameters, specifically created stochastic random variables # with Normal prior distributions for the regression coefficients, # and a half-normal distribution for the standard deviation of the observations. # These are our parameters. beta0 = Normal ( 'beta0' , mu = 0 , sd = 10 ) # Note: betas is a vector of two variables, b1 and b2, (denoted by shape=2) # so, in array notation, our beta1 = betas[0], and beta2=betas[1] betas = Normal ( 'betas' , mu = 0 , sd = 10 , shape = 2 ) sigma = HalfNormal ( 'sigma' , sd = 1 ) # mu is what is called a deterministic random variable, which implies that its value is completely # determined by its parents' values (betas and sigma in our case). # There is no uncertainty in the variable beyond that which is inherent in the parents' values mu = beta0 + betas [ 0 ] * x1 + betas [ 1 ] * x2 # Likelihood function = how probable is my observed data? # This is a special case of a stochastic variable that we call an observed stochastic. # It is identical to a standard stochastic, except that its observed argument, # which passes the data to the variable, indicates that the values for this variable were observed, # and should not be changed by any fitting algorithm applied to the model. # The data can be passed in the form of either a numpy.ndarray or pandas.DataFrame object. Y_obs = Normal ( 'Y_obs' , mu = mu , sd = sigma , observed = Y ) Note: If our problem was a classification for which we would use Logistic regression see below In [18]: ## do not worry about this, it's just a nice graph to have ## you need to install python-graphviz first # conda install -c conda-forge python-graphviz model_to_graphviz ( my_linear_model ) Out[18]: %3 cluster2 2 cluster100 100 beta0 beta0 ~ Normal Y_obs Y_obs ~ Normal beta0->Y_obs sigma sigma ~ HalfNormal sigma->Y_obs betas betas ~ Normal betas->Y_obs Fitting the Model with MAP (FYI, we will not directly use this method) In Bayesian analysis we have our prior(s) , we define our likelihood , and, having specified our model , we try to calculate posterior estimates for the unknown variables in the model. We could try to calculate the posterior estimates analytically, but for most the models, this is not feasible. What we do then is compute summaries based on samples drawn from the posterior distribution using Markov Chain Monte Carlo (MCMC) sampling methods. \\begin{equation} \\label{eq:beta} P(\\theta|\\textbf{D}) \\rightarrow \\{\\theta_1,....\\theta_n\\} \\end{equation} Then we can find any estimate we want by using these samples, for example: \\begin{equation} \\mathbb{E}[f(\\theta] = \\int d\\theta{p(\\theta) f(\\theta)} \\end{equation} So we calculate the maximum a posteriori (MAP) point using optimization methods. \\begin{equation} f(\\hat{\\theta}), \\hat{\\theta} = argmax ({p(\\theta))} \\end{equation} The maximum a posteriori (MAP) estimate for a model, is the mode of the posterior distribution and is generally found using numerical optimization methods. This is often fast and easy to do, but only gives a point estimate for the parameters and can be biased if the mode isn't representative of the distribution. PyMC3 provides this functionality with the find_MAP function. MAP estimate is not always reasonable, especially if the mode is at an extreme or we have a multimodal distribution, or we have high dimensional posteriors. This will often occur in hierarchical models with the variance parameter for the random effect. If the individual group means are all the same, the posterior will have near infinite density if the variance parameter for the group means is almost zero. Most techniques for finding the MAP estimate only find a local optimium (which is often good enough), and can therefore fail badly for multimodal posteriors, as mentioned above. To solve these issues we turn to sampling as our method for finding the posterior. You do not have to worry about MAP in our problems. Our pyMC3 models use the MAP method to initialize the variables under the hood and we do not have to explicitly set this. Fitting the Model with Sampling - Doing Inference See below for PyMC3's sampling method. As you can see it has quite a few parameters. Most of them are set to default values by the package. For some, it's useful to set your own values. pymc3.sampling.sample(draws=500, step=None, init='auto', n_init=200000, start=None, trace=None, chain_idx=0, chains=None, cores=None, tune=500, progressbar=True, model=None, random_seed=None, discard_tuned_samples=True, compute_convergence_checks=True, **kwargs) Parameters to set: draws (int): number of samples to draw, defaults to 500. tune (int): number of iterations to tune, defaults to 500. target_accept (float in $[0, 1]$). The step size is tuned such that we approximate this acceptance rate. Higher values like 0.9 or 0.95 often work better for problematic posteriors. (optional) cores (int) number of chains to run in parallel, defaults to the number of CPUs in the system, but at most 4. pm.sample returns a pymc3.backends.base.MultiTrace object that contains the samples. We usually name it trace . All the information about the posterior is in trace , which also provides statistics about the sampler. In [19]: ## uncomment this to see more about pm.sample #help(pm.sample) In [20]: #help(pm.backends.base.MultiTrace) In [21]: with my_linear_model : print ( f 'Starting MCMC process' ) # draw 2000 posterior samples and run the default number of chains = 4 trace = sample ( 2000 , tune = 1000 , target_accept = 0.9 ) print ( f 'DONE' ) Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Starting MCMC process Multiprocess sampling (4 chains in 4 jobs) NUTS: [sigma, betas, beta0] Sampling 4 chains, 0 divergences: 100%|██████████| 12000/12000 [01:19<00:00, 150.72draws/s] DONE Model Plotting PyMC3 provides a variety of visualizations via plots: https://docs.pymc.io/api/plots.html . One of them is the traceplot , another is the compareplot . In [22]: from pymc3 import traceplot , compareplot , plot_posterior , forestplot traceplot ( trace ); In [23]: #help(pm.Normal) In [24]: trace . varnames Out[24]: ['beta0', 'betas', 'sigma_log__', 'sigma'] In [25]: axes = pm . plot_forest ( trace , kind = 'forestplot' , var_names = [ 'beta0' , 'betas' , 'sigma' ], combined = True , ridgeplot_overlap = 3 , figsize = ( 20 , 3 )) In [26]: # plot individual parameters which maybe do not show # well in combined plot due to scaling varname = [ 'sigma' ] pm . plot_forest ( trace , varnames = varname , combined = True ); $\\hat{R}$ is a metric for comparing how well a chain has converged to the equilibrium distribution by comparing its behavior to other randomly initialized Markov chains. Multiple chains initialized from different initial conditions should give similar results. If all chains converge to the same equilibrium, $\\hat{R}$ will be 1. If the chains have not converged to a common distribution, $\\hat{R}$ will be > 1.01. $\\hat{R}$ is a necessary but not sufficient condition. For details on the $\\hat{R}$ see Gelman and Rubin (1992) . In [27]: #help(pm.backends.base.MultiTrace) In [28]: # Remember, the true (hidden) variables are: sigma, beta0, beta1, beta2 = 1,1,1,2.5 # We want R_hat < 1.3 results = pm . summary ( trace ) results Out[28]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean sd hpd_3% hpd_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat beta0 1.008 0.225 0.589 1.427 0.003 0.002 4838.0 4817.0 4850.0 4290.0 1.0 betas[0] 0.968 9.197 -16.351 18.652 0.171 0.131 2890.0 2476.0 2900.0 2882.0 1.0 betas[1] 2.536 4.600 -6.216 11.296 0.085 0.067 2902.0 2349.0 2913.0 2897.0 1.0 sigma 1.147 0.084 1.000 1.305 0.001 0.001 4293.0 4254.0 4339.0 4027.0 1.0 This linear regression example is from the original paper on PyMC3: Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 https://doi.org/10.7717/peerj-cs.55 Top 4. Hierarchical Models Gelman et al. famous radon dataset is a classic for hierarchical modeling. In this dataset the amount of the radioactive gas radon has been measured among different households in all county's of several states. Radon gas is known to be the highest cause of lung cancer in non-smokers. It is believed to be more strongly present in households containing a basement and to differ in amount present among types of soil. Here we'll investigate this differences and try to make predictions of radonlevels in different county's based on the county itself and the presence of a basement. In [29]: df = pd . read_csv ( '../data/radon.csv' , index_col = [ 0 ]) df [ 'log_radon' ] = df [ 'log_radon' ] . astype ( 'float' ) county_names = df . county . unique () county_idx = df . county_code . values n_counties = len ( df . county . unique ()) df . head () Out[29]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } idnum state state2 stfips zip region typebldg floor room basement windoor rep stratum wave starttm stoptm startdt stopdt activity pcterr adjwt dupflag zipflag cntyfips county fips Uppm county_code log_radon 0 5081.0 MN MN 27.0 55735 5.0 1.0 1.0 3.0 N 2 4.0 41 930.0 930.0 12088.0 12288.0 2.2 9.7 1146.499 1.0 0.0 1.0 AITKIN 27001.0 0.502 0 0.833 1 5082.0 MN MN 27.0 55748 5.0 1.0 0.0 4.0 Y 5 2.0 40 1615.0 1615.0 11888.0 12088.0 2.2 14.5 471.366 0.0 0.0 1.0 AITKIN 27001.0 0.502 0 0.833 2 5083.0 MN MN 27.0 55748 5.0 1.0 0.0 4.0 Y 3 2.0 42 1030.0 1515.0 20288.0 21188.0 2.9 9.6 433.317 0.0 0.0 1.0 AITKIN 27001.0 0.502 0 1.099 3 5084.0 MN MN 27.0 56469 5.0 1.0 0.0 4.0 Y 2 2.0 24 1410.0 1410.0 122987.0 123187.0 1.0 24.3 461.624 0.0 0.0 1.0 AITKIN 27001.0 0.502 0 0.095 4 5085.0 MN MN 27.0 55011 3.0 1.0 0.0 4.0 Y 3 2.0 40 600.0 600.0 12888.0 13088.0 3.1 13.8 433.317 0.0 0.0 3.0 ANOKA 27003.0 0.429 1 1.163 Each row in the dataframe represents the radon measurements for one house in a specific county including whether the house has a basement (floor = 0) or not (floor = 1). We are interested in whether having a basement increases the radon measured in the house. To keep things simple let's keep only the following three variables: county , log_radon , and floor In [30]: # keep only these variables data = df [[ 'county' , 'log_radon' , 'floor' ]] data . head () Out[30]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } county log_radon floor 0 AITKIN 0.833 1.0 1 AITKIN 0.833 0.0 2 AITKIN 1.099 0.0 3 AITKIN 0.095 0.0 4 ANOKA 1.163 0.0 Let's check how many different counties we have. We also notice that they have a different number of houses. Some have a large number of houses measured, some only 1. In [31]: data [ 'county' ] . value_counts () . head ( 5 ) Out[31]: ST LOUIS 116 HENNEPIN 105 DAKOTA 63 ANOKA 52 WASHINGTON 46 Name: county, dtype: int64 In [34]: data [ 'county' ] . value_counts ()[ - 5 :] Out[34]: ROCK 2 STEVENS 2 MAHNOMEN 1 WILKIN 1 MURRAY 1 Name: county, dtype: int64 In [ ]: # let's add a column that numbers the counties from 0 to n # raw_ids = np.unique(data['county']) # raw2newid = {x:np.where(raw_ids == x)[0][0] for x in raw_ids} # data['county_id'] = data['county'].map(raw2newid) # data Pooling: Same Linear Regression for all We can just pool all the data and estimate one big regression to asses the influence of having a basement on radon levels across all counties. Our model would be: \\begin{equation} y_{i} = \\alpha + \\beta*floor_{i} \\end{equation} Where $i$ represents the measurement (house), and floor contains a 0 or 1 if the house has a basement or not. By ignoring the county feature, we do not differenciate on counties. In [35]: with pm . Model () as pooled_model : # common priors for all a = pm . Normal ( 'a' , mu = 0 , sigma = 100 ) b = pm . Normal ( 'b' , mu = 0 , sigma = 100 ) # radon estimate radon_est = a + b * data [ 'floor' ] . values # likelihood after radon observations radon_obs = pm . Normal ( 'radon_obs' , mu = radon_est , observed = data [ 'log_radon' ]) # note here we enter the whole dataset In [36]: model_to_graphviz ( pooled_model ) Out[36]: %3 cluster919 919 a a ~ Normal radon_obs radon_obs ~ Normal a->radon_obs b b ~ Normal b->radon_obs In [37]: with pooled_model : pooled_trace = sample ( 2000 , tune = 1000 , target_accept = 0.9 ) print ( f 'DONE' ) Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 4 jobs) NUTS: [b, a] Sampling 4 chains, 0 divergences: 100%|██████████| 12000/12000 [00:03<00:00, 3812.52draws/s] DONE In [38]: pm . traceplot ( pooled_trace ); Remember, with the pooled model we have only one intercept, $\\alpha$, and only one slope, $\\beta$ for all the counties. Let's plot the regression lines. In [39]: # plot just a subset of the countries counties = [ 'HENNEPIN' , 'AITKIN' , 'WASHINGTON' , 'MURRAY' , 'YELLOW MEDICINE' , 'MAHNOMEN' ] plt . figure ( figsize = ( 10 , 5 )) rows = 2 gs = gridspec . GridSpec ( rows , len ( counties ) // rows ) for i , county in enumerate ( counties ): county_data = data . loc [ data [ 'county' ] == county ] x = np . linspace ( - 0.2 , 1.2 ) radon_est = pooled_trace [ 'a' ] . mean () + pooled_trace [ 'b' ] . mean () * x subplt = plt . subplot ( gs [ i ]) subplt . set_ylim ( 0. , 4. ) subplt . scatter ( county_data [ 'floor' ], county_data [ 'log_radon' ]) subplt . plot ( x , radon_est , c = 'r' , label = 'pooled line' ); subplt . set_xlabel ( 'floor' , fontsize = 10 ) subplt . set_ylabel ( 'radon level' , fontsize = 10 ) subplt . set_title ( str ( county ) + ' County' ) subplt . legend () plt . tight_layout () Unpooling: Separate Linear Regression for each county We believe that different counties have different relationships of radon and basements. Our model would be: \\begin{equation} radon_{i,c} = \\alpha_c + \\beta_c*floor_{i,c} \\end{equation} Where $i$ represents the measurement, $c$ the county, and floor contains a 0 or 1 if the house has a basement or not. Notice we have separate coefficients for each county in $a_c$ and $b_c$. They are totally different, they do not even come from the same distribution. We will do this for only one county, as an example. We pick HENNEPIN county. In [40]: # chose a county county = 'MEEKER' county_data = data . loc [ data [ 'county' ] == county ] county_data . head () Out[40]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } county log_radon floor 479 MEEKER 0.875 0.0 480 MEEKER 1.386 0.0 481 MEEKER 1.988 0.0 482 MEEKER 0.788 0.0 483 MEEKER 1.194 0.0 In [41]: #help(pm.Normal) In [42]: with pm . Model () as unpooled_model : mu_a = pm . Normal ( 'mu_a' , mu = 0. , sigma = 100 ) sigma_a = pm . HalfNormal ( 'sigma_a' , 5. ) mu_b = pm . Normal ( 'mu_b' , mu = 0. , sigma = 100 ) sigma_b = pm . HalfNormal ( 'sigma_b' , 5. ) a = pm . Normal ( 'a' , mu = mu_a , sigma = sigma_a ) b = pm . Normal ( 'b' , mu = mu_b , sigma = sigma_b ) radon_est = a + b * county_data [ 'floor' ] . values radon_obs = pm . Normal ( 'radon_like' , mu = radon_est , observed = county_data [ 'log_radon' ]) In [43]: model_to_graphviz ( unpooled_model ) Out[43]: %3 cluster5 5 mu_a mu_a ~ Normal a a ~ Normal mu_a->a sigma_a sigma_a ~ HalfNormal sigma_a->a radon_like radon_like ~ Normal a->radon_like sigma_b sigma_b ~ HalfNormal b b ~ Normal sigma_b->b b->radon_like mu_b mu_b ~ Normal mu_b->b In [44]: with unpooled_model : unpooled_trace = sample ( 2000 , tune = 1000 , target_accept = 0.9 ) print ( f 'DONE' ) Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 4 jobs) NUTS: [b, a, sigma_b, mu_b, sigma_a, mu_a] Sampling 4 chains, 334 divergences: 100%|██████████| 12000/12000 [01:06<00:00, 181.58draws/s] There were 66 divergences after tuning. Increase `target_accept` or reparameterize. There were 73 divergences after tuning. Increase `target_accept` or reparameterize. There were 132 divergences after tuning. Increase `target_accept` or reparameterize. The acceptance probability does not match the target. It is 0.8236615996894034, but should be close to 0.9. Try to increase the number of tuning steps. There were 63 divergences after tuning. Increase `target_accept` or reparameterize. The number of effective samples is smaller than 10% for some parameters. DONE In [45]: pm . traceplot ( unpooled_trace ); Print the regression line for our chosen county alone. In [46]: county = 'MEEKER' county_data = data . loc [ data [ 'county' ] == county ] x = np . arange ( len ( county_data [ 'floor' ] . values )) radon_est_unpooled = unpooled_trace [ 'a' ] . mean () + unpooled_trace [ 'b' ] . mean () * county_data [ 'floor' ] . values xx = np . linspace ( - 0.2 , 1.2 ) radon_est_pooled = pooled_trace [ 'a' ] . mean () + pooled_trace [ 'b' ] . mean () * xx plt . scatter ( county_data [ 'floor' ], county_data [ 'log_radon' ]) plt . xlim ( - 0.1 , 1.1 ) plt . xlabel ( 'floor' , fontsize = 10 ) plt . ylabel ( 'radon level' , fontsize = 10 ) plt . title ( f '{str(county)} county Radon levels' ) plt . plot ( x , radon_est_unpooled , c = 'g' , label = 'unpooled line' ); plt . plot ( xx , radon_est_pooled , c = 'r' , label = 'pooled line' ); plt . legend (); Partial pooling: Hierarchical Regression (Varying-Coefficients Model) Merely by the fact that all counties are counties, they share similarities, so there is a middle ground to both of these extremes. Specifically, we may assume that while $\\alpha_c$ and $\\beta_c$are different for each county as in the unpooled case, the coefficients are all drawn from the same distribution: \\begin{equation} radon_{i,c} = \\alpha_c + \\beta_c*floor_{i,c} \\end{equation} \\begin{equation} a_c \\sim \\mathcal{N}(\\mu_a,\\,\\sigma_a&#94;{2}) \\end{equation} \\begin{equation} b_c \\sim \\mathcal{N}(\\mu_b,\\,\\sigma_b&#94;{2}) \\end{equation} where the common parameters are: \\begin{eqnarray} \\mu_a \\sim \\mathcal{N}(0,\\,10) \\\\ \\sigma_a&#94;2 \\sim |\\mathcal{N}(0,\\,10)| \\\\ \\mu_b \\sim \\mathcal{N}(0,\\,10) \\\\ \\sigma_b&#94;2 \\sim |\\mathcal{N}(0,\\,10)| \\end{eqnarray} Add math for mu and sigma The different counties are effectively sharing information through the commin priors. We are thus observing what is known as shrinkage; modeling the groups not as independent from each other, neither as a single group but rather as related. Discussion: how can we best handle this data? Does it make sense to make inferences without taking into account the county? Defining the Model for the Hierarchical Model In [47]: with pm . Model () as hierarchical_model : # Hyperpriors for group nodes mu_a = pm . Normal ( 'mu_a' , mu = 0. , sigma = 100 ) sigma_a = pm . HalfNormal ( 'sigma_a' , 5. ) mu_b = pm . Normal ( 'mu_b' , mu = 0. , sigma = 100 ) sigma_b = pm . HalfNormal ( 'sigma_b' , 5. ) # Above we just set mu and sd to a fixed value while here we # plug in a common group distribution for all a and b (which are # vectors of length n_counties). # Intercept for each county, distributed around group mean mu_a a = pm . Normal ( 'a' , mu = mu_a , sigma = sigma_a , shape = n_counties ) # beta for each county, distributed around group mean mu_b b = pm . Normal ( 'b' , mu = mu_b , sigma = sigma_b , shape = n_counties ) # Model error #eps = pm.HalfCauchy('eps', 5.) radon_est = a [ county_idx ] + b [ county_idx ] * data [ 'floor' ] . values # Data likelihood with sigma for random error # radon_like = pm.Normal('radon_like', mu=radon_est, # sigma=eps, observed=data['log_radon']) # Data likelihood with sigma without random error radon_like = pm . Normal ( 'radon_like' , mu = radon_est , #sigma=eps, observed = data [ 'log_radon' ]) In [48]: model_to_graphviz ( hierarchical_model ) Out[48]: %3 cluster85 85 cluster919 919 mu_a mu_a ~ Normal a a ~ Normal mu_a->a sigma_a sigma_a ~ HalfNormal sigma_a->a sigma_b sigma_b ~ HalfNormal b b ~ Normal sigma_b->b mu_b mu_b ~ Normal mu_b->b radon_like radon_like ~ Normal a->radon_like b->radon_like Inference In [49]: with hierarchical_model : hierarchical_trace = pm . sample ( 2000 , tune = 2000 , target_accept =. 9 ) Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 4 jobs) NUTS: [b, a, sigma_b, mu_b, sigma_a, mu_a] Sampling 4 chains, 718 divergences: 100%|██████████| 16000/16000 [00:46<00:00, 343.23draws/s] There were 463 divergences after tuning. Increase `target_accept` or reparameterize. The acceptance probability does not match the target. It is 0.6176943212701334, but should be close to 0.9. Try to increase the number of tuning steps. There were 16 divergences after tuning. Increase `target_accept` or reparameterize. There were 227 divergences after tuning. Increase `target_accept` or reparameterize. The acceptance probability does not match the target. It is 0.693488208557726, but should be close to 0.9. Try to increase the number of tuning steps. There were 12 divergences after tuning. Increase `target_accept` or reparameterize. The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling. The estimated number of effective samples is smaller than 200 for some parameters. In [50]: pm . traceplot ( hierarchical_trace , var_names = [ 'mu_a' , 'mu_b' , 'sigma_a' , 'sigma_b' ]); In [51]: results = pm . summary ( hierarchical_trace ) results [: 10 ] Out[51]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean sd hpd_3% hpd_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat mu_a 1.463 0.052 1.363 1.557 0.002 0.001 1194.0 1188.0 1189.0 2789.0 1.00 mu_b -0.632 0.099 -0.807 -0.441 0.007 0.005 190.0 190.0 193.0 338.0 1.02 a[0] 1.349 0.225 0.913 1.776 0.005 0.003 2284.0 2284.0 2298.0 2950.0 1.00 a[1] 1.059 0.123 0.826 1.285 0.003 0.002 2013.0 1953.0 1999.0 3886.0 1.01 a[2] 1.465 0.232 1.039 1.895 0.008 0.006 828.0 828.0 807.0 4451.0 1.01 a[3] 1.506 0.213 1.099 1.881 0.011 0.008 380.0 375.0 381.0 3873.0 1.01 a[4] 1.458 0.225 1.042 1.889 0.004 0.003 3112.0 3112.0 2950.0 3721.0 1.00 a[5] 1.465 0.229 1.025 1.893 0.005 0.004 1980.0 1980.0 1833.0 3835.0 1.00 a[6] 1.705 0.193 1.361 2.074 0.007 0.005 706.0 706.0 718.0 4744.0 1.01 a[7] 1.558 0.231 1.135 1.999 0.006 0.004 1447.0 1338.0 1451.0 3450.0 1.00 In [54]: # plot just a subset of the countries counties = [ 'HENNEPIN' , 'AITKIN' , 'WASHINGTON' , 'LAKE OF THE WOODS' , 'YELLOW MEDICINE' , 'ANOKA' ] plt . figure ( figsize = ( 10 , 5 )) rows = 2 gs = gridspec . GridSpec ( rows , len ( counties ) // rows ) for i , county in enumerate ( counties ): county_data = data . loc [ data [ 'county' ] == county ] subplt = plt . subplot ( gs [ i ]) # pooled line (single values coeff for all) xx = np . linspace ( - 0.2 , 1.2 ) radon_est = pooled_trace [ 'a' ] . mean () + pooled_trace [ 'b' ] . mean () * xx radon_est_hier = np . mean ( hierarchical_trace [ 'a' ][ i ]) + \\ np . mean ( hierarchical_trace [ 'b' ][ i ]) * xx # un-pooled (single subject) sns . regplot ( x = 'floor' , y = 'log_radon' , ci = None , label = 'unpooled' , data = county_data ) . set_title ( 'County ' + str ( county )) # hierarchical line subplt . set_ylim ( 0. , 4. ) subplt . scatter ( county_data [ 'floor' ], county_data [ 'log_radon' ]) subplt . plot ( xx , radon_est , c = 'r' , label = 'pooled' ); # plot the hierarchical, varying coefficient model subplt . plot ( xx , radon_est_hier , c = 'g' , label = 'hierarchical' ); subplt . set_xlabel ( 'floor' , fontsize = 10 ) subplt . set_ylabel ( 'radon level' , fontsize = 10 ) subplt . set_title ( str ( county ) + ' County' ) subplt . legend () plt . tight_layout () This tutorial has borrowed from PyMC3 docs: https://docs.pymc.io/notebooks/GLM-hierarchical.html What about Logistic Regression? If the problem above was a classification that required a Logistic Regression, we would use the logistic function ( where $\\beta_0$ is the intercept, and $\\beta_i$ (i=1, 2, 3) determines the shape of the logistic function). \\begin{equation} Pr(Y=1|X_1,X_2,X3) = {\\frac{1}{1 + exp&#94;{-(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3)}}} \\end{equation} Since both $\\beta_0$ and the $\\beta_i$s can be any possitive or negative number, we can model them as gaussian random variables. \\begin{eqnarray} \\beta_0 \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;2) \\\\ \\beta_i \\sim \\mathcal{N}(\\mu_i,\\,\\sigma_i&#94;2) \\end{eqnarray} In PyMC3 we can model those as: pm.Normal('beta_0', mu=0, sigma=100) (where $\\mu$ and $\\sigma&#94;2$ can have some initial values that we assign them, e.g. 0 and 100) The dererministic variable would be: p-logit = beta0 + beta_1 * X_1 + beta_2 * X_2 + beta_3 * X_3 To connect this variable (p_logit) with our observed data, we would use a Bernoulli as our likelihood. our_likelihood = pm.Bernoulli('our_likelihood', logit_p=p-logit, observed=our_data) Notice that the main difference with Linear Regression is the use of a Bernoulli distribution instead of a Gaussian distribution, and the use of the logistic function instead of the identity function. Note: we could explicitly create this variable using pm.Deterministic. mu = pm.Deterministic('mu', beta0 + beta_1*X_1 + beta_2*X_2 + beta_3*X_3) In [55]: # A reminder of what the logistic function looks like. # Play with parameters a and b to see the shape of the curve change b = 5. x = np . linspace ( - 8 , 8 , 100 ) plt . plot ( x , 1 / ( 1 + np . exp ( - b * x ))) plt . xlabel ( 'y' ) plt . ylabel ( 'y=logistic(x)' ) Out[55]: Text(0, 0.5, 'y=logistic(x)') References : Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 (https://doi.org/10.7717/peerj-cs.55) Distributions in PyMC3 More Details on Distributions Information about PyMC3 functions including descriptions of distributions, sampling methods, and other functions, is available via the help command. Cool Reading How Bayesian Analysis and Lawrence D. Stone found the Wreckage of Air France Flight AF 447 . Search for the gold on the sunken SS Central America . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab04/notebook-extended/"},{"title":"Lab 5: CNNs-1","text":"Notebook Lab5","tags":"labs","url":"labs/lab05/"},{"title":"Lab 5: CNNs-1","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS-109B Introduction to Data Science Lab 5: Convolutional Neural Networks Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras, Pavlos Protopapas, Patrick Ohiomoba, and David Sondak In [90]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[90]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will look at Convolutional Neural Networks (CNNs), and their building blocks. By the end of this lab, you should: have a good undertanding on how images, a common type of data for a CNN, are represented in the computer and how to think of them as arrays of numbers. be familiar with preprocessing images with tf.keras and scipy . know how to put together the building blocks used in CNNs - such as convolutional layers and pooling layers - in tensorflow.keras with an example. run your first CNN. In [91]: import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) import numpy as np from scipy.optimize import minimize from sklearn.utils import shuffle % matplotlib inline In [92]: from tensorflow.keras.models import Sequential , Model from tensorflow.keras.layers import Dense , Dropout , Flatten , Activation , Input from tensorflow.keras.layers import Conv2D , Conv1D , MaxPooling2D , MaxPooling1D , \\ GlobalAveragePooling1D , GlobalMaxPooling1D from tensorflow.keras.optimizers import Adam , SGD , RMSprop from tensorflow.keras.utils import to_categorical from tensorflow.keras.metrics import AUC , Precision , Recall , FalsePositives , FalseNegatives , \\ TruePositives , TrueNegatives from tensorflow.keras.regularizers import l2 In [93]: from __future__ import absolute_import , division , print_function , unicode_literals # TensorFlow and tf.keras import tensorflow as tf tf . keras . backend . clear_session () # For easy reset of notebook state. print ( tf . __version__ ) # You should see a > 2.0.0 here! 2.1.0 Part 0: Running on SEAS JupyterHub PLEASE READ : Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. NOTE NOTE NOTE: You are not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. source:CS231n Stanford: Google Cloud Tutorial Part 1: Parts of a Convolutional Neural Net We can have 1D CNNs which are useful for time-series or 1-Dimensional data, 2D CNNs used for 2-Dimensional data such as images, and also 3-D CNNs used for video. a. Convolutional Layers. Convolutional layers are comprised of filters and feature maps . The filters are essentially the neurons of the layer. They have the weights and produce the input for the next layer. The feature map is the output of one filter applied to the previous layer. Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis). For an RGB image, the dimension of the depth axis is 3, because the image has three color channels: red, green, and blue. For a black-and-white picture, like the MNIST digits, the depth is 1 (levels of gray). The convolution operation extracts patches from its input feature map and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it has a width and a height. Its depth can be arbitrary, because the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors as in RGB input; rather, they stand for filters. Filters encode specific aspects of the input data: at a high level, a single filter could encode the concept \"presence of a face in the input,\" for instance. In the MNIST example that we will see, the first convolution layer takes a feature map of size (28, 28, 1) and outputs a feature map of size (26, 26, 32): it computes 32 filters over its input. Each of these 32 output channels contains a 26×26 grid of values, which is a response map of the filter over the input, indicating the response of that filter pattern at different locations in the input. Convolutions are defined by two key parameters: Size of the patches extracted from the inputs. These are typically 3×3 or 5×5 The number of filters computed by the convolution. Padding : One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, 1D Convolutional Network In tf.keras see 1D convolutional layers image source: Deep Learning with Python by François Chollet 2D Convolutional Network In tf.keras see 2D convolutional layers keras.layers.Conv2D (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, kernel_initializer='glorot_uniform', data_format='channels_last', bias_initializer='zeros') b. Pooling Layers. Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. In tf.keras see 2D pooling layers keras.layers.MaxPooling2D (pool_size=(2, 2), strides=None, padding='valid', data_format=None) c. Dropout Layers. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. In tf.keras see Dropout layers tf.keras.layers.Dropout(rate, seed=None) rate: float between 0 and 1. Fraction of the input units to drop. seed: A Python integer to use as random seed. References Dropout: A Simple Way to Prevent Neural Networks from Overfitting d. Fully Connected Layers. A fully connected layer flattens the square feature map into a vector. Then we can use a sigmoid or softmax activation function to output probabilities of classes. In tf.keras see Fully Connected layers keras.layers.Dense (units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros') Part 2: Preprocessing the data In [94]: img = plt . imread ( '../images/cat.1700.jpg' ) height , width , channels = img . shape print ( f 'PHOTO: height = {height} , width = {width} , number of channels = {channels} , \\ image datatype = {img.dtype} ' ) PHOTO: height = 252, width = 261, number of channels = 4, image datatype = uint8 In [95]: img . shape Out[95]: (252, 261, 4) In [96]: # let's look at the image imgplot = plt . imshow ( img ) Visualizing the different channels In [97]: colors = [ plt . cm . Reds , plt . cm . Greens , plt . cm . Blues , plt . cm . Greys ] subplots = np . arange ( 221 , 224 ) for i in range ( 3 ): plt . subplot ( subplots [ i ]) plt . imshow ( img [:,:, i ], cmap = colors [ i ]) plt . subplot ( 224 ) plt . imshow ( img ) plt . show () If you want to learn more: Image Processing with Python and Scipy Part 3: Putting the Parts together to make a small ConvNet Model Let's put all the parts together to make a convnet for classifying our good old MNIST digits. In [98]: # Load data and preprocess ( train_images , train_labels ), ( test_images , test_labels ) = tf . keras . datasets . mnist . load_data ( path = 'mnist.npz' ) # load MNIST data train_images . shape Out[98]: (60000, 28, 28) Notice: These photos do not have a third dimention channel because they are B&W. In [99]: train_images . max (), train_images . min () Out[99]: (255, 0) In [100]: train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) train_images = train_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 test_images = test_images . astype ( 'float32' ) / 255 # Convert labels to categorical data train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) In [101]: mnist_cnn_model = Sequential () # Create sequential model # Add network layers mnist_cnn_model . add ( Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 28 , 28 , 1 ))) mnist_cnn_model . add ( MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) mnist_cnn_model . add ( MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the output of the last conv layer is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top. In [102]: mnist_cnn_model . add ( Flatten ()) mnist_cnn_model . add ( Dense ( 32 , activation = 'relu' )) mnist_cnn_model . add ( Dense ( 10 , activation = 'softmax' )) mnist_cnn_model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 13, 13, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 11, 11, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 3, 3, 64) 36928 _________________________________________________________________ flatten (Flatten) (None, 576) 0 _________________________________________________________________ dense (Dense) (None, 32) 18464 _________________________________________________________________ dense_1 (Dense) (None, 10) 330 ================================================================= Total params: 74,538 Trainable params: 74,538 Non-trainable params: 0 _________________________________________________________________ Question Why are we using cross-entropy here? In [103]: loss = tf . keras . losses . categorical_crossentropy optimizer = Adam ( lr = 0.001 ) #optimizer = RMSprop(lr=1e-2) # see https://www.tensorflow.org/api_docs/python/tf/keras/metrics metrics = [ 'accuracy' ] # Compile model mnist_cnn_model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) Discussion How can we choose the batch size? In [69]: %%time # Fit the model verbose , epochs , batch_size = 1 , 10 , 64 # try a different num epochs and batch size : 30, 16 history = mnist_cnn_model . fit ( train_images , train_labels , epochs = epochs , batch_size = batch_size , verbose = verbose , validation_split = 0.2 , # validation_data=(X_val, y_val) # IF you have val data shuffle = True ) Train on 48000 samples, validate on 12000 samples Epoch 1/10 48000/48000 [==============================] - 17s 362us/sample - loss: 0.2466 - accuracy: 0.9252 - val_loss: 0.1024 - val_accuracy: 0.9690 Epoch 2/10 48000/48000 [==============================] - 18s 366us/sample - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0536 - val_accuracy: 0.9845 Epoch 3/10 48000/48000 [==============================] - 18s 372us/sample - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0453 - val_accuracy: 0.9860 Epoch 4/10 48000/48000 [==============================] - 18s 383us/sample - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0433 - val_accuracy: 0.9861 Epoch 5/10 48000/48000 [==============================] - 18s 377us/sample - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0514 - val_accuracy: 0.9857 Epoch 6/10 48000/48000 [==============================] - 18s 380us/sample - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9886 Epoch 7/10 48000/48000 [==============================] - 18s 372us/sample - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0427 - val_accuracy: 0.9883 Epoch 8/10 48000/48000 [==============================] - 18s 374us/sample - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0452 - val_accuracy: 0.9877 Epoch 9/10 48000/48000 [==============================] - 18s 369us/sample - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0404 - val_accuracy: 0.9890 Epoch 10/10 48000/48000 [==============================] - 18s 372us/sample - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0467 - val_accuracy: 0.9887 CPU times: user 10min, sys: 4min 6s, total: 14min 7s Wall time: 2min 58s In [70]: print ( history . history . keys ()) print ( history . history [ 'val_accuracy' ][ - 1 ]) plt . plot ( history . history [ 'accuracy' ]) plt . plot ( history . history [ 'val_accuracy' ]) plt . title ( 'model accuracy' ) plt . ylabel ( 'accuracy' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () # summarize history for loss plt . plot ( history . history [ 'loss' ]) plt . plot ( history . history [ 'val_loss' ]) plt . title ( 'model loss' ) plt . ylabel ( 'loss' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () #plt.savefig('../images/batch8.png') dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy']) 0.98875 In [71]: mnist_cnn_model . metrics_names Out[71]: ['loss', 'accuracy'] In [72]: # Evaluate the model on the test data: score = mnist_cnn_model . evaluate ( test_images , test_labels , batch_size = batch_size , verbose = 0 , callbacks = None ) #print(\"%s: %.2f%%\" % (mnist_cnn_model.metrics_names[1], score[1]*100)) test_acc = mnist_cnn_model . evaluate ( test_images , test_labels ) test_acc 10000/10000 [==============================] - 1s 83us/sample - loss: 0.0392 - accuracy: 0.9898 Out[72]: [0.03917089055543343, 0.9898] Discussion Compare validation accuracy and test accuracy? Comment on whether we have overfitting. Data Preprocessing : Meet the ImageDataGenerator class in keras (keras ImageGenerator documentation) The MNIST and other pre-loaded dataset are formatted in a way that is almost ready for feeding into the model. What about plain images? They should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. The Dogs vs. Cats dataset that you'll use isn't packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren't mainstream. The data has been downloaded for you from https://www.kaggle.com/c/dogs-vs-cats/data The pictures are medium-resolution color JPEGs. In [73]: # TODO: set your base dir to your correct local location base_dir = '../data/cats_and_dogs_small' import os , shutil # Set up directory information train_dir = os . path . join ( base_dir , 'train' ) validation_dir = os . path . join ( base_dir , 'validation' ) test_dir = os . path . join ( base_dir , 'test' ) train_cats_dir = os . path . join ( train_dir , 'cats' ) train_dogs_dir = os . path . join ( train_dir , 'dogs' ) validation_cats_dir = os . path . join ( validation_dir , 'cats' ) validation_dogs_dir = os . path . join ( validation_dir , 'dogs' ) test_cats_dir = os . path . join ( test_dir , 'cats' ) test_dogs_dir = os . path . join ( test_dir , 'dogs' ) print ( 'total training cat images:' , len ( os . listdir ( train_cats_dir ))) print ( 'total training dog images:' , len ( os . listdir ( train_dogs_dir ))) print ( 'total validation cat images:' , len ( os . listdir ( validation_cats_dir ))) print ( 'total validation dog images:' , len ( os . listdir ( validation_dogs_dir ))) print ( 'total test cat images:' , len ( os . listdir ( test_cats_dir ))) print ( 'total test dog images:' , len ( os . listdir ( test_dogs_dir ))) total training cat images: 1000 total training dog images: 1000 total validation cat images: 500 total validation dog images: 500 total test cat images: 500 total test dog images: 500 So you do indeed have 2,000 training images, 1,000 validation images, and 1,000 test images. Each split contains the same number of samples from each class: this is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success. Discussion Should you always do your own splitting of the data How about shuffling? Does it always make sense? In [74]: img_path = '../data/cats_and_dogs_small/train/cats/cat.70.jpg' # We preprocess the image into a 4D tensor from keras.preprocessing import image import numpy as np img = image . load_img ( img_path , target_size = ( 150 , 150 )) img_tensor = image . img_to_array ( img ) img_tensor = np . expand_dims ( img_tensor , axis = 0 ) # Remember that the model was trained on inputs # that were preprocessed in the following way: img_tensor /= 255. # Its shape is (1, 150, 150, 3) print ( img_tensor . shape ) (1, 150, 150, 3) In [75]: plt . imshow ( img_tensor [ 0 ]) plt . show () Why do we need an extra dimension here? Building the network In [76]: model = Sequential () model . add ( Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Flatten ()) model . add ( Dense ( 128 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential_1\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_6 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 6272) 0 _________________________________________________________________ dense_2 (Dense) (None, 128) 802944 _________________________________________________________________ dense_3 (Dense) (None, 1) 129 ================================================================= Total params: 1,043,905 Trainable params: 1,043,905 Non-trainable params: 0 _________________________________________________________________ For the compilation step, you'll go with the RMSprop optimizer. Because you ended the network with a single sigmoid unit, you'll use binary crossentropy as the loss. In [77]: loss = tf . keras . losses . binary_crossentropy #optimizer = Adam(lr=0.001) optimizer = RMSprop ( lr = 1e-2 ) metrics = [ 'accuracy' ] # Compile model model . compile ( optimizer = optimizer , loss = loss , metrics = metrics ) The steps for getting it into the network are roughly as follows: Read the picture files. Convert the JPEG content to RGB grids of pixels. Convert these into floating-point tensors. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically with the class ImageDataGenerator , which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you'll use here. In [78]: from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator ( rescale = 1. / 255 ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Let's look at the output of one of these generators: it yields batches of 150×150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point: In [79]: for data_batch , labels_batch in train_generator : print ( 'data batch shape:' , data_batch . shape ) print ( 'labels batch shape:' , labels_batch . shape ) break data batch shape: (20, 150, 150, 3) labels batch shape: (20,) Let's fit the model to the data using the generator. You do so using the .fit_generator method, the equivalent of .fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples. When using fit_generator, you can pass a validation_data argument, much as with the fit method. It's important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation In [80]: %%time # Fit the model <--- always a good idea to time it verbose , epochs , batch_size , steps_per_epoch = 1 , 5 , 64 , 100 history = model . fit_generator ( train_generator , steps_per_epoch = steps_per_epoch , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) # It's good practice to always save your models after training. model . save ( 'cats_and_dogs_small_1.h5' ) WARNING:tensorflow:From :9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: Please use Model.fit, which supports generators. WARNING:tensorflow:sample_weight modes were coerced from ... to ['...'] WARNING:tensorflow:sample_weight modes were coerced from ... to ['...'] Train for 100 steps, validate for 50 steps Epoch 1/5 100/100 [==============================] - 41s 411ms/step - loss: 149.8046 - accuracy: 0.4885 - val_loss: 0.6931 - val_accuracy: 0.5000 Epoch 2/5 100/100 [==============================] - 38s 382ms/step - loss: 0.6939 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.5000 Epoch 3/5 100/100 [==============================] - 38s 376ms/step - loss: 0.6937 - accuracy: 0.4830 - val_loss: 0.6931 - val_accuracy: 0.5000 Epoch 4/5 100/100 [==============================] - 37s 371ms/step - loss: 0.6933 - accuracy: 0.5010 - val_loss: 0.6935 - val_accuracy: 0.5000 Epoch 5/5 100/100 [==============================] - 39s 392ms/step - loss: 0.6937 - accuracy: 0.4940 - val_loss: 0.6932 - val_accuracy: 0.5000 CPU times: user 13min 32s, sys: 3min 34s, total: 17min 7s Wall time: 3min 13s Let's plot the loss and accuracy of the model over the training and validation data during training: In [81]: print ( history . history . keys ()) print ( history . history [ 'val_accuracy' ][ - 1 ]) plt . plot ( history . history [ 'accuracy' ]) plt . plot ( history . history [ 'val_accuracy' ]) plt . title ( 'model accuracy' ) plt . ylabel ( 'accuracy' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () # summarize history for loss plt . plot ( history . history [ 'loss' ]) plt . plot ( history . history [ 'val_loss' ]) plt . title ( 'model loss' ) plt . ylabel ( 'loss' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () plt . savefig ( '../images/batch8.png' ) dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy']) 0.5 Let's try data augmentation In [82]: datagen = ImageDataGenerator ( rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True , fill_mode = 'nearest' ) These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over this code: rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally. shear_range is for randomly applying shearing transformations. zoom_range is for randomly zooming inside pictures. horizontal_flip is for randomly flipping half the images horizontally—relevant when there are no assumptions of - horizontal asymmetry (for example, real-world pictures). fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. Let's look at the augmented images In [83]: from keras.preprocessing import image fnames = [ os . path . join ( train_dogs_dir , fname ) for fname in os . listdir ( train_dogs_dir )] img_path = fnames [ 3 ] # Chooses one image to augment img = image . load_img ( img_path , target_size = ( 150 , 150 )) # Reads the image and resizes it x = image . img_to_array ( img ) # Converts it to a Numpy array with shape (150, 150, 3) x = x . reshape (( 1 ,) + x . shape ) # Reshapes it to (1, 150, 150, 3) i = 0 for batch in datagen . flow ( x , batch_size = 1 ): plt . figure ( i ) imgplot = plt . imshow ( image . array_to_img ( batch [ 0 ])) i += 1 if i % 4 == 0 : break plt . show () If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images—you can't produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you'll also add a Dropout layer to your model right before the densely connected classifier. In [84]: model = Sequential () model . add ( Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D (( 2 , 2 ))) model . add ( Flatten ()) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 512 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . summary () Model: \"sequential_2\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_7 (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d_6 (MaxPooling2 (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_8 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_7 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_9 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_8 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_10 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_9 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 6272) 0 _________________________________________________________________ dropout (Dropout) (None, 6272) 0 _________________________________________________________________ dense_4 (Dense) (None, 512) 3211776 _________________________________________________________________ dense_5 (Dense) (None, 1) 513 ================================================================= Total params: 3,453,121 Trainable params: 3,453,121 Non-trainable params: 0 _________________________________________________________________ In [85]: loss = tf . keras . losses . binary_crossentropy optimizer = RMSprop ( lr = 1e-4 ) metrics = [ 'acc' , 'accuracy' ] # Compile model model . compile ( loss = loss , optimizer = optimizer , metrics = metrics ) In [86]: # Let's train the network using data augmentation and dropout. train_datagen = ImageDataGenerator ( rescale = 1. / 255 , rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ,) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) # Note that the validation data shouldn't be augmented! train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) # save model if needed model . save ( 'cats_and_dogs_small_2.h5' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. WARNING:tensorflow:sample_weight modes were coerced from ... to ['...'] WARNING:tensorflow:sample_weight modes were coerced from ... to ['...'] Train for 100 steps, validate for 50 steps Epoch 1/5 63/100 [=================>............] - ETA: 22s - loss: 0.6958 - acc: 0.5100 - accuracy: 0.5100WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset. And let's plot the results again. Thanks to data augmentation and dropout, you're no longer overfitting: the training curves are closely tracking the validation curves. You now reach an accuracy of 82%, a 15% relative improvement over the non-regularized model. (Note: these numbers are for 100 epochs..) In [44]: print ( history . history . keys ()) print ( history . history [ 'val_accuracy' ][ - 1 ]) plt . plot ( history . history [ 'accuracy' ]) plt . plot ( history . history [ 'val_accuracy' ]) plt . title ( 'Accuracy with data augmentation' ) plt . ylabel ( 'accuracy' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () # summarize history for loss plt . plot ( history . history [ 'loss' ]) plt . plot ( history . history [ 'val_loss' ]) plt . title ( 'Loss with data augmentation' ) plt . ylabel ( 'loss' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' , 'val' ], loc = 'upper left' ) plt . show () #plt.savefig('../images/batch8.png') dict_keys(['val_loss', 'val_acc', 'val_accuracy', 'loss', 'acc', 'accuracy']) 0.6040608882904053 By using regularization techniques even further, and by tuning the network's parameters (such as the number of filters per convolution layer, or the number of layers in the network), you may be able to get an even better accuracy, likely up to 86% or 87%. But it would prove difficult to go any higher just by training your own convnet from scratch, because you have so little data to work with. As a next step to improve your accuracy on this problem, you'll have to use a pretrained model. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab05/notebook/"},{"title":"Lecture 10: CNNs 1/2","text":"Slides Lecture 10 Slides [PPTX] Lecture 10 Slides [PDF]","tags":"lectures","url":"lectures/lecture10/"},{"title":"Lecture 9: ML/NN Roadmap","text":"Slides Lecture 9 Slides [PDF] Lecture 9 Slides [PPTX]","tags":"lectures","url":"lectures/lecture09/"},{"title":"Lab 4: Bayesian Analysis","text":"Notebooks Lab 4: Bayesian Analysis Lab 4: Bayesian Analysis (Extended) Data dataset_2_test.csv dataset_2_train.csv","tags":"labs","url":"labs/lab04/"},{"title":"Lab 4: Bayesian Analysis","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 4 - Bayesian Analysis Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import pymc3 as pm from pymc3 import summary In [3]: import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats import pandas as pd % matplotlib inline import warnings warnings . filterwarnings ( 'ignore' ) In [4]: print ( 'Running on PyMC3 v {} ' . format ( pm . __version__ )) Running on PyMC3 v3.8 In [5]: %% javascript IPython . OutputArea . auto_scroll_threshold = 20000 ; var element = $('#4e038893-fae0-4204-818d-3e10bbc43bad'); IPython.OutputArea.auto_scroll_threshold = 20000; Learning Objectives By the end of this lab, you should be able to: Understand how probability distributions work. Apply Bayes Rule in calculating probabilities. Understand how to apply Bayesian analysis using PyMC3 Avoid getting fired when talking to your Bayesian employer. This lab corresponds to Lectures 6, 7, and 8, and maps to Homework 3. Table of Contents The Bayesian Way of Thinking or Is this a Fair Coin? Intro to pyMC3 . Bayesian Linear Regression . Try this at Home: Example on Mining Disasters . 1. The Bayesian way of Thinking Here is my state of knowledge about the situation. Here is some data, I am now going to revise my state of knowledge. Table Exercise : Discuss the statement above with your table mates and make sure everyone understands what it means and what constitutes Bayesian way of thinking. Finally, count the Bayesians among you. A. Bayes Rule \\begin{equation} \\label{eq:bayes} P(A|\\textbf{B}) = \\frac{P(\\textbf{B} |A) P(A) }{P(\\textbf{B})} \\end{equation} $P(A|\\textbf{B})$ is the posterior distribution, prob(hypothesis | data) $P(\\textbf{B} |A)$ is the likelihood function, how probable is my data B for different values of the parameters $P(A)$ is the marginal probability to observe the data, called the prior , this captures our belief about the data before observing it. $P(\\textbf{B})$ is the marginal distribution (sometimes called marginal likelihood) Table Exercise : Solve the Monty Hall Paradox using Bayes Rule. You are invited to play a game. There are 3 doors behind one of which are the keys to a brand new red Tesla. There is a goat behind each of the other two. You are asked to pick one door, and let's say you pick Door1 . The host knows where the keys are. Of the two remaining closed doors, he will always open the door that has a goat behind it. He'll say \"I will do you a favor and open Door2 \". So he opens Door2 inside which there is, of course, a goat. He now asks you, do you want to open the initial Door you chose or change to Door3 ? Generally, in this game, when you are presented with this choice should you swap the doors? Initial Steps: Start by defining the events of this probabilities game. One definition is: $A_i$: car is behind door $i$ $B_i$ host opens door $i$ $i\\in[1,2,3]$ In more math terms, the question is: is the probability that the price is behind Door 1 higher than the probability that the price is behind Door2 , given that an event has occured ? B. Bayes Rule written with Probability Distributions We have data that we believe come from an underlying distribution of unknown parameters. If we find those parameters, we know everything about the process that generated this data and we can make inferences (create new data). \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} But what is $\\theta \\;$? $\\theta$ is an unknown yet fixed set of parameters. In Bayesian inference we express our belief about what $\\theta$ might be and instead of trying to guess $\\theta$ exactly, we look for its probability distribution . What that means is that we are looking for the parameters of that distribution. For example, for a Poisson distribution our $\\theta$ is only $\\lambda$. In a normal distribution, our $\\theta$ is often just $\\mu$ and $\\sigma$. C. A review of Common Probability Distributions Discrete Distributions The random variable has a probability mass function (pmf) which measures the probability that our random variable will take a specific value $y$, denoted $P(Y=y)$. Bernoulli (binary outcome, success has probability $\\theta$, $one$ trial): $ P(Y=k) = \\theta&#94;k(1-\\theta)&#94;{1-k} $ Binomial (binary outcome, success has probability $\\theta$, $n$ trials): \\begin{equation} P(Y=k) = {{n}\\choose{k}} \\cdot \\theta&#94;k(1-\\theta)&#94;{n-k} \\end{equation} Note : Binomial(1,$p$) = Bernouli($p$) Negative Binomial Poisson (counts independent events occurring at a rate) \\begin{equation} P\\left( Y=y|\\lambda \\right) = \\frac{{e&#94;{ - \\lambda } \\lambda &#94;y }}{{y!}} \\end{equation} y = 0,1,2,... Discrete Uniform Categorical, or Multinulli (random variables can take any of K possible categories, each having its own probability; this is a generalization of the Bernoulli distribution for a discrete variable with more than two possible outcomes, such as the roll of a die) Dirichlet-multinomial (a generalization of the beta distribution for many variables) Continuous Distributions The random variable has a probability density function (pdf) . Uniform (variable equally likely to be near each value in interval $(a,b)$) \\begin{equation} P(X = x) = \\frac{1}{b - a} \\end{equation} anywhere within the interval $(a, b)$, and zero elsewhere. Normal (a.k.a. Gaussian) \\begin{equation} X \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} A Normal distribution can be parameterized either in terms of precision $\\tau$ or standard deviation ($\\sigma&#94;{2}$. The link between the two is given by \\begin{equation} \\tau = \\frac{1}{\\sigma&#94;{2}} \\end{equation} Mean $\\mu$ Variance $\\frac{1}{\\tau}$ or $\\sigma&#94;{2}$ Parameters: mu: float , sigma: float or tau: float Beta (variable ($\\theta$) taking on values in the interval $[0,1]$, and parametrized by two positive parameters, $\\alpha$ and $\\beta$ that control the shape of the distribution. Note: Beta is a good distribution to use for priors (beliefs) because its range is $[0,1]$ which is the natural range for a probability and because we can model a wide range of functions by changing the $\\alpha$ and $\\beta$ parameters. \\begin{equation} \\label{eq:beta} P(\\theta) = \\frac{1}{B(\\alpha, \\beta)} {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\propto {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\end{equation} where the normalisation constant, $B$, is a beta function of $\\alpha$ and $\\beta$, \\begin{equation} B(\\alpha, \\beta) = \\int_{t=0}&#94;1 t&#94;{\\alpha - 1} (1 - t)&#94;{\\beta - 1} dt. \\end{equation} Exponential Gamma Code Resources: Statistical Distributions in numpy/scipy: scipy.stats Statistical Distributions in pyMC3: distributions in PyMC3 (we will see those below). Exercise: Plot a Discrete variable Change the value of $\\mu$ in the Poisson PMF and see how the plot changes. Remember that the y-axis in a discrete probability distribution shows the probability of the random variable having a specific value in the x-axis. \\begin{equation} P\\left( X=k \\right) = \\frac{{e&#94;{ - \\mu } \\mu &#94;k }}{{k!}} \\end{equation} stats.poisson.pmf(x, mu) $\\mu$(mu) is our $\\theta$ in this case. In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 30 ) for m in [ 0.5 , 3 , 8 ]: pmf = stats . poisson . pmf ( x , m ) plt . plot ( x , pmf , 'o' , alpha = 0.5 , label = '$\\mu$ = {} ' . format ( m )) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . ylim = ( - 0.1 ) plt . show () In [ ]: # same for binomial plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 22 ) ns = [ 10 , 17 ] ps = [ 0.5 , 0.7 ] for n , p in zip ( ns , ps ): pmf = stats . binom . pmf ( x , n , p ) plt . plot ( x , pmf , 'o' , alpha = 0.5 , label = 'n = {} , p = {} ' . format ( n , p )) plt . xlabel ( 'x' , fontsize = 14 ) plt . ylabel ( 'f(x)' , fontsize = 14 ) plt . legend ( loc = 1 ) plt . show () In [ ]: # discrete uniform plt . style . use ( 'seaborn-darkgrid' ) ls = [ 0 ] us = [ 3 ] # watch out, this number can only be integer! for l , u in zip ( ls , us ): x = np . arange ( l , u + 1 ) pmf = [ 1.0 / ( u - l + 1 )] * len ( x ) plt . plot ( x , pmf , '-o' , label = 'lower = {} , upper = {} ' . format ( l , u )) plt . xlabel ( 'x' , fontsize = 12 ) plt . ylabel ( 'probability P(x)' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () Exercise: Plot a continuous variable Change the value of $\\mu$ in the Uniform PDF and see how the plot changes. Remember that the y-axis in a continuous probability distribution does not shows the actual probability of the random variable having a specific value in the x-axis because that probability is zero!. Instead, to see the probability that the variable is within a small margin we look at the integral below the curve of the PDF. The uniform is often used as a noninformative prior. Uniform - numpy.random.uniform(a=0.0, b=1.0, size) $\\alpha$ and $\\beta$ are our parameters. size is how many tries to perform. Our $\\theta$ is basically the combination of the parameters a,b. We can also call it \\begin{equation} \\mu = (a+b)/2 \\end{equation} In [ ]: from scipy.stats import uniform r = uniform . rvs ( size = 1000 ) plt . plot ( r , uniform . pdf ( r ), 'r-' , lw = 5 , alpha = 0.6 , label = 'uniform pdf' ) plt . hist ( r , density = True , histtype = 'stepfilled' , alpha = 0.2 ) plt . ylabel ( r 'probability density' ) plt . xlabel ( f 'random variable' ) plt . legend ( loc = 'best' , frameon = False ) plt . show () In [ ]: from scipy.stats import beta alphas = [ 0.5 , 1.5 , 3.0 ] betas = [ 0.5 , 1.5 , 3.0 ] x = np . linspace ( 0 , 1 , 1000 ) colors = [ 'red' , 'green' , 'blue' ] fig , ax = plt . subplots ( figsize = ( 8 , 5 )) for a , b , colors in zip ( alphas , betas , colors ): dist = beta ( a , b ) plt . plot ( x , dist . pdf ( x ), c = colors , label = f 'a= {a} , b= {b} ' ) ax . set_ylim ( 0 , 3 ) ax . set_xlabel ( r '$\\theta$' ) ax . set_ylabel ( r '$p(\\theta|\\alpha,\\beta)$' ) ax . set_title ( 'Beta Distribution' ) ax . legend ( loc = 'best' ) fig . show (); In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . linspace ( - 5 , 5 , 1000 ) mus = [ 0. , 0. , 0. , - 2. ] sigmas = [ 0.4 , 1. , 2. , 0.4 ] for mu , sigma in zip ( mus , sigmas ): pdf = stats . norm . pdf ( x , mu , sigma ) plt . plot ( x , pdf , label = r '$\\mu$ = ' + f ' {mu} ,' + r '$\\sigma$ = ' + f ' {sigma} ' ) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability density' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . linspace ( - 5 , 5 , 1000 ) mus = [ 0. , 0. , 0. , - 2. ] # mean sigmas = [ 0.4 , 1. , 2. , 0.4 ] # std for mu , sigma in zip ( mus , sigmas ): plt . plot ( x , uniform . pdf ( x , mu , sigma ), lw = 5 , alpha = 0.4 , \\ label = r '$\\mu$ = ' + f ' {mu} ,' + r '$\\sigma$ = ' + f ' {sigma} ' ) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability density' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () D. Is this a Fair Coin? We do not want to promote gambling but let's say you visit the casino in Monte Carlo . You want to test your theory that casinos are dubious places where coins have been manipulated to have a larger probability for tails. So you will try to estimate how fair a coin is based on 100 flips. You begin by flipping the coin. You get either Heads ($H$) or Tails ($T$) as our observed data and want to see if your posterior probabilities change as you obtain more data, that is, more coin flips. A nice way to visualize this is to plot the posterior probabilities as we observe more flips (data). We will be using Bayes rule. $\\textbf{D}$ is our data. \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} In the case of a coin toss when we observe $k$ heads in $n$ tosses: \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{k}) = Beta(\\alpha + \\textbf{k}, \\beta + n - \\textbf{k}) \\end{equation} we can say that $\\alpha$ and $\\beta$ play the roles of a \"prior number of heads\" and \"prior number of tails\". In [ ]: # play with the priors - here we manually set them but we could be sampling from a separate Beta trials = np . array ([ 0 , 1 , 3 , 5 , 10 , 15 , 20 , 100 , 200 , 300 ]) heads = np . array ([ 0 , 1 , 2 , 4 , 8 , 10 , 10 , 50 , 180 , 150 ]) x = np . linspace ( 0 , 1 , 100 ) # for simplicity we set a,b=1 plt . figure ( figsize = ( 10 , 8 )) for k , N in enumerate ( trials ): sx = plt . subplot ( len ( trials ) / 2 , 2 , k + 1 ) posterior = stats . beta . pdf ( x , 1 + heads [ k ], 1 + trials [ k ] - heads [ k ]) plt . plot ( x , posterior , alpha = 0.5 , label = f ' {trials[k]} tosses \\n {heads[k]} heads' ); plt . fill_between ( x , 0 , posterior , color = \"#348ABD\" , alpha = 0.4 ) plt . legend ( loc = 'upper left' , fontsize = 10 ) plt . legend () plt . autoscale ( tight = True ) plt . suptitle ( \"Posterior probabilities for coin flips\" , fontsize = 15 ); plt . tight_layout () plt . subplots_adjust ( top = 0.88 ) Top 2. Introduction to pyMC3 PyMC3 is a Python library for programming Bayesian analysis, and more specifically, data creation, model definition, model fitting, and posterior analysis. It uses the concept of a model which contains assigned parametric statistical distributions to unknown quantities in the model. Within models we define random variables and their distributions. A distribution requires at least a name argument, and other parameters that define it. You may also use the logp() method in the model to build the model log-likelihood function. We define and fit the model. PyMC3 includes a comprehensive set of pre-defined statistical distributions that can be used as model building blocks. Although they are not meant to be used outside of a model , you can invoke them by using the prefix pm , as in pm.Normal . Markov Chain Monte Carlo (MCMC) Simulations PyMC3 uses the No-U-Turn Sampler (NUTS) and the Random Walk Metropolis , two Markov chain Monte Carlo (MCMC) algorithms for sampling in posterior space. Monte Carlo gets into the name because when we sample in posterior space, we choose our next move via a pseudo-random process. NUTS is a sophisticated algorithm that can handle a large number of unknown (albeit continuous) variables. In [ ]: with pm . Model () as model : z = pm . Normal ( 'z' , mu = 0. , sigma = 5. ) x = pm . Normal ( 'x' , mu = z , sigma = 1. , observed = 5. ) print ( x . logp ({ 'z' : 2.5 })) print ( z . random ( 10 , 100 )[: 10 ]) References : Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 (https://doi.org/10.7717/peerj-cs.55) Distributions in PyMC3 More Details on Distributions Information about PyMC3 functions including descriptions of distributions, sampling methods, and other functions, is available via the help command. In [ ]: #help(pm.Poisson) Top 3. Bayesian Linear Regression Let's say we want to predict outcomes Y as normally distributed observations with an expected value $mu$ that is a linear function of two predictor variables, $\\bf{x}_1$ and $\\bf{x}_2$. \\begin{equation} \\mu = \\alpha + \\beta_1 \\bf{x}_1 + \\beta_2 x_2 \\end{equation}\\begin{equation} Y \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} where $\\sigma&#94;2$ represents the measurement error. In this example, we will use $\\sigma&#94;2 = 10$ We also choose the parameters as normal distributions: \\begin{eqnarray} \\alpha \\sim \\mathcal{N}(0,\\,10) \\\\ \\beta_i \\sim \\mathcal{N}(0,\\,10) \\\\ \\sigma&#94;2 \\sim |\\mathcal{N}(0,\\,10)| \\end{eqnarray} We will artificially create the data to predict on. We will then see if our model predicts them correctly. In [ ]: # Initialize random number generator np . random . seed ( 123 ) # True parameter values alpha , sigma = 1 , 1 beta = [ 1 , 2.5 ] # Size of dataset size = 100 # Predictor variable X1 = np . linspace ( 0 , 1 , size ) X2 = np . linspace ( 0 , . 2 , size ) # Simulate outcome variable Y = alpha + beta [ 0 ] * X1 + beta [ 1 ] * X2 + np . random . randn ( size ) * sigma fig , ax = plt . subplots ( 1 , 2 , figsize = ( 10 , 6 ), sharex = True ) ax [ 0 ] . scatter ( X1 , Y ) ax [ 1 ] . scatter ( X2 , Y ) ax [ 0 ] . set_xlabel ( r '$x_1$' , fontsize = 14 ) ax [ 0 ] . set_ylabel ( r '$Y$' , fontsize = 14 ) ax [ 1 ] . set_xlabel ( r '$x_2$' , fontsize = 14 ) ax [ 1 ] . set_ylabel ( r '$Y$' , fontsize = 14 ) In [ ]: from pymc3 import Model , Normal , HalfNormal basic_model = Model () with basic_model : # Priors for unknown model parameters, specifically create stochastic random variables # with Normal prior distributions for the regression coefficients, # and a half-normal distribution for the standard deviation of the observations, σ. alpha = Normal ( 'alpha' , mu = 0 , sd = 10 ) beta = Normal ( 'beta' , mu = 0 , sd = 10 , shape = 2 ) sigma = HalfNormal ( 'sigma' , sd = 1 ) # Expected value of outcome - posterior mu = alpha + beta [ 0 ] * X1 + beta [ 1 ] * X2 # Likelihood (sampling distribution) of observations Y_obs = Normal ( 'Y_obs' , mu = mu , sd = sigma , observed = Y ) In [ ]: # model fitting with sampling from pymc3 import NUTS , sample , find_MAP from scipy import optimize with basic_model : # obtain starting values via MAP start = find_MAP ( fmin = optimize . fmin_powell ) # instantiate sampler step = NUTS ( scaling = start ) # draw 2000 posterior samples trace = sample ( 2000 , step , start = start ) In [ ]: from pymc3 import traceplot traceplot ( trace ); In [ ]: results = pm . summary ( trace , var_names = [ 'alpha' , 'beta' , 'sigma' ]) results This linear regression example is from the original paper on PyMC3: Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 https://doi.org/10.7717/peerj-cs.55 Top 4. Try this at Home: Example on Mining Disasters We will go over the classical mining disasters from 1851 to 1962 dataset. This example is from the pyMC3 Docs . In [ ]: import pandas as pd disaster_data = pd . Series ([ 4 , 5 , 4 , 0 , 1 , 4 , 3 , 4 , 0 , 6 , 3 , 3 , 4 , 0 , 2 , 6 , 3 , 3 , 5 , 4 , 5 , 3 , 1 , 4 , 4 , 1 , 5 , 5 , 3 , 4 , 2 , 5 , 2 , 2 , 3 , 4 , 2 , 1 , 3 , np . nan , 2 , 1 , 1 , 1 , 1 , 3 , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 3 , 1 , 0 , 3 , 2 , 2 , 0 , 1 , 1 , 1 , 0 , 1 , 0 , 1 , 0 , 0 , 0 , 2 , 1 , 0 , 0 , 0 , 1 , 1 , 0 , 2 , 3 , 3 , 1 , np . nan , 2 , 1 , 1 , 1 , 1 , 2 , 4 , 2 , 0 , 0 , 1 , 4 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 1 ]) fontsize = 12 years = np . arange ( 1851 , 1962 ) plt . figure ( figsize = ( 10 , 5 )) #plt.scatter(years, disaster_data); plt . bar ( years , disaster_data ) plt . ylabel ( 'Disaster count' , size = fontsize ) plt . xlabel ( 'Year' , size = fontsize ); plt . title ( 'Was there a Turning Point in Mining disasters from 1851 to 1962?' , size = 15 ); Building the model Step1: We choose the probability model for our experiment. Occurrences of disasters in the time series is thought to follow a Poisson process with a large rate parameter in the early part of the time series, and from one with a smaller rate in the later part. We are interested in locating the change point in the series, which perhaps is related to changes in mining safety regulations. disasters = pm.Poisson('disasters', rate, observed=disaster_data) We have two rates, early_rate if $t<=s$, and late_rate if $t>s$, where $s$ is the year the switch was made (a.k.a. the switchpoint ). Step2: Choose a prior distributions of the two rates, what we believe the rates were before we observed the data, and the switchpoint. We choose Exponential. early_rate = pm.Exponential('early_rate', 1) The parameters of this model are: Note: Watch for missing values. Missing values are handled transparently by passing a MaskedArray or a pandas.DataFrame. Behind the scenes, another random variable, disasters.missing_values is created to model the missing values. If you pass a np.array with missing values you will get an error. In [ ]: with pm . Model () as disaster_model : # discrete switchpoint = pm . DiscreteUniform ( 'switchpoint' , lower = years . min (), upper = years . max (), testval = 1900 ) # Priors for pre- and post-switch rates number of disasters early_rate = pm . Exponential ( 'early_rate' , 1 ) late_rate = pm . Exponential ( 'late_rate' , 1 ) # our theta - allocate appropriate Poisson rates to years before and after current # switch is an `if` statement in puMC3 rate = pm . math . switch ( switchpoint >= years , early_rate , late_rate ) # our observed data as a likelihood function of the `rate` parameters # shows how we think our data is distributed disasters = pm . Poisson ( 'disasters' , rate , observed = disaster_data ) Model Fitting In [ ]: # there are defaults but we can also more explicitly set the sampling algorithms with disaster_model : # for continuous variables step1 = pm . NUTS ([ early_rate , late_rate ]) # for discrete variables step2 = pm . Metropolis ([ switchpoint , disasters . missing_values [ 0 ]] ) trace = pm . sample ( 10000 , step = [ step1 , step2 ]) # try different number of samples #trace = pm.sample(5000, step=[step1, step2]) Posterior Analysis On the left side plots we notice that our early rate is between 2.5 and 3.5 disasters a year. In the late period it seems to be between 0.6 and 1.2 so definitely lower. The right side plots show the samples we drew to come to our conclusion. In [ ]: pm . traceplot ( trace , [ 'early_rate' , 'late_rate' , 'switchpoint' ], figsize = ( 20 , 10 )); In [ ]: results = pm . summary ( trace , var_names = [ 'early_rate' , 'late_rate' , 'switchpoint' ]) results if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab04/notebook/"},{"title":"Lecture 8: Bayesian 3/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture08/"},{"title":"Lecture 7: Bayesian 2/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture07/"},{"title":"Lab 3: Clustering","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 3 - Clustering Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Content: Chris Tanner and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler from sklearn import preprocessing % matplotlib inline Learning Objectives By the end of this lab, you should be able to: Explain what PCA is and know the differences between it and clustering Understand the common distance metrics (e.g., Euclidean, Manhattan, Hamming) Understand how different clustering algorithms work (e.g., k-means, Hierarchical, DBScan) Explain the trade-offs between the clustering approaches Quantitatively describe the quality clusters' fit, according to different metrics Comfortably cluster any new data that you are presented with This lab corresponds to Lectures #4 and #5 and maps to Homework #2. Table of Contents PCA Refresher Distant Metrics Clustering Algorithms and Measuring Quality of Clusters 1. PCA Refresher Discussion #1 What is PCA? How can it be useful? How to use it ( via sklearn ): # assume we a DataFrame df a. Instantiate a new PCA object : pca_transformer = PCA() b. Fit some data (learns the transformation based on this data) : fitted_pca = pca_transformer.fit(df) c. Transform the data to the reduced dimensions : pca_df = fitted_pca.transform(df) Using two distinct steps (i.e., (b) and (c)) to fit and transform our data allows one the flexibility to transform any dataset according to our learned fit() . Alternatively, if you know you only want to transform a single dataset, you can combine (b) and (c) into one step: Fit and transform : pca_df = pca_transformer.fit_transform(df) Example: In [3]: ms_df = pd . read_csv ( \"../data/multishapes.csv\" )[[ 'x' , 'y' ]] # loads x,y columns of a dataset pca_transformer = PCA () fitted_pca = pca_transformer . fit ( ms_df ) pca_df = fitted_pca . transform ( ms_df ) NOTE: The above PCA transformation is a bit silly because we started with 2 dimensions and are transforming it to 2 dimensions -- no reduction. The data is still transforming the original data by applying a linear transformation so as to capture the most variance, but PCA is even more useful when the original data is high-dimensional. This example was just to remind you of the syntax. Discussion #2: We didn't scale our data before applying PCA. Should we usually do so? Why or why not? 2. Distance Metrics In the picture below, we are concerned with measuring the distance between two points, p and q . (edited from Wikipedia.org) Euclidean Distance: The Euclidean distance measures the shortest path between the two points, navigating through all dimensions: Manhattan Distance: The Manhattan distance measures the cumulative difference between the two points, across all dimensions. Discussion #3: Where have we seen something like this before in CS109A? What are the effects of using one versus another? Hamming Distance (extra credit): If our two elements of comparison can be represented a sequence of discrete items, it can be useful to measure how many of their elements differ. For example: Mahmoud and Mahmood differ by just 1 character and thus have a hamming distance of 1. 10101 and 01101 have a hamming distance of 2. Mary and Barry have a hamming distance of 3 (m->b, y->r, null->y). Note: the last example may seem sub-optimal, as we could transform Mary to Barry by just 2 operations (substituting the M with a B, then adding an 'r'). The very related Levenshtein distance can handle this, and thus tends to be more appropriate for Strings. 3. Clustering Algorithms Question: Why do we care about clustering? How/why is it useful? We will now walk through three clustering algorithms, first discussing them at a high-level, then showing how to implement them with Python libraries. Let's first load and scale our data, so that particular dimensions don't naturally dominate in their contributions in the distant calculations: In [4]: # loads and displays our summary statistics of our data multishapes = pd . read_csv ( \"../data/multishapes.csv\" ) ms_df = multishapes [[ 'x' , 'y' ]] ms_df . describe () Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1100.000000 1100.000000 mean -0.081222 -0.625431 std 0.644967 1.176170 min -1.489180 -3.353462 25% -0.478839 -1.126752 50% -0.132920 -0.297040 75% 0.366072 0.250817 max 1.492208 1.253874 In [5]: # scales our data scaled_df = pd . DataFrame ( preprocessing . scale ( ms_df ), index = multishapes [ 'shape' ], columns = ms_df . columns ) scaled_df . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1.100000e+03 1100.000000 mean 6.459479e-18 0.000000 std 1.000455e+00 1.000455 min -2.183985e+00 -2.320473 25% -6.167723e-01 -0.426425 50% -8.019252e-02 0.279331 75% 6.938298e-01 0.745340 max 2.440659e+00 1.598544 In [6]: # plots our data msplot = scaled_df . plot . scatter ( x = 'x' , y = 'y' , c = 'Black' , title = \"Multishapes data\" , figsize = ( 11 , 8.5 )) msplot . set_xlabel ( \"X\" ) msplot . set_ylabel ( \"Y\" ) plt . show () 3a. k-Means clustering: Table Exercise #1 : With your table, collectively discuss how k-means works. Use a whiteboard, draw a bunch of dots, and walk through each step of how the algorithm works. When you're confident of your answer, speak with a TF to verify its correctness. Code (via sklearn ): In [7]: from sklearn.cluster import KMeans ms_kmeans = KMeans ( n_clusters = 3 , init = 'random' , n_init = 3 , random_state = 109 ) . fit ( scaled_df ) That's it! Just 1 line of code! Now that we've run k-Means, we can look at various attributes of our clusters. Full documenation is here . In [8]: display ( ms_kmeans . cluster_centers_ ) display ( ms_kmeans . labels_ [ 0 : 10 ]) array([[ 1.06623356, 0.17403387], [-0.46343097, 0.54170897], [-0.98352608, -1.57663916]]) array([1, 0, 0, 1, 0, 0, 1, 1, 1, 1], dtype=int32) Plotting Take note of matplotlib's c= argument to color items in the plot, along with our stacking two different plotting functions in the same plot. In [9]: plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = ms_kmeans . labels_ ); plt . scatter ( ms_kmeans . cluster_centers_ [:, 0 ], ms_kmeans . cluster_centers_ [:, 1 ], c = 'r' , marker = 'h' , s = 100 ); Question : Is this expected or did something go wrong? Should we always scale our data before clustering? Lessons: Initializations matter; run multiple times Total Squared distance should never get worse during an update k-Means can struggle with clusters that are close together; they can get lumped into one There's no notion of 'not part of any cluster' or 'part of two clusters' Visualization here Quality of Clusters: Inertia Inertia measures the total squared distance from points to their cluster's centroid. We obviously want this distance to be relatively small. If we increase the number of clusters, it will naturally make the average distance smaller. If every point has its own cluster, then our distance would be 0. That's obviously not an ideal way to cluster. One way to determine a reasonable number of clusters to simply try many different clusterings as we vary k , and each time, measure the overall inertia. In [10]: wss = [] for i in range ( 1 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) wss . append ( fitx . inertia_ ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), wss , 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Inertia' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () Look for the place(s) where distance stops decreasing as much (i.e., the 'elbow' of the curve). It seems that 4 would be a good number of clusters, as a higher k yields diminishing returns. Quality of Clusters: Silhouette Let's say we have a data point $i$, and the cluster it belongs to is referred to as $C(i)$. One way to measure the quality of a cluster $C(i)$ is to measure how close its data points are to each other (within-cluster) compared to nearby, other clusters $C(j)$. This is what Silhouette Scores provide for us. The range is [-1,1]; 0 indicates a point on the decision boundary (equal average closeness to points intra-cluster and out-of-cluster), and negative values mean that datum might be better in a different cluster. Specifically, let $a(i)$ denote the average distance data point $i$ is to the other points in the same cluster: Similarly, we can also compute the average distance that data point $i$ is to all other clusters. The cluster that yields the minimum distance is denoted by $b(i)$: Hopefully our data point $i$ is much closer, on average, to points within its own cluster (i.e., $a(i)$ than it is to its closest neighboring cluster $b(i)$). The silhouette score quantifies this as $s(i)$: NOTE: If data point $i$ belongs to its own cluster (no other points), then the silhouette score is set to 0 (otherwise, $a(i)$ would be undefined). The silhouette score plotted below is the overall average across all points in our dataset. The silhouette_score() function is available in sklearn . We can manually loop over values of K (for applying k-Means algorithm), then plot its silhouette score. This should allow us to make a reasonable choice for selecting the 'optimal' number of clusters. In [11]: from sklearn.metrics import silhouette_score scores = [ 0 ] for i in range ( 2 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) score = silhouette_score ( scaled_df , fitx . labels_ ) scores . append ( score ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), np . array ( scores ), 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Average Silhouette' ) plt . title ( 'Silhouette Scores for varying $k$ clusters' ) plt . show () Visualizing all Silhoutte scores for a particular clustering Below, we borrow from an sklearn example. The second plot may be overkill. The second plot is just the scaled data. It is not a PCA plot If you only need the raw silhouette scores, use the silhouette_samples() function In [12]: from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.cm as cm #modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html def silplot ( X , clusterer , pointlabels = None ): cluster_labels = clusterer . labels_ n_clusters = clusterer . n_clusters # Create a subplot with 1 row and 2 columns fig , ( ax1 , ax2 ) = plt . subplots ( 1 , 2 ) fig . set_size_inches ( 11 , 8.5 ) # The 1st subplot is the silhouette plot # The silhouette coefficient can range from -1, 1 but in this example all # lie within [-0.1, 1] ax1 . set_xlim ([ - 0.1 , 1 ]) # The (n_clusters+1)*10 is for inserting blank space between silhouette # plots of individual clusters, to demarcate them clearly. ax1 . set_ylim ([ 0 , len ( X ) + ( n_clusters + 1 ) * 10 ]) # The silhouette_score gives the average value for all the samples. # This gives a perspective into the density and separation of the formed # clusters silhouette_avg = silhouette_score ( X , cluster_labels ) print ( \"For n_clusters = \" , n_clusters , \", the average silhouette_score is \" , silhouette_avg , \".\" , sep = \"\" ) # Compute the silhouette scores for each sample sample_silhouette_values = silhouette_samples ( X , cluster_labels ) y_lower = 10 for i in range ( 0 , n_clusters + 1 ): # Aggregate the silhouette scores for samples belonging to # cluster i, and sort them ith_cluster_silhouette_values = \\ sample_silhouette_values [ cluster_labels == i ] ith_cluster_silhouette_values . sort () size_cluster_i = ith_cluster_silhouette_values . shape [ 0 ] y_upper = y_lower + size_cluster_i color = cm . nipy_spectral ( float ( i ) / n_clusters ) ax1 . fill_betweenx ( np . arange ( y_lower , y_upper ), 0 , ith_cluster_silhouette_values , facecolor = color , edgecolor = color , alpha = 0.7 ) # Label the silhouette plots with their cluster numbers at the middle ax1 . text ( - 0.05 , y_lower + 0.5 * size_cluster_i , str ( i )) # Compute the new y_lower for next plot y_lower = y_upper + 10 # 10 for the 0 samples ax1 . set_title ( \"The silhouette plot for the various clusters.\" ) ax1 . set_xlabel ( \"The silhouette coefficient values\" ) ax1 . set_ylabel ( \"Cluster label\" ) # The vertical line for average silhouette score of all the values ax1 . axvline ( x = silhouette_avg , color = \"red\" , linestyle = \"--\" ) ax1 . set_yticks ([]) # Clear the yaxis labels / ticks ax1 . set_xticks ([ - 0.1 , 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ]) # 2nd Plot showing the actual clusters formed colors = cm . nipy_spectral ( cluster_labels . astype ( float ) / n_clusters ) ax2 . scatter ( X [:, 0 ], X [:, 1 ], marker = '.' , s = 200 , lw = 0 , alpha = 0.7 , c = colors , edgecolor = 'k' ) xs = X [:, 0 ] ys = X [:, 1 ] if pointlabels is not None : for i in range ( len ( xs )): plt . text ( xs [ i ], ys [ i ], pointlabels [ i ]) # Labeling the clusters centers = clusterer . cluster_centers_ # Draw white circles at cluster centers ax2 . scatter ( centers [:, 0 ], centers [:, 1 ], marker = 'o' , c = \"white\" , alpha = 1 , s = 200 , edgecolor = 'k' ) for i , c in enumerate ( centers ): ax2 . scatter ( c [ 0 ], c [ 1 ], marker = '$ %d $' % int ( i ), alpha = 1 , s = 50 , edgecolor = 'k' ) ax2 . set_title ( \"The visualization of the clustered data.\" ) ax2 . set_xlabel ( \"Feature space for the 1st feature\" ) ax2 . set_ylabel ( \"Feature space for the 2nd feature\" ) plt . suptitle (( \"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters = %d \" % n_clusters ), fontsize = 14 , fontweight = 'bold' ) In [13]: # run k-means with 3 clusters ms_kmeans = KMeans ( n_clusters = 3 , init = 'random' , n_init = 3 , random_state = 109 ) . fit ( scaled_df ) # plot a fancy silhouette plot silplot ( scaled_df . values , ms_kmeans ) For n_clusters = 3, the average silhouette_score is 0.4269854455072775. Exercise #1 : Using the silhouette scores' optimal number of clusters (per the elbow plot above): Fit a new k-Means model with that many clusters Plot the clusters like we originally did with k-means Plot the silhouette scores just like the above cells Which seems like a better clustering (i.e., 3 clusters or the number returned by the elbow plot above)? In [14]: # your code here # %load solutions/exercise1-solution.py Quality of Clusters: Gap Statistic The gap statistic compares within-cluster distances (like in silhouette), but instead of comparing against the second-best existing cluster for that point, it compares our clustering's overall average to the average we'd see if the data were generated at random (we'd expect randomly generated data to not necessarily have any inherit patterns that can be easily clustered). For full details, you can read the original research paper. In essence, the within-cluster distances (in the elbow plot) will go down just becuse we have more clusters. We additionally calculate how much they'd go down on non-clustered data with the same spread as our data and subtract that trend out to produce the plot below. In [15]: from gap_statistic import OptimalK from sklearn.datasets.samples_generator import make_blobs gs_obj = OptimalK () n_clusters = gs_obj ( scaled_df . values , n_refs = 50 , cluster_array = np . arange ( 1 , 15 )) print ( 'Optimal clusters: ' , n_clusters ) Optimal clusters: 14 In [16]: gs_obj . gap_df Out[16]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } n_clusters gap_value gap* ref_dispersion_std diff diff* 0 1.0 -2.485489 -2016.745254 3.197501 -0.048743 327.709212 1 2.0 -2.414842 -1166.422655 2.485720 -0.047171 201.216617 2 3.0 -2.343297 -680.433189 1.740576 0.124498 278.323626 3 4.0 -2.428315 -477.003229 1.929003 0.125511 419.030416 4 5.0 -2.527884 -445.798296 1.003146 -0.098308 221.349425 5 6.0 -2.406904 -331.922050 0.739480 -0.003661 215.946444 6 7.0 -2.376581 -272.577609 0.732733 -0.050279 155.749504 7 8.0 -2.289622 -213.102403 0.879548 0.148301 215.475149 8 9.0 -2.392151 -213.226757 0.991139 -0.066456 126.100923 9 10.0 -2.287996 -168.823140 0.714412 0.113461 167.342742 10 11.0 -2.366609 -167.250275 0.605772 -0.023348 122.170160 11 12.0 -2.306497 -143.993202 0.591874 0.067395 128.290998 12 13.0 -2.332732 -135.467448 0.598679 -0.071119 89.515897 13 14.0 -2.224408 -111.934186 0.509789 NaN NaN In [17]: gs_obj . plot_results () # makes nice plots If we wish to add error bars to help us decide how many clusters to use, the following code displays such: In [18]: def display_gapstat_with_errbars ( gap_df ): gaps = gap_df [ \"gap_value\" ] . values diffs = gap_df [ \"diff\" ] err_bars = np . zeros ( len ( gap_df )) err_bars [ 1 :] = diffs [: - 1 ] - gaps [: - 1 ] + gaps [ 1 :] plt . scatter ( gap_df [ \"n_clusters\" ], gap_df [ \"gap_value\" ]) plt . errorbar ( gap_df [ \"n_clusters\" ], gap_df [ \"gap_value\" ], yerr = err_bars , capsize = 6 ) plt . xlabel ( \"Number of Clusters\" ) plt . ylabel ( \"Gap Statistic\" ) plt . show () display_gapstat_with_errbars ( gs_obj . gap_df ) For more information about the gap_stat package, please see the full documentation here . 3b. Agglomerative Clustering Table Exercise #2 : With your table, collectively discuss how agglomerative clustering works. Use a whiteboard, draw a bunch of dots, and walk through each step of how the algorithm works. When you're confident of your answer, speak with a TF to verify its correctness. Code (via scipy ): There are many different cluster-merging criteria, one of which is Ward's criteria. Ward's optimizes having the lowest total within-cluster distances, so it merges the two clusters that will harm this objective least. scipy 's agglomerative clustering function implements Ward's method. In [19]: import scipy.cluster.hierarchy as hac from scipy.spatial.distance import pdist plt . figure ( figsize = ( 11 , 8.5 )) dist_mat = pdist ( scaled_df , metric = \"euclidean\" ) ward_data = hac . ward ( dist_mat ) hac . dendrogram ( ward_data ); Discussion #4 : How do you read a plot like the above? What are valid options for number of clusters, and how can you tell? Are some more valid than others? Does it make sense to compute silhouette scores for an agglomerative clustering? If we wanted to compute silhouette scores, what would we need for this to be possible? Lessons: It's expensive: O(n&#94;3) time complexity and O(n&#94;2) space complexity. Many choices for linkage criteria Every node gets clustered (no child left behind) In [20]: # %load solutions/discussion4-solution.py 3c. DBscan Clustering DBscan uses an intuitive notion of denseness to define clusters, rather than defining clusters by a central point as in k-means. Code (via sklearn ): DBscan is implemented in good 'ol sklearn, but there aren't great automated tools for searching for the optimal epsilon parameter. For full documentation, please visit this page In [21]: from sklearn.cluster import DBSCAN plt . figure ( figsize = ( 11 , 8.5 )) fitted_dbscan = DBSCAN ( eps = 0.2 ) . fit ( scaled_df ) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_dbscan . labels_ ); Note: the dark purple dots are not clustered with anything else. They are lone singletons. You can validate such by setting epsilon to a very small value, and increase the min_samples to a high value. Under these conditions, nothing would cluster, and yet all dots become dark purple. Exercise #2 : Experiment with the above code by changing its epsilon value and the min_samples (what is the default value for it, since the above code doesn't specify a value?) Instead of just empirically observing how the epsilon value affects the clustering (which would be very costly for large, high-dimensional data), we can also inspect how far each data point is to its $N&#94;{th}$ closest neighbor: In [22]: from sklearn.neighbors import NearestNeighbors # x-axis is each individual data point, numbered by an artificial index # y-axis is the distance to its 2nd closest neighbor def plot_epsilon ( df , min_samples ): fitted_neigbors = NearestNeighbors ( n_neighbors = min_samples ) . fit ( df ) distances , indices = fitted_neigbors . kneighbors ( df ) dist_to_nth_nearest_neighbor = distances [:, - 1 ] plt . plot ( np . sort ( dist_to_nth_nearest_neighbor )) plt . xlabel ( \"Index \\n (sorted by increasing distances)\" ) plt . ylabel ( \" {} -NN Distance (epsilon)\" . format ( min_samples - 1 )) plt . tick_params ( right = True , labelright = True ) In [23]: plot_epsilon ( scaled_df , 3 ) Lessons: Can cluster non-linear relationships very well; potential for more natural, arbritrarily shaped groupings Does not require specifying the # of clusters (i.e., k ); the algorithm determines such Robust to outliers Very sensitive to the parameters (requires strong knowledge of the data) Doesn't guarantee that every (or ANY) item will be clustered Discussion #5 : When should we prefer one type of clustering over another? Should we always just try all of them? Imagine you work at Spotify and you want to create personalized playlists for each person. One could imagine a dataset exists whereby each row is a particular song, and the columns are features (e.g., tempo (BPM), average vocal frequency, amount of bass, sentiment of lyrics, duration in seconds, etc). Let's use clustering to group one's catalog of favorite music, which will serve as disjoint starting points for suggesting future songs. Specifically, imagine that you've 'liked' 500 songs on Spotify so far, and your recommendation algorithm needs to cluster those 500 songs. Would you first experiment with k-Means, Agglomerative, or DBScan? Why? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab03/notebook/"},{"title":"Lecture 6: Bayesian 1/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture06/"},{"title":"Lab 3: Clustering","text":"Notebooks Lab 3: Clustering Solutions These solutions can be loaded directly into the Lab 3 notebook. For this to work they need to be placed in a solutions directory in the same directory as the notebook. Exercise 1 Solutions Discussion 4 Solutions","tags":"labs","url":"labs/lab03/"},{"title":"Lecture 5: Unsupervised Learning - Clustering 2","text":"Slides This lecture is only available to registered students Lecture 4-5 Slides [PDF] Notebooks Clustering Notebook Data These data files are required for running the clustering notebook faithful.csv multishapes.csv USArrests.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 cs109b.yml Zip This zip includes slides, notebook, all data files, and the YAML cs109b_lec4-5_clustering.zip","tags":"lectures","url":"lectures/lecture05/"},{"title":"Lecture 4: Unsupervised Learning - Clustering 1","text":"Slides This lecture is only available to registered students Lecture 4-5 Slides [PDF] Notebooks Clustering Notebook Data These data files are required for running the clustering notebook faithful.csv multishapes.csv USArrests.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 cs109b.yml Zip This zip includes slides, notebook, all data files, and the YAML cs109b_lec4-5_clustering.zip","tags":"lectures","url":"lectures/lecture04/"},{"title":"Lab 2: Smoothers & GAMs","text":"Notebooks Lab 2: Smooths & GAMs","tags":"labs","url":"labs/lab02/"},{"title":"Lab 2: Smoothers & GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models - Model Fitting Spring 2020 Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Content: Eleni Kaxiras and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np from scipy.interpolate import interp1d import matplotlib.pyplot as plt import pandas as pd % matplotlib inline Learning Goals By the end of this lab, you should be able to: Understand how to implement GAMs with the Python package pyGAM Learn about the practical aspects of Splines and how to use them. This lab corresponds to lectures 1, 2, and 3 and maps to homework 1. Table of Contents 1 - Overview - A Top View of LMs, GLMs, and GAMs to set the stage 2 - A review of Linear Regression with statsmodels . What are those weird formulas? 3 - Splines 4 - Generative Additive Models with pyGAM 5 - Smooting Splines using pyGAM Overview Linear Models (LM), Generalized Linear Models (GLMs), Generalized Additive Models (GAMs), Splines, Natural Splines, Smoothing Splines! So many definitions. Let's try and work through an example for each of them so we can better understand them. image source: Dani Servén Marín (one of the developers of pyGAM) A - Linear Models First we have the Linear Models which you know from 109a. These models are linear in the coefficients. Very interpretable but suffer from high bias because let's face it, few relationships in life are linear. Simple Linear Regression (defined as a model with one predictor) as well as Multiple Linear Regression (more than one predictors) are examples of LMs. Polynomial Regression extends the linear model by adding terms that are still linear for the coefficients but non-linear when it somes to the predictiors which are now raised in a power or multiplied between them. $$ \\begin{aligned} y = \\beta{_0} + \\beta{_1}{x_1} & \\mbox{(simple linear regression)}\\\\ y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_2} + \\beta{_3}{x_3} & \\mbox{(multiple linear regression)}\\\\ y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_1&#94;2} + \\beta{_3}{x_3&#94;3} & \\mbox{(polynomial regression)}\\\\ \\end{aligned} $$ Discussion What does it mean for a model to be interpretable ? Are linear regression models interpretable? Are random forests? What about Neural Networks such as FFNs and CNNs? Do we always want interpretability? Describe cases where we do and cases where we do not care. B - Generalized Linear Models (GLMs) $$ \\begin{aligned} y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_2} + \\beta{_3}{x_3} \\end{aligned} $$ Generalized Linear Models is a term coined in the early 1970s by Nelder and Wedderburn for a class of models that includes both Linear Regression and Logistic Regression. A GLM fits one coefficient per feature (predictor). C - Generalized Additive Models (GAMs) Hastie and Tidshirani coined the term Generalized Additive Models in 1986 for a class of non-linear extensions to Generalized Linear Models. $$ \\begin{aligned} y = \\beta{_0} + f_1\\left(x_1\\right) + f_2\\left(x_2\\right) + f_3\\left(x_3\\right) \\\\ y = \\beta{_0} + f_1\\left(x_1\\right) + f_2\\left(x_2, x_3\\right) + f_3\\left(x_3\\right) & \\mbox{(with interaction terms)} \\end{aligned} $$ In practice we add splines and regularization via smoothing penalties to our GLMs. Decision Trees also fit in this category. image source: Dani Servén Marín D - Basis Functions In our models we can use various types of functions as \"basis\". Monomials such as $x&#94;2$, $x&#94;4$ ( Polynomial Regression ) Sigmoid functions (neural networks) Fourier functions Wavelets Regression splines which we will look at shortly. Discussion Where does polynomial regression fit in all this? Answer: GLMs include Polynomial Regression so the graphic above should really include curved lines, not just straight... Implementation 1 - Linear/Polynomial Regression We will use the diabetes dataset. Variables are: subject: subject ID number age: age diagnosed with diabetes acidity: a measure of acidity called base deficit Response: y: natural log of serum C-peptide concentration Original source is Sockett et al. (1987) mentioned in Hastie and Tibshirani's book \"Generalized Additive Models\". Reading data and (some) exploring in Pandas: In [3]: diab = pd . read_csv ( \"../data/diabetes.csv\" ) diab . head () Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } subject age acidity y 0 1 5.2 -8.1 4.8 1 2 8.8 -16.1 4.1 2 3 10.5 -0.9 5.2 3 4 10.6 -7.8 5.5 4 5 10.4 -29.0 5.0 In [4]: diab . dtypes Out[4]: subject int64 age float64 acidity float64 y float64 dtype: object In [5]: diab . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } subject age acidity y count 43.000000 43.000000 43.000000 43.000000 mean 22.000000 9.032558 -8.148837 4.746512 std 12.556539 4.022539 7.123080 0.720565 min 1.000000 0.900000 -29.000000 3.000000 25% 11.500000 5.500000 -12.700000 4.450000 50% 22.000000 10.400000 -7.800000 4.900000 75% 32.500000 11.850000 -2.000000 5.100000 max 43.000000 15.600000 -0.200000 6.600000 Plotting with matplotlib: In [6]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear/Polynomial regression with statsmodels. As you remember from 109a, we have two tools for Linear Regression: statsmodels https://www.statsmodels.org/stable/regression.html , and sklearn https://scikit-learn.org/stable/index.html Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. using sklearn 's PolynomialFeatures). statsmodels allows users to fit statistical models using R-style formulas . They build the target value and design matrix for you. # our target variable is 'Lottery', while 'Region' is a categorical predictor df = dta.data[['Lottery', 'Literacy', 'Wealth', 'Region']] formula='Lottery ~ Literacy + Wealth + C(Region) + Literacy * Wealth' For more on these formulas see: https://www.statsmodels.org/stable/examples/notebooks/generated/formulas.html https://patsy.readthedocs.io/en/latest/overview.html In [7]: import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Let's build a dataframe to predict values on (sometimes this is just the test or validation set). Very useful for making pretty plots of the model predictions - predict for TONS of values, not just whatever's in the training set. In [8]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Out[8]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age 0 0.000000 1 0.161616 2 0.323232 3 0.484848 4 0.646465 Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [9]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Out[9]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean mean_se mean_ci_lower mean_ci_upper obs_ci_lower obs_ci_upper 0 3.996031 0.244590 3.502071 4.489991 2.600828 5.391235 1 4.009459 0.240929 3.522892 4.496026 2.616856 5.402063 2 4.022887 0.237280 3.543691 4.502084 2.632842 5.412932 3 4.036315 0.233642 3.564466 4.508165 2.648786 5.423845 4 4.049743 0.230016 3.585216 4.514270 2.664687 5.434800 Plot the model and error bars In [10]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars. You can either take Route1 : Build a design df with a column for each of age , age**2 , age**3 , or Route2 : Just edit the formula In [11]: # your answer here In [12]: # %load ../solutions/exercise1-1.py fit2_lm = sm . ols ( formula = \"y ~ age + np.power(age, 2) + np.power(age, 3)\" , data = diab ) . fit () poly_predictions = fit2_lm . get_prediction ( predict_df ) . summary_frame () poly_predictions . head () Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean mean_se mean_ci_lower mean_ci_upper obs_ci_lower obs_ci_upper 0 2.740481 0.508197 1.712556 3.768406 1.156238 4.324724 1 2.846265 0.472858 1.889819 3.802710 1.307439 4.385090 2 2.948751 0.439558 2.059661 3.837841 1.450860 4.446641 3 3.047990 0.408303 2.222119 3.873860 1.586737 4.509242 4 3.144031 0.379104 2.377221 3.910841 1.715328 4.572735 In [13]: # %load ../solutions/exercise1-2.py ax2 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares cubic fit\" ) ax2 . set_xlabel ( \"Age at Diagnosis\" ) ax2 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean' ], color = \"green\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); Ed exercise This example was similar with the Ed exercise. Open it in Ed and let's go though it. 2 - Piecewise Polynomials a.k.a. Splines Splines are a type of piecewise polynomial interpolant. A spline of degree k is a piecewise polynomial that is continuously differentiable k − 1 times. Splines are the basis of CAD software and vector graphics including a lot of the fonts used in your computer. The name \"spline\" comes from a tool used by ship designers to draw smooth curves. Here is the letter $epsilon$ written with splines: font idea inspired by David Knezevic (AM205) If the degree is 1 then we have a Linear Spline. If it is 3 then we have a Cubic spline. It turns out that cubic splines because they have a continous 2nd derivative at the knots are very smoothly looking to the eye. We do not need higher order than that. The Cubic Splines are usually Natural Cubic Splines which means they have the added constrain of the end points' second derivative = 0. We will use the CubicSpline and the B-Spline as well as the Linear Spline. scipy.interpolate See all the different splines that scipy.interpolate has to offer: https://docs.scipy.org/doc/scipy/reference/interpolate.html Let's use the simplest form which is interpolate on a set of points and then find the points between them. In [14]: from scipy.interpolate import splrep , splev from scipy.interpolate import BSpline , CubicSpline from scipy.interpolate import interp1d # define the range of the function a = - 1 b = 1 # define the number of knots num_knots = 10 x = np . linspace ( a , b , num_knots ) # define the function we want to approximate y = 1 / ( 1 + 25 * ( x ** 2 )) # make a linear spline linspline = interp1d ( x , y ) # sample at these points to plot xx = np . linspace ( a , b , 1000 ) yy = 1 / ( 1 + 25 * ( xx ** 2 )) plt . plot ( x , y , '*' ) plt . plot ( xx , yy , label = 'true function' ) plt . plot ( xx , linspline ( xx ), label = 'linear spline' ); plt . legend (); Exercise 2 The Linear interpolation does not look very good. Fit a Cubic Spline and plot along the Linear to compare. In [15]: # your answer here In [16]: # %load ../solutions/exercise2.py # define the range of the function a = - 1 b = 1 # define the knots num_knots = 10 x = np . linspace ( a , b , num_knots ) # define the function we want to approximate y = 1 / ( 1 + 25 * ( x ** 2 )) # make the Cubic spline cubspline = CubicSpline ( x , y ) # OR make a linear spline linspline = interp1d ( x , y ) # plot xx = np . linspace ( a , b , 1000 ) yy = 1 / ( 1 + 25 * ( xx ** 2 )) plt . plot ( xx , yy , label = 'true function' ) plt . plot ( x , y , '*' ) plt . plot ( xx , linspline ( xx ), label = 'linear' ); plt . plot ( xx , cubspline ( xx ), label = 'cubic' ); plt . legend (); Discussion Change the number of knots to 100 and see what happens. What would happen if we run a polynomial model of degree equal to the number of knots (a global one as in polynomial regression, not a spline)? What makes a spline 'Natural'? B-Splines A B-splines (Basis Splines) is defined by a set of control points and a set of basis functions that intepolate (fit) the function between these points. By choosing to have no smoothing factor we forces the final B-spline to pass though all the points. If, on the other hand, we set a smothing factor, our function is more of an approximation with the control points as \"guidance\". The latter produced a smoother curve which is prefferable for drawing software. For more on Splines see: https://en.wikipedia.org/wiki/B-spline ) We will use scipy.splrep to calulate the coefficients for the B-Spline and draw it. B-Spline with no smooting In [17]: from scipy.interpolate import splev , splrep x = np . linspace ( 0 , 10 , 10 ) y = np . sin ( x ) t , c , k = splrep ( x , y ) # (tck) is a tuple containing the vector of knots, coefficients, degree of the spline print ( t , c , k ) # define the points to plot on (x2) x2 = np . linspace ( 0 , 10 , 200 ) y2 = BSpline ( t , c , k ) plt . plot ( x , y , 'o' , x2 , y2 ( x2 )) plt . show () [ 0. 0. 0. 0. 2.22222222 3.33333333 4.44444444 5.55555556 6.66666667 7.77777778 10. 10. 10. 10. ] [-4.94881722e-18 8.96543619e-01 1.39407154e+00 -2.36640266e-01 -1.18324030e+00 -8.16301228e-01 4.57836125e-01 1.48720677e+00 1.64338775e-01 -5.44021111e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00] 3 B-Spline with smooting factor s In [18]: from scipy.interpolate import splev , splrep x = np . linspace ( 0 , 10 , 10 ) y = np . sin ( x ) s = 0.5 # add smooting factor task = 0 # task needs to be set to 0, which represents: # we are specifying a smoothing factor and thus only want # splrep() to find the optimal t and c t , c , k = splrep ( x , y , task = task , s = s ) # define the points to plot on (x2) x2 = np . linspace ( 0 , 10 , 200 ) y2 = BSpline ( t , c , k ) plt . plot ( x , y , 'o' , x2 , y2 ( x2 )) plt . show () B-Spline with given knots In [19]: x = np . linspace ( 0 , 10 , 100 ) y = np . sin ( x ) knots = np . quantile ( x , [ 0.25 , 0.5 , 0.75 ]) print ( knots ) [2.5 5. 7.5] In [20]: # calculate the B-Spline t , c , k = splrep ( x , y , t = knots ) In [21]: curve = BSpline ( t , c , k ) curve Out[21]: In [22]: plt . scatter ( x = x , y = y , c = 'grey' , alpha = 0.4 ) yknots = np . sin ( knots ) plt . scatter ( knots , yknots , c = 'r' ) plt . plot ( x , curve ( x )) plt . show () Ed exercise This example was similar with the Ed exercise. Open it in Ed and let's go though it. 3 - GAMs https://readthedocs.org/projects/pygam/downloads/pdf/latest/ A - Classification in pyGAM Let's get our (multivariate!) data, the kyphosis dataset, and the LogisticGAM model from pyGAM to do binary classification. kyphosis - wherther a particular deformation was present post-operation age - patient's age in months number - the number of vertebrae involved in the operation start - the number of the topmost vertebrae operated on In [23]: kyphosis = pd . read_csv ( \"../data/kyphosis.csv\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Kyphosis Age Number Start 0 absent 71 3 5 1 absent 158 3 14 2 present 128 4 5 3 absent 2 5 1 4 absent 1 4 15 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Kyphosis Age Number Start count 81 81.000000 81.000000 81.000000 unique 2 NaN NaN NaN top absent NaN NaN NaN freq 64 NaN NaN NaN mean NaN 83.654321 4.049383 11.493827 std NaN 58.104251 1.619423 4.883962 min NaN 1.000000 2.000000 1.000000 25% NaN 26.000000 3.000000 9.000000 50% NaN 87.000000 4.000000 13.000000 75% NaN 130.000000 5.000000 16.000000 max NaN 206.000000 10.000000 18.000000 Kyphosis object Age int64 Number int64 Start int64 dtype: object In [24]: # convert the outcome in a binary form, 1 or 0 kyphosis = pd . read_csv ( \"../data/kyphosis.csv\" ) kyphosis [ \"outcome\" ] = 1 * ( kyphosis [ \"Kyphosis\" ] == \"present\" ) kyphosis . describe () Out[24]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Number Start outcome count 81.000000 81.000000 81.000000 81.000000 mean 83.654321 4.049383 11.493827 0.209877 std 58.104251 1.619423 4.883962 0.409758 min 1.000000 2.000000 1.000000 0.000000 25% 26.000000 3.000000 9.000000 0.000000 50% 87.000000 4.000000 13.000000 0.000000 75% 130.000000 5.000000 16.000000 0.000000 max 206.000000 10.000000 18.000000 1.000000 In [25]: from pygam import LogisticGAM , s , f , l X = kyphosis [[ \"Age\" , \"Number\" , \"Start\" ]] y = kyphosis [ \"outcome\" ] kyph_gam = LogisticGAM () . fit ( X , y ) Outcome dependence on features To help us see how the outcome depends on each feature, pyGAM has the partial_dependence() function. pdep, confi = kyph_gam.partial_dependence(term=i, X=XX, width=0.95) For more on this see the : https://pygam.readthedocs.io/en/latest/api/logisticgam.html In [26]: res = kyph_gam . deviance_residuals ( X , y ) for i , term in enumerate ( kyph_gam . terms ): if term . isintercept : continue XX = kyph_gam . generate_X_grid ( term = i ) pdep , confi = kyph_gam . partial_dependence ( term = i , X = XX , width = 0.95 ) pdep2 , _ = kyph_gam . partial_dependence ( term = i , X = X , width = 0.95 ) plt . figure () plt . scatter ( X . iloc [:, term . feature ], pdep2 + res ) plt . plot ( XX [:, term . feature ], pdep ) plt . plot ( XX [:, term . feature ], confi , c = 'r' , ls = '--' ) plt . title ( X . columns . values [ term . feature ]) plt . show () Notice that we did not specify the basis functions in the .fit(). Cool. pyGAM figures them out for us by using $s()$ (splines) for numerical variables and $f()$ for categorical features. If this is not what we want we can manually specify the basis functions, as follows: In [27]: kyph_gam = LogisticGAM ( s ( 0 ) + s ( 1 ) + s ( 2 )) . fit ( X , y ) In [28]: res = kyph_gam . deviance_residuals ( X , y ) for i , term in enumerate ( kyph_gam . terms ): if term . isintercept : continue XX = kyph_gam . generate_X_grid ( term = i ) pdep , confi = kyph_gam . partial_dependence ( term = i , X = XX , width = 0.95 ) pdep2 , _ = kyph_gam . partial_dependence ( term = i , X = X , width = 0.95 ) plt . figure () plt . scatter ( X . iloc [:, term . feature ], pdep2 + res ) plt . plot ( XX [:, term . feature ], pdep ) plt . plot ( XX [:, term . feature ], confi , c = 'r' , ls = '--' ) plt . title ( X . columns . values [ term . feature ]) plt . show () B - Regression in pyGAM For regression problems, we can use a linearGAM model. For this part we will use the wages dataset. https://pygam.readthedocs.io/en/latest/api/lineargam.html The wages dataset Let's inspect another dataset that is included in pyGAM that notes the wages of people based on their age, year of employment and education. In [29]: # from the pyGAM documentation from pygam import LinearGAM , s , f from pygam.datasets import wage X , y = wage ( return_X_y = True ) ## model gam = LinearGAM ( s ( 0 ) + s ( 1 ) + f ( 2 )) gam . gridsearch ( X , y ) ## plotting plt . figure (); fig , axs = plt . subplots ( 1 , 3 ); titles = [ 'year' , 'age' , 'education' ] for i , ax in enumerate ( axs ): XX = gam . generate_X_grid ( term = i ) ax . plot ( XX [:, i ], gam . partial_dependence ( term = i , X = XX )) ax . plot ( XX [:, i ], gam . partial_dependence ( term = i , X = XX , width =. 95 )[ 1 ], c = 'r' , ls = '--' ) if i == 0 : ax . set_ylim ( - 30 , 30 ) ax . set_title ( titles [ i ]); 100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time: 0:00:00 Discussion What are your observations from the plots above? 4 - Smoothing Splines using pyGAM For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point. Let's see how this smoothing works in pyGAM . We start by creating some arbitrary data and fitting them with a GAM. In [30]: X = np . linspace ( 0 , 10 , 500 ) y = np . sin ( X * 2 * np . pi ) * X + np . random . randn ( len ( X )) plt . scatter ( X , y ); In [31]: # let's try a large lambda first and lots of splines gam = LinearGAM ( lam = 1e6 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); We see that the large $\\lambda$ forces a straight line, no flexibility. Let's see now what happens if we make it smaller. In [32]: # let's try a smaller lambda gam = LinearGAM ( lam = 1e2 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); There is some curvature there but still not a good fit. Let's try no penalty. That should have the line fit exactly. In [33]: # no penalty, let's try a 0 lambda gam = LinearGAM ( lam = 0 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ) plt . plot ( XX , gam . predict ( XX )) Out[33]: [ ] Yes, that is good. Now let's see what happens if we lessen the number of splines. The fit should not be as good. In [34]: # no penalty, let's try a 0 lambda gam = LinearGAM ( lam = 0 , n_splines = 10 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); Indeed. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab02/notebook/"},{"title":"Lecture 3: Smoothers and Additive 3/3","text":"Slides This lecture is only available to registered students Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture03/"},{"title":"Lecture 2: Smoothers and Additive 2/3","text":"Slides This lecture is only available to registered students Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture02/"},{"title":"Lecture 1: Introduction + Smoothers and Additive 1/3","text":"Slides This lecture is only available to registered students Introduction [PPTX] Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture01/"},{"title":"Lab 1: Getting Started","text":"Notebooks Lab 1: Getting Started Additional Files YAML file to create local Conda environment Forking a Repo Guide","tags":"labs","url":"labs/lab01/"},{"title":"Lab 1: Getting Started","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 1 - Introduction and Setup Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Contributors: Will Claybaugh and Eleni Kaxiras In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np #import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Learning Goals The purpose of this lab is to get you up to speed with what you will need to run the code for CS109b. 1. Getting Class Material Option 1A: Cloning the class repo and then copying the contents in a different directory so you can make changes. Open the Terminal in your computer and go to the Directory where you want to clone the repo. Then run git clone https://github.com/Harvard-IACS/2020-CS109B.git If you have already cloned the repo, go inside the '/2020-CS109B/' directory and run git pull If you change the notebooks and then run git pull your changes will be overwritten. So create a playground folder and copy the folder with the notebook with which you want to work there. Option 1B: Forking the class repo To get access to the code used in class you will need to clone the class repo: https://github.com/Harvard-IACS/2020-CS109B In order not to lose any changes you have made when updating the content (pulling) from the main repo, a good practice is to fork the repo locally. For more on this see Maddy Nakada's notes: How to Fork a Repo . NOTE: While Fork is a proper way to handle local changes, it doesn't magically solve everything -- if you edit a file that originated from our course repo (e.g., a HW notebook), and later pull from our 'upstream' repo again, any changes you make will require resolving merge conflict(s) . Thus, if you want to safetly and easily preserve any of your changes, we recommend renaming your files and/or copying them into an independent directory within your repo. You will need this year's repo: https://github.com/Harvard-IACS/2020-CS109B.git 2. Running code: Option 2A: Managing Local Resources (supported by cs109b) Use Virtual Environments: I cannot stress this enough! Isolating your projects inside specific environments helps you manage dependencies and therefore keep your sanity. You can recover from mess-ups by simply deleting an environment. Sometimes certain installation of libraries conflict with one another. In order of isolation here is what you can do: a) set up a virtual environment, b) set up a virtual machine. The two most popular tools for setting up environments are: conda (a package and environment manager) pip (a Python package manager) with virtualenv (a tool for creating environments) We recommend using conda package installation and environments. conda installs packages from the Anaconda Repository and Anaconda Cloud, whereas pip installs packages from PyPI. Even if you are using conda as your primary package installer and are inside a conda environment, you can still use pip install for those rare packages that are not included in the conda ecosystem. See here for more details on how to manage Conda Environments . Exercise 1: Clone of Fork the CS109b git repository. Use the cs109b.yml file to create an environment: $ cd /2020-CS109B/content/labs/lab01/ $ conda env create -f cs109b.yml $ conda activate cs109b We have included the packages that you will need in the cs109b.yml file. It should be in the same directory as this notebook. Option 2B: Using Cloud Resources (optional) Using SEAS JupyterHub (supported by cs109b) Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class, accessible via the 'JupyterHub' menu link in Canvas. Between now and March 1, each student will have their own t2.medium AWS ec2 instance with 4GB CPU RAM, and 2 vCPUs. After March 1st the instances will be upgraded to p2.xlarge AWS ec2 instances with a GPU, 61GB CPU RAM, 12GB GPU RAM, 10gB disk space, and 4 vCPUs. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are to use it with prudence; also it is not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Using Google Colab (on your own) Google's Colab platform https://colab.research.google.com/ offers a GPU enviromnent to test your ideas, it's fast, free, with the only caveat that your files persist only for 12 hours. The solution is to keep your files in a repository and just clone it each time you use Colab. Using AWS in the Cloud (on your own) For those of you who want to have your own machines in the Cloud to run whatever you want, Amazon Web Services is a (paid) solution. For more see: https://docs.aws.amazon.com/polly/latest/dg/setting-up.html Remember, AWS is a paid service so if you let your machine run for days you will get charged! source: maybe Stanford's cs231n via Medium 3. Ensuring everything is installed correctly Packages we will need for this class Clustering : Sklearn - https://scikit-learn.org/stable/ scipy - https://www.scipy.org gap_statistic (by Miles Granger) - https://anaconda.org/milesgranger/gap-statistic/notebook Smoothing : statsmodels - https://www.statsmodels.org/ statsmodels examples: https://www.statsmodels.org/stable/examples/index.html#regression scipy pyGAM - https://pygam.readthedocs.io/en/latest/ Bayes : pymc3 - https://docs.pymc.io Neural Networks : keras - https://www.tensorflow.org/guide/keras We will test that these packages load correctly in our environment. In [12]: from sklearn import datasets iris = datasets . load_iris () digits = datasets . load_digits () digits . target # you should see [0, 1, 2, ..., 8, 9, 8] Out[12]: array([0, 1, 2, ..., 8, 9, 8]) In [13]: from scipy import misc import matplotlib.pyplot as plt face = misc . face () plt . imshow ( face ) plt . show () # you should see a racoon In [14]: import statsmodels.api as sm import statsmodels.formula.api as smf # Load data dat = sm . datasets . get_rdataset ( \"Guerry\" , \"HistData\" ) . data dat . head () Out[14]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dept Region Department Crime_pers Crime_prop Literacy Donations Infants Suicides MainCity ... Crime_parents Infanticide Donation_clergy Lottery Desertion Instruction Prostitutes Distance Area Pop1831 0 1 E Ain 28870 15890 37 5098 33120 35039 2:Med ... 71 60 69 41 55 46 13 218.372 5762 346.03 1 2 N Aisne 26226 5521 51 8901 14572 12831 2:Med ... 4 82 36 38 82 24 327 65.945 7369 513.00 2 3 C Allier 26747 7925 13 10973 17044 114121 2:Med ... 46 42 76 66 16 85 34 161.927 7340 298.26 3 4 E Basses-Alpes 12935 7289 46 2733 23018 14238 1:Sm ... 70 12 37 80 32 29 2 351.399 6925 155.90 4 5 E Hautes-Alpes 17488 8174 69 6962 23076 16171 1:Sm ... 22 23 64 79 35 7 1 320.280 5549 129.10 5 rows × 23 columns In [6]: from pygam import PoissonGAM , s , te from pygam.datasets import chicago from mpl_toolkits.mplot3d import Axes3D X , y = chicago ( return_X_y = True ) gam = PoissonGAM ( s ( 0 , n_splines = 200 ) + te ( 3 , 1 ) + s ( 2 )) . fit ( X , y ) In [7]: XX = gam . generate_X_grid ( term = 1 , meshgrid = True ) Z = gam . partial_dependence ( term = 1 , X = XX , meshgrid = True ) ax = plt . axes ( projection = '3d' ) ax . plot_surface ( XX [ 0 ], XX [ 1 ], Z , cmap = 'viridis' ) Out[7]: In [ ]: import pymc3 as pm print ( 'Running PyMC3 v {} ' . format ( pm . __version__ )) # you should see 'Running on PyMC3 v3.8' Plotting matplotlib and seaborn matplotlib seaborn: statistical data visualization . seaborn works great with pandas . It can also be customized easily. Here is the basic seaborn tutorial: Seaborn tutorial . Plotting a function of 2 variables using contours In optimization, our objective function will often be a function of two or more variables. While it's hard to visualize a function of more than 3 variables, it's very informative to plot one of 2 variables. To do this we use contours. First we define the $x1$ and $x2$ variables and then construct their pairs using meshgrid . In [21]: import seaborn as sn In [11]: x1 = np . linspace ( - 0.1 , 0.1 , 50 ) x2 = np . linspace ( - 0.1 , 0.1 , 100 ) xx , yy = np . meshgrid ( x1 , x2 ) z = np . sqrt ( xx ** 2 + yy ** 2 ) plt . contour ( x1 , x2 , z ); We will be using tensorflow and keras TensorFlow is a framework for representing complicated ML algorithms and executing them in any platform, from a phone to a distributed system using GPUs. Developed by Google Brain, TensorFlow is used very broadly today. Keras , is a high-level API used for fast prototyping, advanced research, and production. We will use tf.keras which is TensorFlow's implementation of the keras API. Exercise 2: Run the following cells to make sure you have the basic libraries to do deep learning In [3]: from __future__ import absolute_import , division , print_function , unicode_literals # TensorFlow and tf.keras import tensorflow as tf from tensorflow.keras import layers from tensorflow.keras import models from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential from tensorflow.keras.regularizers import l2 tf . keras . backend . clear_session () # For easy reset of notebook state. print ( tf . __version__ ) # You should see a >2.0.0 here! print ( tf . keras . __version__ ) 2.0.0 2.2.4-tf In [8]: # Checking if our machine has NVIDIA GPUs. Mine does not.. hasGPU = tf . config . experimental_list_devices () print ( f 'My computer has the following GPUs: {hasGPU} ' ) My computer has the following GPUs: ['/job:localhost/replica:0/task:0/device:CPU:0'] DELIVERABLES Submit this notebook to Canvas with the output produced . Describe below the environment in which you will be working, e.g. I have installed the environment needed locally and have tested all the code in this notebook OR/and I am using JupyterHub ---------------- your answer here if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab01/notebook/"}]}