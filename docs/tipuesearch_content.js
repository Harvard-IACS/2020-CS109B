var tipuesearch = {"pages":[{"title":"Calendars","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Select full calendar or weekly schedule tab from the spreadsheet below.","tags":"pages","url":"pages/calendars.html"},{"title":"FAQ","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } General Do I have access to the video recorded materials if I am not an Extension School student? Yes. All CS109B students have access to all recorded videos (lectures, labs, & advanced sections) as well as streaming video for labs. Extension School students also have access to live-streaming of lectures due to the nature of some members of the student body of that school. If you have any issues accessing the video content, please send an email to our helpline with your name and HUID. Can I access live streaming? Only Harvard Extension School students have access to live-streaming of CS109B lectures, and advanced sections. Can I make-up quizzes? No. Only 50% of quiz grades will count towards your final grade. This policy is to reduce stress and is in place so that missing a quiz on occasion should not affect your final grade. Auditors Can I audit this course? What can I and cannot do? Yes, you are welcome to audit this course and attend lecture, sections and lab. However, auditors should not submit HWs or participate in projects, and should refrain from using any course TF resources that are destined and created for our registered students like Ed or JupyterHub. Extension School I am an Extension School Student, can I take the quizzes? And do they count towards my grade? All CS109B students have access to quizzes. If you are a Harvard Extension School student, the quizzes will not be considered towards your final grade. The official quiz will be closed 30 minutes after lecture. After this a duplicate marked \"[Extension Students Only]\" will be launched. This is to allow students in different time zones to attempt the quiz if they choose. Note: only the original quiz will count towards the grade of non-extension students. I am an Extension School student, can I attend lectures and OH in person? Yes, as a student from a Harvard School you are welcome to attend all learning instances (lecture, OH, advanced sections, and labs) in person. Given the distance nature of the student body of Harvard Extension School, we also provide live streaming and video capture of our learning instances.","tags":"pages","url":"pages/faq.html"},{"title":"Homework Policies & Submission Instructions","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } V. Jan 29, 2020 General Policies Colaboration Except for HW2 and HW6 which will be done by each student individually , you're allowed and encouraged to work with a fellow student on the homework. This does not mean that you are to divide and conquer. In the spirit of learning and getting the most out of this course and out of collaborating with your peer, you should solve each problem on your own, compare with your partner, and decide on a common solution. Importing Libraries As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list. You are allowed to use other libraries such as seaborn. Submitting HW Late Submissions will not be accepted. Extensions are provided only for medical reasons with a doctor's note. If there are issues, send an email to the course email: cs109b2020@gmail.com . Homework assignments will be done in Python in the Jupyter Notebook environment. When you are finished editing your notebook, re-run all the cells to make sure they work . Normally, you need only submit the .ipynb file with one caveat: If your notebook references other files such as images which are necessary for interpreting your work, they must be uploaded as well. You may also choose to \"attach\" the images to the notebook itself. See the section on markdown attachments under \"other additions\" here for details. Please do not submit .zip or .rar files. File Naming Convention Do not include your name in the paper or the filename as we try to keep grading as anonymous as possible. Making a HW Group in Canvas DO NOT join a group if you are submitting the assignment alone. DO NOT make new groups. Look for an empty group among the pre-made groups for each assignment and join it. Follow instructions below. Click \"People\" in the navbar Click the \"Groups\" tab Type in the search box: \"HW#\" (replace # with the homework number, e.g. HW3) Choose an empty group and have both members in your pair click \"Join\". Again, this must be done before you submit and before the homework deadline. If you haven't joined a group before the homework deadline, we will assume you are working alone. Groups do not persist across assignments. You need to make a group for every assignment. Warning: If you are submitting in a pair: both members must join a Canvas group BEFORE they submit and BEFORE the homework deadline, whichever is earlier. If your group is not in place when you submit or if you submit after the assignment deadline, then you are submitting alone. This is a Canvas limitation. Making a HW Group in Canvas Video","tags":"pages","url":"pages/hw.html"},{"title":"CS109b: Advanced Topics in Data Science","text":"Spring 2020 Pavlos Protopapas , Mark Glickman , & Chris Tanner Lab Leaders: Chris Tanner & Eleni Kaxiras Head TF: Chris Gumb Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models, and unsupervised learning. Lectures: Mon and Wed 1:30‚Äê2:45pm in NW B103 Labs: Monday 4:30-5:45pm & 6:00-7:15pm in Pierce Hall 301 (identical material at both times) Advanced Sections: Wed 4:30-5:45pm in Maxwell-Dworkin G115 (starting 3/4) Office Hours: See weekly calendar for times and locations Prerequisites: CS 109a, AC 209a, Stat 121a, or CSCI E-109a or the equivalent. Course Email: cs109b2020@gmail.com Previous Material 2019 2018","tags":"pages","url":"pages/index.html"},{"title":"Modules","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Predicting Fine Particulate Matter Pollution We introduce the data setting and provide a high-level overview of the most important data science methods for estimating the health risks of air pollution and climate change related exposures. Given the strong evidence that the presence of fine particulate matter in the atmosphere increases mortality and hospitalization rates, it is important that we can track and predict these pollution levels. One of the main challenges in this work is that the fine particulate matter detectors are sparsely located across the US, meaning that many areas do not have quality data. In this project, you will build a model to predict fine particulate matter pollution in the untracked regions of the US, given data from the tracked areas. This data includes meteorological readings, land use data, and satellite data. Francesca Dominici is the Clarence James Gamble Professor of Biostatistics, Population and Data Science at Harvard T.H. Chan School of Public Health and Director of the Data Science Initiative at Harvard University. Dr. Dominici is an international leader at the interface of statistics, data science, causal inference and and public health. Dr. Dominici has stellar leadership in education and mentoring, and the promotion of diversity and gender equality. Dr. Dominici's team has provided the scientific community and policy makers with robust evidence on the adverse health effects of air pollution, and climate change. Her studies have directly and routinely impacted air quality policy, leading to more stringent ambient air quality standards in the US. Room Labelling and Object Arrangement Floor plans play an invaluable role in the architectural world - they tell us the shape and size of a built environment, and also convey the architect's vision for the style and feel of the final product. Much of this work is currently done with 3D renderings, but in the past, a 2D floor plan was the standard. Many of these floor plans exist as essentially unstructured data, such as images. In this project, you will be working with a data set of approximately 1000 floor plans. While it is easy for a human to look at one of these images and understand the purpose of each room, a computer has a harder time understanding this. Your goal is build a system to identify the different types of rooms (living room, bed room, etc.) in each floor plan, and arrange furniture of various sizes within the building using these labels. Your implementation should be careful not to block doors and paths within the building. Jose Luis Garc√≠a del Castillo y L√≥pez is an architect, computational designer, and educator. He advocates for a future where programming and code are tools as natural to artists as paper and pencil. In his work, he explores creative opportunities at the intersection of design, technology, fabrication, data and art. He is currently a Lecturer in Architectural Technology at the Harvard Graduate School of Design. Data Science for Case Law This project will challenge you to read case law, and generate automatic summarizations of the cases. Headnotes are brief case summary statements often generated by commercial third parties. They are under copyright protection, and so are not always available or are subject to many usage restrictions. In this project, you will reconstruct these headnotes for a variety of cases, using historical court cases as a training set. We will use the Caselaw Access Project, a recently-released dataset of all United States case law from the Harvard Law School Library. Jack Cushman is a Lecturer at the Harvard Law School. Jack teaches Computer Programming for Lawyers at Harvard Law School and is a senior developer at the Harvard Library Innovation Lab. He previously practiced as an appellate lawyer at the firm of Stern, Shapiro, Weissberg and Garin. Kelly Fitzpatrick is a Research Associate at the Harvard Law School Library. Kelly runs outreach and communications for the Caselaw Access Project at the Harvard Library Innovation Lab. She holds a masters in library science and worked previously on the Harvard Open Access Project. Predicting Disease Activity This project involves applying machine learning techniques and novel Internet-based data sources for real-time monitoring and short-term forecasting of population-level disease activity. In this project, you will learn how to design and deploy predictive models to track and forecast epidemic outbreaks in real time. For this, you will gain access to epidemiological data of ongoing and historical disease outbreaks in the US and other countries. Diseases of interest include Influenza (USA), Dengue fever (Puerto Rico and Peru), Ebola (DRC), Coronavirus 2019-nCoV (China and the world). Given that most epidemiological monitoring systems in the world provide lagged information about disease activity (case counts of infected people are known to decision-makers weeks after the fact due to lab testing and data collection delays), you will learn how to design and implement time-series based prediction models to estimate the likely disease activity in current time and future weeks. You will learn how to utilize data sources that were not originally designed to be indicators of disease activity to complement time-series predictive models. These data sources include: disease-related Google search activity, disease-related Twitter microblogs, air travel, and weather patterns. Dr. Mauricio Santillana is a physicist and applied mathematician with expertise in mathematical modeling and scientific computing. He has worked in multiple research areas frequently analyzing big data sets to understand and predict the behavior of complex systems. His research modeling population growth patterns has informed policy makers in Mexico and Texas. His research in numerical analysis and computational fluid dynamics has been used to improve models of coastal floods due to hurricanes, and to improve the performance of global atmospheric chemistry models. Mauricio received a B.S. in physics with highest honors from the Universidad Nacional Autonoma de Mexico in Mexico City, and a master's and PhD in computational and applied mathematics from the University of Texas at Austin. Mauricio first joined Harvard as a postdoctoral fellow at the Harvard Center for the Environment and has been a lecturer in applied mathematics at the Harvard SEAS, receiving two awards for excellence in teaching. Predicting Project Success Data Science has become a core function in many firms today, driving innovation and new data-intensive business and operating models. This project will demonstrate how data and data science offers unprecedented opportunities to organizations in running their business, focusing on project planning capabilities. In this project, you will be exposed to concepts related to business operations and an in depth understanding of the role of data and predictions in these operations. In particular, can project success or failure (defined by budgetary or temporal constraints) be predicted ahead of time, given a variety of project features? Many businesses operate without a reliable predictor of project success, and therefore waste time and money due to mismanagement. This project addresses a real-world business need with data, and will help managers better plan their business operations. Dr. Yael Grushka-Cockayne is Visiting Associate Professor of Business Administration, Harvard Business School. Associate Professor Grushka-Cockayne's research and teaching activities focus on data science, analytics, forecasting, decision analysis, project management, and behavioral decision-making. Yael is an award-winning teacher and in 2014 was named one of \"21 Thought-Leader Professors\" in Data Science. At HBS Yael teaches the required Technology and Operations Management course and an elective course on Business Analytics. She has been teaching in the Harvard Business Analytics Program, powered by 2U, since 2018. Previously, Yael taught courses on Decision Analysis, Project Management, and Data Science in Business. Yael's \"Fundamentals of Project Planning and Management\" Coursera MOOC had over 200,000 enrolled, across 200 countries worldwide. Before starting her academic career, she worked in San Francisco as a marketing director of an ERP company. As an expert in the areas of project management, she has served as a consultant to international firms in the aerospace and pharmaceutical industries. Yael is an Associate Editor at Management Science, Operation Research, and Decision Analysis. Education: B.Sc., Ben-Gurion University; MSc, London School of Economics; Ph.D., MRes, London Business School Measuring the shape and brightness of galaxies with neural networks For decades, astronomers have scanned the sky with increasingly powerful telescopes and cameras, collecting millions of digital images of billions of stars, galaxies, and other objects. These \"sky surveys\" collect so much data that no human could ever look at it all directly, so we rely on automated software to detect objects, isolate them from their neighbors, and determine their properties. Traditionally this has been done by model fitting. For example, to characterize a galaxy, we use a parametric generative model for the galaxy that outputs an image (values in a grid of pixels) as a function of the location, size, shape, orientation, and brightness of the galaxy. A common choice is the S√©rsic profile (https://en.wikipedia.org/wiki/Sersic_profile). One can define an objective function (or loss function) given the model and a noise model, and run an optimizer or Markov chain Monte Carlo to estimate the parameters and their uncertainty. Much of modern astronomy is built on this approach, even though the S√©rsic model is not a terribly good fit for many galaxies. A more modern approach would be to use neural networks. This would allow us to specify our concept of what galaxies look like by using many training examples (real or simulated) rather than a functional form. The neural network can be trained with those input examples, and desired output parameters, and then applied to new data. For this module we will use the galsim software (https://github.com/GalSim-developers/GalSim) to generate mock data with known parameters and noise. We will then train a neural net on the mock data, and quantify its performance. By showing that modern data-driven approaches can succeed on this problem, we open the door to future work on real galaxies, including edge cases such as merging systems of galaxies, or galaxies that overlap along the line of sight -- situations that traditional methods sometimes handle poorly. Dr. Douglas Finkbeiner has a joint appointment in the Department of Astronomy and Department of Physics, working on topics ranging from dark matter to interstellar dust. He is currently excited about the Dark Energy Spectroscopic Instrument (DESI), a 5000-fiber spectrograph on the 4m telescope at Kitt Peak, AZ.","tags":"pages","url":"pages/modules.html"},{"title":"Resources","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } FAQ GitHub Repo Ed Guides Homework Policies & Submission Instructions JupyterHub (requires Canvas access)","tags":"pages","url":"pages/resources.html"},{"title":"Schedule","text":"Week Lecture (Mon) Lecture (Weds) Lab (Mon) Advanced Section (Weds) Assignment (R:Released Weds - D:Due Thurs) 1 Lecture 1: Introduction + Smoothers and Additive 1/3 Lecture 2: Smoothers and Additive 2/3 Lab 1: Getting Started HW1 - R: 1/29 D: 2/6 2 Lecture 3: Smoothers and GAM 3/3 Lecture 4: Unsupervised learning/clustering 1 Lab 2: Smoothers+GAM HW2 - R: 2/5 D: 2/20 3 Lecture 5: Unsupervised learning/clustering 2 Lecture 6: Bayesian 1/3 Lab 3: Clustering No New Assignment 4 No Lecture (Presidents' Day) Lecture 7: Bayesian 2/3 No Lab (President's Day) HW3 - R: 2/19 D: 3/5 5 Lecture 8: Bayesian 3/3 Lecture 9: ML/NN Roadmap Lab 4: Bayesian No New Assignment 6 Lecture 10: CNN-1 Lecture 11: CNN-2 Lab 5: CNNs-1 A-Sec 1: ResNet, Dense-Net, res-Next and Inception and transfer learning HW4 - R: 3/4 D: 3/12 7 Lecture 12: Autoencoders + Unet Lecture 13: RNN1 Lab 6: CNNs -2 A-Sec 2: Segmentation Techniques, YOLO, Unet and M-RCNN HW5 - R: 3/11 D: 3/26 8 No Lecture (Spring Break) No Lecture No Lab No A-Sec No New Assignment 9 Lecture 14: RNN2 + Text1 Lecture 15: Text2 Lab 7: AE A-Sec 3: RNN, echo state HW6 - R: 3/25 D: 4/9 10 Lecture 16: Text3 Lecture 17: VAE + Generative models Lab 8: RNNS A-Sec 4: Variational Inference No New Assignment 11 Lecture 18: GANS 1 Lecture 19: GANS 2 Lab 9: Text A-Sec 5: GANS. Bicylcle GANS etc HW7 - R: 4/8 D: 4/16 12 Lecture 20: Reinforcement Learning Basics Lecture 21: Deep Reinforcement Learning Lab 10: VAE+GANS A-Sec 6: RL HW8 - R: 4/15 D: 4/23 13 MODULE: LECTURE DOMAIN MODULE: PROBLEM BACKGROUND Lab 11: RL 14 MODULE PROJECT WORK 15 PROJECT WORK PROJECT WORK","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"Advanced Topics in Data Science (Spring 2020) CS 109b, AC 209b, Stat 121b, or CSCI E-109b Instructors Pavlos Protopapas (SEAS), Mark Glickman (Statistics), & Chris Tanner (SEAS) Lab Leaders: Chris Tanner & Eleni Kaxiras Lectures: Mon and Wed 1:30‚Äê2:45pm in NW B103 Labs: Monday 4:30-5:45pm & 6:00-7:15pm in Pierce Hall 301 (identical material at both times) Advanced Sections: Wed 4:30-5:45pm in Maxwell-Dworkin G115 Office Hours: See weekly calendar for times and locations Prerequisites: CS 109a, AC 209a, Stat 121a, or CSCI E-109a or the equivalent. Course description Tentative Course Topics Course Objectives Course Components Lectures Labs In-class Quizzes Advanced Sections Exams Projects Homework Assignments Course Resources Online Materials Recommended Textbooks Getting Help Course Policies and Expectations Grading Collaboration Policy Late or Wrongly Submitted Assignments Re-grade Requests Auditing the Class Academic Integrity Accommodations for students with disabilities Diversity and Inclusion Statement Course Description Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models, and unsupervised learning. The programming language will be Python. Tentative Course Topics Smoothing and Additive Models Unsupervised Learning, Clustering Bayesian Modeling Convolutional Neural Networks Autoencoders Recurrent Neural Networks NLP / Text Analysis Variational AutoEncoders & Generative Models Generative Adversarial Networks (Deep) Reinforcement Learning Course Objectives Upon successful completion of this course, you should feel comfortable with the material mentioned above, and you will have gained experience working with others on real-world problems. The content knowledge, the project, and teamwork will prepare you for the professional world or further studies. Course Components There will be live video feed available only to continuing education students for lectures, labs, and advanced sections. Recordings for all other students will be available within 24 hrs. Video streams and recordings can be accessed from the Videos section on Canvas. Lectures The class meets twice a week for lectures. Attending lectures is a crucial component of learning the material presented in this course. Labs Lectures are supplemented by weekly lab sections that include additional discussion of the course material, hands-on programming exercises, and group activities. In-Class Quizzes At the end of each lecture, we will ask you to take a short, graded quiz on the material presented in class; there will be no AC209b content in the quizzes. 50% of the quizzes will be dropped from your grade. DCE students' quizzes will not count toward their final grade. Advanced Sections The course will include advanced sections for 209b students and will cover a different topic per week. These are 75 min lectures and they will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the advanced sections is required for all AC209b students. Tentative topics are: ResNet, Dense-Net, res-Next and Inception and transfer learning Segmentation Techniques, YOLO, Unet and M-RCNN RNN, Echo State Variational Inference GANS. Cycle GANS, etc. RL Exams There are no exams in this course. Projects Non-DCE Students During the final four (4) weeks of the course, students will be divided in break-out thematic sections where they will study topics. These topics are tentative at the moment but may include medicine, law, astronomy, e-commerce, and government. Each section will include lectures by Harvard faculty, experts on the field, followed by project work also led by that faculty. You will get to present your projects in the SEAS Design Fair at the end of the semester. DCE Students The goal of the project is to have a complete end-to-end data science process encompassing both semesters of subject material while working as a 3-4 person team. We will supply a small set of project choices within the thematic categories. Teams may propose a different project with sufficient notice and will be subject to approval by the course staff. Homework Assignments There will be eight graded homework assignments. Some of them will be due one week after being assigned and some will be due two weeks after being assigned. For six assignments, you have the option to work and submit in pairs, the two remaining are to be completed individually. Course Resources Online Materials All course materials, including lecture notes, lab notes, and section notes will be published on the course GitHub repo as well as the public site's Materials section . Note: Lecture content for weeks 1-3 is only available to registered students through the Materals section. Assignments will only be posted on Canvas. Working Environment You will be working in Jupyter Notebooks which you can run in your own machine or in the SEAS JupyterHub cloud (see lab 1 for details). Recommended Textbooks ISLR: An Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani (Springer: New York, 2013) DL: Deep Learning by Goodfellow, Bengio and Courville. (The MIT Press: Cambridge, 2016) Free electronic versions are available ( ISLR , DL ) or hard copy through Amazon ( ISLR , DL ). Getting Help For questions about homework, course content, package installation, the process is: try to troubleshoot yourself by reading the lecture, lab, and section notes, and looking up online resources. go to office hours this is the best way to get help. post on the class Ed forum; we want you and your peers to engage in helping each other. TFs also monitor Ed and will respond within 24 hours. Note that Ed questions are visible to everyone. If you are citing homework solution code you must post privately so that only the staff sees your message. watch for official announcements via Canvas so make sure you have your Canvas notifications turned on. Ed should always be your first resource for seeking answers to your content questions. send an email to the Helpline cs109b2020@gmail.com for administrative issues, regrade requests, and non-content specific questions. for personal matters that you do not feel comfortable sharing with the TFs, you may send an email to either or both of the instructors. Course Policies and Expectations Grading for CS109b, STAT121b, and CS209b (tentative): Your final score for the course will be computed using the following weights: Non-DCE Students Assignment Final Grade Weight Paired Homework (6) 47% Individual Homework (2) 21% Quizzes 8% Ed Exercises 4% Project 20% Total 100% Note: Regular homework (for everyone) counts as 5 points. 209b extra homework counts as 1 point. DCE Students Assignment Final Grade Weight Paired Homework (6) 51% Individual Homework (2) 23% Ed Exercises 4% Project 22% Total 100% Collaboration Policy We expect you to adhere to the Harvard Honor Code at all times. Failure to adhere to the honor code and our policies may result in serious penalties, up to and including automatic failure in the course and reference to the ad board. If you work with a partner on an assignment make sure both parties solve all the problems. Do not divide and conquer. You are expected to be intellectually honest and give credit where credit is due. In particular: if you work with a fellow student but decide to submit different papers, include the name of each other in the designated area of the submission paper. if you work with a fellow student and want to submit the same paper you need to form a group prior to the submission. Details in the assignment. Not all assignments will permit group submissions. you need to write your solutions entirely on your own or with your collaborator you are welcome to take ideas from code presented in labs, lecture, or sections but you need to change it, adapt it to your style, and ultimately write your own. We do not want to see code copied verbatim from the above sources. if you use code found on the internet, books, or other sources you need to cite those sources. you should not view any written materials or code created by other students for the same assignment; you may not provide or make available solutions to individuals who take or may take this course in the future. if the assignment allows it you may use third-party libraries and example code, so long as the material is available to all students in the class and you give proper attribution. Do not remove any original copyright notices and headers. Late or Wrongly Submitted Assignments There are no late days in homework submission. We will accept late submissions only for medical reasons and if accompanied by a doctor's note. To submit after Canvas has closed or to ask for an extension , send an email to the Helpline with subject line \"Submit HW1: Reason=the flu\" replacing 'HW1' with the name of the current assignment and \"the flu\" with your reason. You need to attach the note from your medical provider otherwise we will not accept the request. If you forgot to join a Group with your peer and are asking for the same grade we will accept this with no penalty up to HW3. For homeworks beyond that we feel that you should be familiar with the process of joining groups. After that there will be a penalty of -1 point for both members of the group provided the submission was on time. Re-grade Requests Our graders and instructors make every effort in grading accurately and in giving you a lot of feedback. If you discover that your answer to a homework problem was correct but it was marked as incorrect, send an email to the Helpline with a description of the error. Please do not submit regrade requests based on what you perceive is overly harsh grading . The points we take off are based on a grading rubric that is being applied uniformly to all assignments. If you decide to send a regrade request , send an email to the Helpline with subject line \"Regrade HW1: Grader=johnsmith\" replacing 'HW1' with the current assignment and 'johnsmith' with the name of the grader within 48 hours of the grade release . Auditing the Class If you would like to audit the class, please send an email to the Helpline indicating who you are and why you want to audit the class. You need a HUID to be included to Canvas. Please note that auditors may not submit assignments for grading or make use of other limited student resources such as office hours. Academic Integrity Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109b we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Collaborations section above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with the professor by the end of the second week of the term, (fill in specific date). Failure to do so may result in the Course Head's inability to respond in a timely manner. All discussions will remain confidential, although Faculty are invited to contact AEO to discuss appropriate implementation. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made w/ Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this: If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion . We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates.","tags":"pages","url":"pages/syllabus.html"},{"title":"Advanced Sections 01:","text":"Slides","tags":"a-section","url":"a-section/a-section01/"},{"title":"Advanced Sections 02:","text":"Slides","tags":"a-section","url":"a-section/a-section02/"},{"title":"Advanced Sections 03:","text":"Slides","tags":"a-section","url":"a-section/a-section03/"},{"title":"Advanced Sections 04:","text":"Slides","tags":"a-section","url":"a-section/a-section04/"},{"title":"Advanced Sections 05:","text":"Slides","tags":"a-section","url":"a-section/a-section05/"},{"title":"Lab 05:","text":"Slides","tags":"labs","url":"labs/lab05/"},{"title":"Lab 06:","text":"Slides","tags":"labs","url":"labs/lab06/"},{"title":"Lab 07:","text":"Slides","tags":"labs","url":"labs/lab07/"},{"title":"Lab 08:","text":"Slides","tags":"labs","url":"labs/lab08/"},{"title":"Lab 09:","text":"Slides","tags":"labs","url":"labs/lab09/"},{"title":"Lab 10:","text":"Slides","tags":"labs","url":"labs/lab10/"},{"title":"Lab 11:","text":"Slides","tags":"labs","url":"labs/lab11/"},{"title":"Lab 12:","text":"Slides","tags":"labs","url":"labs/lab12/"},{"title":"Lecture 09:","text":"Slides","tags":"lectures","url":"lectures/lecture09/"},{"title":"Lecture 10:","text":"Slides","tags":"lectures","url":"lectures/lecture10/"},{"title":"Lecture 11:","text":"Slides","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lecture 12:","text":"Slides","tags":"lectures","url":"lectures/lecture12/"},{"title":"Lecture 13:","text":"Slides","tags":"lectures","url":"lectures/lecture13/"},{"title":"Lecture 14:","text":"Slides","tags":"lectures","url":"lectures/lecture14/"},{"title":"Lecture 15:","text":"Slides","tags":"lectures","url":"lectures/lecture15/"},{"title":"Lecture 16:","text":"Slides","tags":"lectures","url":"lectures/lecture16/"},{"title":"Lecture 17:","text":"Slides","tags":"lectures","url":"lectures/lecture17/"},{"title":"Lecture 18:","text":"Slides","tags":"lectures","url":"lectures/lecture18/"},{"title":"Lecture 19:","text":"Slides","tags":"lectures","url":"lectures/lecture19/"},{"title":"Lecture 20:","text":"Slides","tags":"lectures","url":"lectures/lecture20/"},{"title":"Lecture 21:","text":"Slides","tags":"lectures","url":"lectures/lecture21/"},{"title":"Lecture 22:","text":"Slides","tags":"lectures","url":"lectures/lecture22/"},{"title":"Lecture 23:","text":"Slides","tags":"lectures","url":"lectures/lecture23/"},{"title":"Lecture 24:","text":"Slides","tags":"lectures","url":"lectures/lecture24/"},{"title":"Lecture 25:","text":"Slides","tags":"lectures","url":"lectures/lecture25/"},{"title":"Lecture 26:","text":"Slides","tags":"lectures","url":"lectures/lecture26/"},{"title":"Lab 4: Bayesian Analysis","text":"Notebooks Lab 4: Bayesian Analysis Data dataset_2_test.csv dataset_2_train.csv","tags":"labs","url":"labs/lab04/"},{"title":"Lab 4: Bayesian Analysis","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 4 - Bayesian Analysis Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Angelaki Kaxiras Content: Eleni Angelaki Kaxiras In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [ ]: import pymc3 as pm In [ ]: import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats import pandas as pd % matplotlib inline import warnings warnings . filterwarnings ( 'ignore' ) In [ ]: print ( 'Running on PyMC3 v {} ' . format ( pm . __version__ )) In [ ]: %% javascript IPython . OutputArea . auto_scroll_threshold = 20000 ; Learning Objectives By the end of this lab, you should be able to: Apply Bayes Rule in calculating probabilities. Understand how to apply Bayesian analysis using PyMC3 Avoid getting fired when talking to your Bayesian employer. This lab corresponds to Lectures 6, 7, and 8, and maps to Homework 3. Table of Contents The Bayesian Way of Thinking or Is this a Fair Coin? Intro to pyMC3 . Bayesian Linear Regression . 1. The Bayesian way of Thinking Here is my state of knowledge about the situation. Here is some data, I am now going to revise my state of knowledge. Table Exercise : Discuss the statement above with your table mates and make sure everyone understands what it means and what constitutes Bayesian way of thinking. Finally, count the Bayesians among you. A. Bayes Rule \\begin{equation} \\label{eq:bayes} P(A|\\textbf{B}) = \\frac{P(\\textbf{B} |A) P(A) }{P(\\textbf{B})} \\end{equation} $P(A|\\textbf{B})$ is the posterior distribution, prob(hypothesis | data) $P(\\textbf{B} |A)$ is the likelihood function, how probable is my data B for different values of the parameters $P(A)$ is the marginal probability to observe the data, called the prior , this captures our belief about the data before observing it. $P(\\textbf{B})$ is the marginal distribution (sometimes called marginal likelihood) Table Exercise : Solve the Monty Hall Paradox using Bayes Rule. You are invited to play a game. There are 3 doors behind one of which are the keys to a brand new red Tesla. There is a goat behind each of the other two. You are asked to pick one door, and let's say you pick Door1 . The host, who knows where the keys are, then says \"I will do you a favor and open Door2 \". So he opens Door2 inside which there is, of course, a goat. He now asks you, do you want to open the initial Door you chose or change to Door3 ? What do you do? Initial Steps: Start by defining the events of this probabilities game. One definition is: $A_i$: car is behind door $i$ $B_i$ host opens door $i$ $i\\in[1,2,3]$ In more math terms, the question is: is the probability that the price is behind Door 1 higher than the probability that the price is behind Door2 , given that an event has occured ? B. Bayes Rule written with Probability Distributions We have data that we believe come from an underlying distribution of unknown parameters. If we find those parameters, we know everything about the process that generated this data and we can make inferences (create new data). \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} But what is $\\theta \\;$? $\\theta$ is an unknown yet fixed parameter. In Bayesian inference we express our belief about what $\\theta$ might be and instead of trying to guess $\\theta$ exactly, we look for its probability distribution . What that means is that we are looking for the parameters of that distribution. For example, for a Poisson distribution we need to find the parameter $\\lambda$. You will see $\\theta$ with many names, e.g. $\\mu$ for the normal distribution. C. A review of Common Probability Distributions Discrete Distributions The random variable has a probability mass function (pmf) which measures the probability that our random variable will take a specific value $y$, denoted $P(Y=y)$. Bernoulli (binary outcome, success has probability $\\theta$, $one$ trial): $ P(Y=k) = \\theta&#94;k(1-\\theta)&#94;{1-k} $ Binomial (binary outcome, success has probability $\\theta$, $n$ trials): \\begin{equation} P(Y=k) = {{n}\\choose{k}} \\cdot \\theta&#94;k(1-\\theta)&#94;{n-k} \\end{equation} Note : Binomial(1,$p$) = Bernouli($p$) Negative Binomial Poisson (counts independent events occurring at a rate) \\begin{equation} P\\left( Y=y|\\mu \\right) = \\frac{{e&#94;{ - \\mu } \\mu &#94;y }}{{y!}} \\end{equation} y = 0,1,2,... Discrete Uniform Categorical, or Multinulli (random variables can take any of K possible categories, each having its own probability; this is a generalization of the Bernoulli distribution for a discrete variable with more than two possible outcomes, such as the roll of a die) Dirichlet-multinomial (a generalization of the beta distribution for many variables) Continuous Distributions The random variable has a probability density function (pdf) . Uniform (variable equally likely to be near each value in interval $(a,b)$) \\begin{equation} P(X = x) = \\frac{1}{b - a} \\end{equation} anywhere within the interval $(a, b)$, and zero elsewhere. Normal (a.k.a. Gaussian) \\begin{equation} X \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} A Normal distribution can be parameterized either in terms of precision $\\tau$ or standard deviation ($\\sigma&#94;{2}$. The link between the two is given by \\begin{equation} \\tau = \\frac{1}{\\sigma&#94;{2}} \\end{equation} Mean $\\mu$ Variance $\\frac{1}{\\tau}$ or $\\sigma&#94;{2}$ Parameters: mu: float , sigma: float or tau: float Beta (variable ($\\theta$) taking on values in the interval $[0,1]$, and parametrized by two positive parameters, $\\alpha$ and $\\beta$ that control the shape of the distribution. Note: Beta is a good distribution to use for priors (beliefs) because its range is $[0,1]$ which is the natural range for a probability and because we can model a wide range of functions by changing the $\\alpha$ and $\\beta$ parameters. \\begin{equation} \\label{eq:beta} P(\\theta) = \\frac{1}{B(\\alpha, \\beta)} {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\propto {\\theta}&#94;{\\alpha - 1} (1 - \\theta)&#94;{\\beta - 1} \\end{equation} where the normalisation constant, $B$, is a beta function of $\\alpha$ and $\\beta$, \\begin{equation} B(\\alpha, \\beta) = \\int_{t=0}&#94;1 t&#94;{\\alpha - 1} (1 - t)&#94;{\\beta - 1} dt. \\end{equation} Exponential Gamma Code Resources: Statistical Distributions in numpy/scipy: scipy.stats Statistical Distributions in pyMC3: distributions in PyMC3 (we will see those below). Exercise: Plot a Discrete variable Change the value of $\\mu$ in the Poisson PMF and see how the plot changes. Remember that the y-axis in a discrete probability distribution shows the probability of the random variable having a specific value in the x-axis. \\begin{equation} P\\left( X=k \\right) = \\frac{{e&#94;{ - \\mu } \\mu &#94;k }}{{k!}} \\end{equation} stats.poisson.pmf(x, mu) $\\mu$(mu) is our $\\theta$ in this case. In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 30 ) for m in [ 0.5 , 3 , 8 ]: pmf = stats . poisson . pmf ( x , m ) plt . plot ( x , pmf , 'o' , alpha = 0.5 , label = '$\\mu$ = {} ' . format ( m )) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . ylim = ( - 0.1 ) plt . show () In [ ]: # same for binomial plt . style . use ( 'seaborn-darkgrid' ) x = np . arange ( 0 , 22 ) ns = [ 10 , 17 ] ps = [ 0.5 , 0.7 ] for n , p in zip ( ns , ps ): pmf = stats . binom . pmf ( x , n , p ) plt . plot ( x , pmf , 'o' , alpha = 0.5 , label = 'n = {} , p = {} ' . format ( n , p )) plt . xlabel ( 'x' , fontsize = 14 ) plt . ylabel ( 'f(x)' , fontsize = 14 ) plt . legend ( loc = 1 ) plt . show () In [ ]: # discrete uniform plt . style . use ( 'seaborn-darkgrid' ) ls = [ 0 ] us = [ 3 ] # watch out, this number can only be integer! for l , u in zip ( ls , us ): x = np . arange ( l , u + 1 ) pmf = [ 1.0 / ( u - l + 1 )] * len ( x ) plt . plot ( x , pmf , '-o' , label = 'lower = {} , upper = {} ' . format ( l , u )) plt . xlabel ( 'x' , fontsize = 12 ) plt . ylabel ( 'probability P(x)' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () Exercise: Plot a continuous variable Change the value of $\\mu$ in the Uniform PDF and see how the plot changes. Remember that the y-axis in a continuous probability distribution does not shows the actual probability of the random variable having a specific value in the x-axis because that probability is zero!. Instead, to see the probability that the variable is within a small margin we look at the integral below the curve of the PDF. The uniform is often used as a noninformative prior. Uniform - numpy.random.uniform(a=0.0, b=1.0, size) $\\alpha$ and $\\beta$ are our parameters. size is how many tries to perform. Our $\\theta$ is basically the combination of the parameters a,b. We can also call it \\begin{equation} \\mu = (a+b)/2 \\end{equation} In [ ]: from scipy.stats import uniform r = uniform . rvs ( size = 100 ) plt . hist ( r , density = True , bins = 'rice' , alpha = 0.3 , label = 'uniform pdf' ) plt . ylabel ( r 'probability density' ) plt . xlabel ( f 'random variable' ) plt . legend ( loc = 'best' , frameon = False ) plt . show () In [ ]: from scipy.stats import beta alphas = [ 0.5 , 1.5 , 3.0 ] betas = [ 0.5 , 1.5 , 3.0 ] x = np . linspace ( 0 , 1 , 1000 ) colors = [ 'red' , 'green' , 'blue' ] fig , ax = plt . subplots ( figsize = ( 8 , 5 )) for a , b , colors in zip ( alphas , betas , colors ): dist = beta ( a , b ) plt . plot ( x , dist . pdf ( x ), c = colors , label = f 'a= {a} , b= {b} ' ) ax . set_ylim ( 0 , 3 ) ax . set_xlabel ( r '$\\theta$' ) ax . set_ylabel ( r '$p(\\theta|\\alpha,\\beta)$' ) ax . set_title ( 'Beta Distribution' ) ax . legend ( loc = 'best' ) fig . show (); In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . linspace ( - 5 , 5 , 1000 ) mus = [ 0. , 0. , 0. , - 2. ] sigmas = [ 0.4 , 1. , 2. , 0.4 ] for mu , sigma in zip ( mus , sigmas ): pdf = stats . norm . pdf ( x , mu , sigma ) plt . plot ( x , pdf , label = r '$\\mu$ = ' + f ' {mu} ,' + r '$\\sigma$ = ' + f ' {sigma} ' ) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability density' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () In [ ]: plt . style . use ( 'seaborn-darkgrid' ) x = np . linspace ( - 5 , 5 , 1000 ) mus = [ 0. , 0. , 0. , - 2. ] # mean sigmas = [ 0.4 , 1. , 2. , 0.4 ] # std for mu , sigma in zip ( mus , sigmas ): plt . plot ( x , uniform . pdf ( x , mu , sigma ), lw = 5 , alpha = 0.4 , \\ label = r '$\\mu$ = ' + f ' {mu} ,' + r '$\\sigma$ = ' + f ' {sigma} ' ) plt . xlabel ( 'random variable' , fontsize = 12 ) plt . ylabel ( 'probability density' , fontsize = 12 ) plt . legend ( loc = 1 ) plt . show () D. Is this a Fair Coin? We do not want to promote gambling but let's say you visit the casino in Monte Carlo . You want to test your theory that casinos are dubious places where coins have been manipulated to have a larger probability for tails. So you will try to estimate how fair a coin is based on 100 flips. You begin by flipping the coin. You get either Heads ($H$) or Tails ($T$) as our observed data and want to see if your posterior probabilities change as you obtain more data, that is, more coin flips. A nice way to visualize this is to plot the posterior probabilities as we observe more flips (data). We will be using Bayes rule. $\\textbf{D}$ is our data. \\begin{equation} \\label{eq:bayes} P(\\theta|\\textbf{D}) = \\frac{P(\\textbf{D} |\\theta) P(\\theta) }{P(\\textbf{D})} \\end{equation} In [ ]: # play with the prior trials = np . array ([ 0 , 1 , 3 , 5 , 10 , 15 , 20 , 100 , 200 , 300 ]) heads = np . array ([ 0 , 1 , 2 , 4 , 8 , 10 , 10 , 50 , 180 , 150 ]) x = np . linspace ( 0 , 1 , 100 ) plt . figure ( figsize = ( 10 , 8 )) for k , N in enumerate ( trials ): sx = plt . subplot ( len ( trials ) / 2 , 2 , k + 1 ) prior = stats . beta . pdf ( x , 1 + heads [ k ], 1 + trials [ k ] - heads [ k ]) #plt.ylim(0,2.) plt . plot ( x , prior , alpha = 0.5 , label = f ' {trials[k]} tosses \\n {heads[k]} heads' ); plt . fill_between ( x , 0 , prior , color = \"#348ABD\" , alpha = 0.4 ) plt . legend ( loc = 'upper left' , fontsize = 10 ) plt . legend () plt . autoscale ( tight = True ) plt . suptitle ( \"Posterior probabilities for coin flips\" , fontsize = 15 ); plt . tight_layout () plt . subplots_adjust ( top = 0.88 ) Top 2. Introduction to pyMC3 PyMC3 is a Python library for programming Bayesian analysis, and more specifically, data creation, model definition, model fitting, and posterior analysis. It uses the concept of a model which contains assigned parametric statistical distributions to unknown quantities in the model. Within models we define random variables and their distributions. A distribution requires at least a name argument, and other parameters that define it. You may also use the logp() method in the model to build the model log-likelihood function. We define and fit the model. PyMC3 includes a comprehensive set of pre-defined statistical distributions that can be used as model building blocks. Although they are not meant to be used outside of a model , you can invoke them by using the prefix pm , as in pm.Normal . Markov Chain Monte Carlo (MCMC) Simulations PyMC3 uses the No-U-Turn Sampler (NUTS) and the Random Walk Metropolis , two Markov chain Monte Carlo (MCMC) algorithms for sampling in posterior space. Monte Carlo gets into the name because when we sample in posterior space, we choose our next move via a pseudo-random process. NUTS is a sophisticated algorithm that can handle a large number of unknown (albeit continuous) variables. In [ ]: with pm . Model () as model : z = pm . Normal ( 'z' , mu = 0. , sigma = 5. ) x = pm . Normal ( 'x' , mu = z , sigma = 1. , observed = 5. ) print ( x . logp ({ 'z' : 2.5 })) print ( z . random ( 10 , 100 )[: 10 ]) References : Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 (https://doi.org/10.7717/peerj-cs.55) Distributions in PyMC3 More Details on Distributions Information about PyMC3 functions including descriptions of distributions, sampling methods, and other functions, is available via the help command. In [ ]: #help(pm.Poisson) Example: Mining Disasters We will go over the classical mining disasters from 1851 to 1962 dataset. This example is from the pyMC3 Docs . In [ ]: import pandas as pd disaster_data = pd . Series ([ 4 , 5 , 4 , 0 , 1 , 4 , 3 , 4 , 0 , 6 , 3 , 3 , 4 , 0 , 2 , 6 , 3 , 3 , 5 , 4 , 5 , 3 , 1 , 4 , 4 , 1 , 5 , 5 , 3 , 4 , 2 , 5 , 2 , 2 , 3 , 4 , 2 , 1 , 3 , np . nan , 2 , 1 , 1 , 1 , 1 , 3 , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 3 , 1 , 0 , 3 , 2 , 2 , 0 , 1 , 1 , 1 , 0 , 1 , 0 , 1 , 0 , 0 , 0 , 2 , 1 , 0 , 0 , 0 , 1 , 1 , 0 , 2 , 3 , 3 , 1 , np . nan , 2 , 1 , 1 , 1 , 1 , 2 , 4 , 2 , 0 , 0 , 1 , 4 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 1 ]) fontsize = 12 years = np . arange ( 1851 , 1962 ) plt . figure ( figsize = ( 10 , 5 )) #plt.scatter(years, disaster_data); plt . bar ( years , disaster_data ) plt . ylabel ( 'Disaster count' , size = fontsize ) plt . xlabel ( 'Year' , size = fontsize ); plt . title ( 'Was there a Turning Point in Mining disasters from 1851 to 1962?' , size = 15 ); Building the model Step1: We choose the probability model for our experiment. Occurrences of disasters in the time series is thought to follow a Poisson process with a large rate parameter in the early part of the time series, and from one with a smaller rate in the later part. We are interested in locating the change point in the series, which perhaps is related to changes in mining safety regulations. disasters = pm.Poisson('disasters', rate, observed=disaster_data) We have two rates, early_rate if $t<=s$, and late_rate if $t>s$, where $s$ is the year the switch was made (a.k.a. the switchpoint ). Step2: Choose a prior distributions of the two rates, what we believe the rates were before we observed the data, and the switchpoint. We choose Exponential. early_rate = pm.Exponential('early_rate', 1) The parameters of this model are: Note: Watch for missing values. Missing values are handled transparently by passing a MaskedArray or a pandas.DataFrame. Behind the scenes, another random variable, disasters.missing_values is created to model the missing values. If you pass a np.array with missing values you will get an error. In [ ]: with pm . Model () as disaster_model : # discrete switchpoint = pm . DiscreteUniform ( 'switchpoint' , lower = years . min (), upper = years . max (), testval = 1900 ) # Priors for pre- and post-switch rates number of disasters early_rate = pm . Exponential ( 'early_rate' , 1 ) late_rate = pm . Exponential ( 'late_rate' , 1 ) # our theta - allocate appropriate Poisson rates to years before and after current # switch is an `if` statement in puMC3 rate = pm . math . switch ( switchpoint >= years , early_rate , late_rate ) # our observed data as a likelihood function of the `rate` parameters # shows how we think our data is distributed disasters = pm . Poisson ( 'disasters' , rate , observed = disaster_data ) Model Fitting In [ ]: # there are defaults but we can also more explicitly set the sampling algorithms with disaster_model : # for continuous variables step1 = pm . NUTS ([ early_rate , late_rate ]) # for discrete variables step2 = pm . Metropolis ([ switchpoint , disasters . missing_values [ 0 ]] ) trace = pm . sample ( 10000 , step = [ step1 , step2 ]) # try different number of samples #trace = pm.sample(5000, step=[step1, step2]) Posterior Analysis On the left side plots we notice that our early rate is between 2.5 and 3.5 disasters a year. In the late period it seems to be between 0.6 and 1.2 so definitely lower. The right side plots show the samples we drew to come to our conclusion. In [ ]: pm . traceplot ( trace , [ 'early_rate' , 'late_rate' , 'switchpoint' ], figsize = ( 20 , 10 )); In [ ]: results = pm . summary ( trace , var_names = [ 'early_rate' , 'late_rate' , 'switchpoint' ]) results Top 3. Bayesian Linear Regression Let's say we want to predict outcomes Y as normally distributed observations with an expected value $mu$ that is a linear function of two predictor variables, $\\bf{x}_1$ and $\\bf{x}_2$. \\begin{equation} \\mu = \\alpha + \\beta_1 \\bf{x}_1 + \\beta_2 x_2 \\end{equation}\\begin{equation} Y \\sim \\mathcal{N}(\\mu,\\,\\sigma&#94;{2}) \\end{equation} where $\\sigma&#94;2$ represents the measurement error. In this example, we will use $\\sigma&#94;2 = 10$ We also choose the parameters as normal distributions: \\begin{eqnarray} \\alpha \\sim \\mathcal{N}(0,\\,10) \\\\ \\beta_i \\sim \\mathcal{N}(0,\\,10) \\\\ \\sigma \\sim |\\mathcal{N}(0,\\,10)| \\end{eqnarray} We will artificially create the data to predict on. We will then see if our model predicts them correctly. In [ ]: # Initialize random number generator np . random . seed ( 123 ) # True parameter values alpha , sigma = 1 , 1 beta = [ 1 , 2.5 ] # Size of dataset size = 100 # Predictor variable X1 = np . linspace ( 0 , 1 , size ) X2 = np . linspace ( 0 , . 2 , size ) # Simulate outcome variable Y = alpha + beta [ 0 ] * X1 + beta [ 1 ] * X2 + np . random . randn ( size ) * sigma fig , ax = plt . subplots ( 1 , 2 , figsize = ( 10 , 6 ), sharex = True ) ax [ 0 ] . scatter ( X1 , Y ) ax [ 1 ] . scatter ( X2 , Y ) ax [ 0 ] . set_xlabel ( r '$x_1$' , fontsize = 14 ) ax [ 0 ] . set_ylabel ( r '$Y$' , fontsize = 14 ) ax [ 1 ] . set_xlabel ( r '$x_2$' , fontsize = 14 ) ax [ 1 ] . set_ylabel ( r '$Y$' , fontsize = 14 ) In [ ]: from pymc3 import Model , Normal , HalfNormal basic_model = Model () with basic_model : # Priors for unknown model parameters, specifically create stochastic random variables # with Normal prior distributions for the regression coefficients, # and a half-normal distribution for the standard deviation of the observations, œÉ. alpha = Normal ( 'alpha' , mu = 0 , sd = 10 ) beta = Normal ( 'beta' , mu = 0 , sd = 10 , shape = 2 ) sigma = HalfNormal ( 'sigma' , sd = 1 ) # Expected value of outcome mu = alpha + beta [ 0 ] * X1 + beta [ 1 ] * X2 # Likelihood (sampling distribution) of observations Y_obs = Normal ( 'Y_obs' , mu = mu , sd = sigma , observed = Y ) In [ ]: # model fitting with sampling from pymc3 import NUTS , sample , find_MAP from scipy import optimize with basic_model : # obtain starting values via MAP start = find_MAP ( fmin = optimize . fmin_powell ) # instantiate sampler step = NUTS ( scaling = start ) # draw 2000 posterior samples trace = sample ( 2000 , step , start = start ) In [ ]: from pymc3 import traceplot traceplot ( trace ); In [ ]: from pymc3 import summary summary ( trace [ 'alpha' ]) In [ ]: summary ( trace [ 'beta' ]) This linear regression example is from the original paper on PyMC3: Salvatier J, Wiecki TV, Fonnesbeck C. 2016. Probabilistic programming in Python using PyMC3. PeerJ Computer Science 2:e55 https://doi.org/10.7717/peerj-cs.55 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab04/notebook/"},{"title":"Lecture 8: Bayesian 3/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture08/"},{"title":"Lecture 7: Bayesian 2/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture07/"},{"title":"Lab 3: Clustering","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 3 - Clustering Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Content: Chris Tanner and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler from sklearn import preprocessing % matplotlib inline Learning Objectives By the end of this lab, you should be able to: Explain what PCA is and know the differences between it and clustering Understand the common distance metrics (e.g., Euclidean, Manhattan, Hamming) Understand how different clustering algorithms work (e.g., k-means, Hierarchical, DBScan) Explain the trade-offs between the clustering approaches Quantitatively describe the quality clusters' fit, according to different metrics Comfortably cluster any new data that you are presented with This lab corresponds to Lectures #4 and #5 and maps to Homework #2. Table of Contents PCA Refresher Distant Metrics Clustering Algorithms and Measuring Quality of Clusters 1. PCA Refresher Discussion #1 What is PCA? How can it be useful? How to use it ( via sklearn ): # assume we a DataFrame df a. Instantiate a new PCA object : pca_transformer = PCA() b. Fit some data (learns the transformation based on this data) : fitted_pca = pca_transformer.fit(df) c. Transform the data to the reduced dimensions : pca_df = fitted_pca.transform(df) Using two distinct steps (i.e., (b) and (c)) to fit and transform our data allows one the flexibility to transform any dataset according to our learned fit() . Alternatively, if you know you only want to transform a single dataset, you can combine (b) and (c) into one step: Fit and transform : pca_df = pca_transformer.fit_transform(df) Example: In [3]: ms_df = pd . read_csv ( \"../data/multishapes.csv\" )[[ 'x' , 'y' ]] # loads x,y columns of a dataset pca_transformer = PCA () fitted_pca = pca_transformer . fit ( ms_df ) pca_df = fitted_pca . transform ( ms_df ) NOTE: The above PCA transformation is a bit silly because we started with 2 dimensions and are transforming it to 2 dimensions -- no reduction. The data is still transforming the original data by applying a linear transformation so as to capture the most variance, but PCA is even more useful when the original data is high-dimensional. This example was just to remind you of the syntax. Discussion #2: We didn't scale our data before applying PCA. Should we usually do so? Why or why not? 2. Distance Metrics In the picture below, we are concerned with measuring the distance between two points, p and q . (edited from Wikipedia.org) Euclidean Distance: The Euclidean distance measures the shortest path between the two points, navigating through all dimensions: Manhattan Distance: The Manhattan distance measures the cumulative difference between the two points, across all dimensions. Discussion #3: Where have we seen something like this before in CS109A? What are the effects of using one versus another? Hamming Distance (extra credit): If our two elements of comparison can be represented a sequence of discrete items, it can be useful to measure how many of their elements differ. For example: Mahmoud and Mahmood differ by just 1 character and thus have a hamming distance of 1. 10101 and 01101 have a hamming distance of 2. Mary and Barry have a hamming distance of 3 (m->b, y->r, null->y). Note: the last example may seem sub-optimal, as we could transform Mary to Barry by just 2 operations (substituting the M with a B, then adding an 'r'). The very related Levenshtein distance can handle this, and thus tends to be more appropriate for Strings. 3. Clustering Algorithms Question: Why do we care about clustering? How/why is it useful? We will now walk through three clustering algorithms, first discussing them at a high-level, then showing how to implement them with Python libraries. Let's first load and scale our data, so that particular dimensions don't naturally dominate in their contributions in the distant calculations: In [4]: # loads and displays our summary statistics of our data multishapes = pd . read_csv ( \"../data/multishapes.csv\" ) ms_df = multishapes [[ 'x' , 'y' ]] ms_df . describe () Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1100.000000 1100.000000 mean -0.081222 -0.625431 std 0.644967 1.176170 min -1.489180 -3.353462 25% -0.478839 -1.126752 50% -0.132920 -0.297040 75% 0.366072 0.250817 max 1.492208 1.253874 In [5]: # scales our data scaled_df = pd . DataFrame ( preprocessing . scale ( ms_df ), index = multishapes [ 'shape' ], columns = ms_df . columns ) scaled_df . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1.100000e+03 1100.000000 mean 6.459479e-18 0.000000 std 1.000455e+00 1.000455 min -2.183985e+00 -2.320473 25% -6.167723e-01 -0.426425 50% -8.019252e-02 0.279331 75% 6.938298e-01 0.745340 max 2.440659e+00 1.598544 In [6]: # plots our data msplot = scaled_df . plot . scatter ( x = 'x' , y = 'y' , c = 'Black' , title = \"Multishapes data\" , figsize = ( 11 , 8.5 )) msplot . set_xlabel ( \"X\" ) msplot . set_ylabel ( \"Y\" ) plt . show () 3a. k-Means clustering: Table Exercise #1 : With your table, collectively discuss how k-means works. Use a whiteboard, draw a bunch of dots, and walk through each step of how the algorithm works. When you're confident of your answer, speak with a TF to verify its correctness. Code (via sklearn ): In [7]: from sklearn.cluster import KMeans ms_kmeans = KMeans ( n_clusters = 3 , init = 'random' , n_init = 3 , random_state = 109 ) . fit ( scaled_df ) That's it! Just 1 line of code! Now that we've run k-Means, we can look at various attributes of our clusters. Full documenation is here . In [8]: display ( ms_kmeans . cluster_centers_ ) display ( ms_kmeans . labels_ [ 0 : 10 ]) array([[ 1.06623356, 0.17403387], [-0.46343097, 0.54170897], [-0.98352608, -1.57663916]]) array([1, 0, 0, 1, 0, 0, 1, 1, 1, 1], dtype=int32) Plotting Take note of matplotlib's c= argument to color items in the plot, along with our stacking two different plotting functions in the same plot. In [9]: plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = ms_kmeans . labels_ ); plt . scatter ( ms_kmeans . cluster_centers_ [:, 0 ], ms_kmeans . cluster_centers_ [:, 1 ], c = 'r' , marker = 'h' , s = 100 ); Question : Is this expected or did something go wrong? Should we always scale our data before clustering? Lessons: Initializations matter; run multiple times Total Squared distance should never get worse during an update k-Means can struggle with clusters that are close together; they can get lumped into one There's no notion of 'not part of any cluster' or 'part of two clusters' Visualization here Quality of Clusters: Inertia Inertia measures the total squared distance from points to their cluster's centroid. We obviously want this distance to be relatively small. If we increase the number of clusters, it will naturally make the average distance smaller. If every point has its own cluster, then our distance would be 0. That's obviously not an ideal way to cluster. One way to determine a reasonable number of clusters to simply try many different clusterings as we vary k , and each time, measure the overall inertia. In [10]: wss = [] for i in range ( 1 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) wss . append ( fitx . inertia_ ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), wss , 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Inertia' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () Look for the place(s) where distance stops decreasing as much (i.e., the 'elbow' of the curve). It seems that 4 would be a good number of clusters, as a higher k yields diminishing returns. Quality of Clusters: Silhouette Let's say we have a data point $i$, and the cluster it belongs to is referred to as $C(i)$. One way to measure the quality of a cluster $C(i)$ is to measure how close its data points are to each other (within-cluster) compared to nearby, other clusters $C(j)$. This is what Silhouette Scores provide for us. The range is [-1,1]; 0 indicates a point on the decision boundary (equal average closeness to points intra-cluster and out-of-cluster), and negative values mean that datum might be better in a different cluster. Specifically, let $a(i)$ denote the average distance data point $i$ is to the other points in the same cluster: Similarly, we can also compute the average distance that data point $i$ is to all other clusters. The cluster that yields the minimum distance is denoted by $b(i)$: Hopefully our data point $i$ is much closer, on average, to points within its own cluster (i.e., $a(i)$ than it is to its closest neighboring cluster $b(i)$). The silhouette score quantifies this as $s(i)$: NOTE: If data point $i$ belongs to its own cluster (no other points), then the silhouette score is set to 0 (otherwise, $a(i)$ would be undefined). The silhouette score plotted below is the overall average across all points in our dataset. The silhouette_score() function is available in sklearn . We can manually loop over values of K (for applying k-Means algorithm), then plot its silhouette score. This should allow us to make a reasonable choice for selecting the 'optimal' number of clusters. In [11]: from sklearn.metrics import silhouette_score scores = [ 0 ] for i in range ( 2 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) score = silhouette_score ( scaled_df , fitx . labels_ ) scores . append ( score ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), np . array ( scores ), 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Average Silhouette' ) plt . title ( 'Silhouette Scores for varying $k$ clusters' ) plt . show () Visualizing all Silhoutte scores for a particular clustering Below, we borrow from an sklearn example. The second plot may be overkill. The second plot is just the scaled data. It is not a PCA plot If you only need the raw silhouette scores, use the silhouette_samples() function In [12]: from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.cm as cm #modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html def silplot ( X , clusterer , pointlabels = None ): cluster_labels = clusterer . labels_ n_clusters = clusterer . n_clusters # Create a subplot with 1 row and 2 columns fig , ( ax1 , ax2 ) = plt . subplots ( 1 , 2 ) fig . set_size_inches ( 11 , 8.5 ) # The 1st subplot is the silhouette plot # The silhouette coefficient can range from -1, 1 but in this example all # lie within [-0.1, 1] ax1 . set_xlim ([ - 0.1 , 1 ]) # The (n_clusters+1)*10 is for inserting blank space between silhouette # plots of individual clusters, to demarcate them clearly. ax1 . set_ylim ([ 0 , len ( X ) + ( n_clusters + 1 ) * 10 ]) # The silhouette_score gives the average value for all the samples. # This gives a perspective into the density and separation of the formed # clusters silhouette_avg = silhouette_score ( X , cluster_labels ) print ( \"For n_clusters = \" , n_clusters , \", the average silhouette_score is \" , silhouette_avg , \".\" , sep = \"\" ) # Compute the silhouette scores for each sample sample_silhouette_values = silhouette_samples ( X , cluster_labels ) y_lower = 10 for i in range ( 0 , n_clusters + 1 ): # Aggregate the silhouette scores for samples belonging to # cluster i, and sort them ith_cluster_silhouette_values = \\ sample_silhouette_values [ cluster_labels == i ] ith_cluster_silhouette_values . sort () size_cluster_i = ith_cluster_silhouette_values . shape [ 0 ] y_upper = y_lower + size_cluster_i color = cm . nipy_spectral ( float ( i ) / n_clusters ) ax1 . fill_betweenx ( np . arange ( y_lower , y_upper ), 0 , ith_cluster_silhouette_values , facecolor = color , edgecolor = color , alpha = 0.7 ) # Label the silhouette plots with their cluster numbers at the middle ax1 . text ( - 0.05 , y_lower + 0.5 * size_cluster_i , str ( i )) # Compute the new y_lower for next plot y_lower = y_upper + 10 # 10 for the 0 samples ax1 . set_title ( \"The silhouette plot for the various clusters.\" ) ax1 . set_xlabel ( \"The silhouette coefficient values\" ) ax1 . set_ylabel ( \"Cluster label\" ) # The vertical line for average silhouette score of all the values ax1 . axvline ( x = silhouette_avg , color = \"red\" , linestyle = \"--\" ) ax1 . set_yticks ([]) # Clear the yaxis labels / ticks ax1 . set_xticks ([ - 0.1 , 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ]) # 2nd Plot showing the actual clusters formed colors = cm . nipy_spectral ( cluster_labels . astype ( float ) / n_clusters ) ax2 . scatter ( X [:, 0 ], X [:, 1 ], marker = '.' , s = 200 , lw = 0 , alpha = 0.7 , c = colors , edgecolor = 'k' ) xs = X [:, 0 ] ys = X [:, 1 ] if pointlabels is not None : for i in range ( len ( xs )): plt . text ( xs [ i ], ys [ i ], pointlabels [ i ]) # Labeling the clusters centers = clusterer . cluster_centers_ # Draw white circles at cluster centers ax2 . scatter ( centers [:, 0 ], centers [:, 1 ], marker = 'o' , c = \"white\" , alpha = 1 , s = 200 , edgecolor = 'k' ) for i , c in enumerate ( centers ): ax2 . scatter ( c [ 0 ], c [ 1 ], marker = '$ %d $' % int ( i ), alpha = 1 , s = 50 , edgecolor = 'k' ) ax2 . set_title ( \"The visualization of the clustered data.\" ) ax2 . set_xlabel ( \"Feature space for the 1st feature\" ) ax2 . set_ylabel ( \"Feature space for the 2nd feature\" ) plt . suptitle (( \"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters = %d \" % n_clusters ), fontsize = 14 , fontweight = 'bold' ) In [13]: # run k-means with 3 clusters ms_kmeans = KMeans ( n_clusters = 3 , init = 'random' , n_init = 3 , random_state = 109 ) . fit ( scaled_df ) # plot a fancy silhouette plot silplot ( scaled_df . values , ms_kmeans ) For n_clusters = 3, the average silhouette_score is 0.4269854455072775. Exercise #1 : Using the silhouette scores' optimal number of clusters (per the elbow plot above): Fit a new k-Means model with that many clusters Plot the clusters like we originally did with k-means Plot the silhouette scores just like the above cells Which seems like a better clustering (i.e., 3 clusters or the number returned by the elbow plot above)? In [14]: # your code here # %load solutions/exercise1-solution.py Quality of Clusters: Gap Statistic The gap statistic compares within-cluster distances (like in silhouette), but instead of comparing against the second-best existing cluster for that point, it compares our clustering's overall average to the average we'd see if the data were generated at random (we'd expect randomly generated data to not necessarily have any inherit patterns that can be easily clustered). For full details, you can read the original research paper. In essence, the within-cluster distances (in the elbow plot) will go down just becuse we have more clusters. We additionally calculate how much they'd go down on non-clustered data with the same spread as our data and subtract that trend out to produce the plot below. In [15]: from gap_statistic import OptimalK from sklearn.datasets.samples_generator import make_blobs gs_obj = OptimalK () n_clusters = gs_obj ( scaled_df . values , n_refs = 50 , cluster_array = np . arange ( 1 , 15 )) print ( 'Optimal clusters: ' , n_clusters ) Optimal clusters: 14 In [16]: gs_obj . gap_df Out[16]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } n_clusters gap_value gap* ref_dispersion_std diff diff* 0 1.0 -2.485489 -2016.745254 3.197501 -0.048743 327.709212 1 2.0 -2.414842 -1166.422655 2.485720 -0.047171 201.216617 2 3.0 -2.343297 -680.433189 1.740576 0.124498 278.323626 3 4.0 -2.428315 -477.003229 1.929003 0.125511 419.030416 4 5.0 -2.527884 -445.798296 1.003146 -0.098308 221.349425 5 6.0 -2.406904 -331.922050 0.739480 -0.003661 215.946444 6 7.0 -2.376581 -272.577609 0.732733 -0.050279 155.749504 7 8.0 -2.289622 -213.102403 0.879548 0.148301 215.475149 8 9.0 -2.392151 -213.226757 0.991139 -0.066456 126.100923 9 10.0 -2.287996 -168.823140 0.714412 0.113461 167.342742 10 11.0 -2.366609 -167.250275 0.605772 -0.023348 122.170160 11 12.0 -2.306497 -143.993202 0.591874 0.067395 128.290998 12 13.0 -2.332732 -135.467448 0.598679 -0.071119 89.515897 13 14.0 -2.224408 -111.934186 0.509789 NaN NaN In [17]: gs_obj . plot_results () # makes nice plots If we wish to add error bars to help us decide how many clusters to use, the following code displays such: In [18]: def display_gapstat_with_errbars ( gap_df ): gaps = gap_df [ \"gap_value\" ] . values diffs = gap_df [ \"diff\" ] err_bars = np . zeros ( len ( gap_df )) err_bars [ 1 :] = diffs [: - 1 ] - gaps [: - 1 ] + gaps [ 1 :] plt . scatter ( gap_df [ \"n_clusters\" ], gap_df [ \"gap_value\" ]) plt . errorbar ( gap_df [ \"n_clusters\" ], gap_df [ \"gap_value\" ], yerr = err_bars , capsize = 6 ) plt . xlabel ( \"Number of Clusters\" ) plt . ylabel ( \"Gap Statistic\" ) plt . show () display_gapstat_with_errbars ( gs_obj . gap_df ) For more information about the gap_stat package, please see the full documentation here . 3b. Agglomerative Clustering Table Exercise #2 : With your table, collectively discuss how agglomerative clustering works. Use a whiteboard, draw a bunch of dots, and walk through each step of how the algorithm works. When you're confident of your answer, speak with a TF to verify its correctness. Code (via scipy ): There are many different cluster-merging criteria, one of which is Ward's criteria. Ward's optimizes having the lowest total within-cluster distances, so it merges the two clusters that will harm this objective least. scipy 's agglomerative clustering function implements Ward's method. In [19]: import scipy.cluster.hierarchy as hac from scipy.spatial.distance import pdist plt . figure ( figsize = ( 11 , 8.5 )) dist_mat = pdist ( scaled_df , metric = \"euclidean\" ) ward_data = hac . ward ( dist_mat ) hac . dendrogram ( ward_data ); Discussion #4 : How do you read a plot like the above? What are valid options for number of clusters, and how can you tell? Are some more valid than others? Does it make sense to compute silhouette scores for an agglomerative clustering? If we wanted to compute silhouette scores, what would we need for this to be possible? Lessons: It's expensive: O(n&#94;3) time complexity and O(n&#94;2) space complexity. Many choices for linkage criteria Every node gets clustered (no child left behind) In [20]: # %load solutions/discussion4-solution.py 3c. DBscan Clustering DBscan uses an intuitive notion of denseness to define clusters, rather than defining clusters by a central point as in k-means. Code (via sklearn ): DBscan is implemented in good 'ol sklearn, but there aren't great automated tools for searching for the optimal epsilon parameter. For full documentation, please visit this page In [21]: from sklearn.cluster import DBSCAN plt . figure ( figsize = ( 11 , 8.5 )) fitted_dbscan = DBSCAN ( eps = 0.2 ) . fit ( scaled_df ) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_dbscan . labels_ ); Note: the dark purple dots are not clustered with anything else. They are lone singletons. You can validate such by setting epsilon to a very small value, and increase the min_samples to a high value. Under these conditions, nothing would cluster, and yet all dots become dark purple. Exercise #2 : Experiment with the above code by changing its epsilon value and the min_samples (what is the default value for it, since the above code doesn't specify a value?) Instead of just empirically observing how the epsilon value affects the clustering (which would be very costly for large, high-dimensional data), we can also inspect how far each data point is to its $N&#94;{th}$ closest neighbor: In [22]: from sklearn.neighbors import NearestNeighbors # x-axis is each individual data point, numbered by an artificial index # y-axis is the distance to its 2nd closest neighbor def plot_epsilon ( df , min_samples ): fitted_neigbors = NearestNeighbors ( n_neighbors = min_samples ) . fit ( df ) distances , indices = fitted_neigbors . kneighbors ( df ) dist_to_nth_nearest_neighbor = distances [:, - 1 ] plt . plot ( np . sort ( dist_to_nth_nearest_neighbor )) plt . xlabel ( \"Index \\n (sorted by increasing distances)\" ) plt . ylabel ( \" {} -NN Distance (epsilon)\" . format ( min_samples - 1 )) plt . tick_params ( right = True , labelright = True ) In [23]: plot_epsilon ( scaled_df , 3 ) Lessons: Can cluster non-linear relationships very well; potential for more natural, arbritrarily shaped groupings Does not require specifying the # of clusters (i.e., k ); the algorithm determines such Robust to outliers Very sensitive to the parameters (requires strong knowledge of the data) Doesn't guarantee that every (or ANY) item will be clustered Discussion #5 : When should we prefer one type of clustering over another? Should we always just try all of them? Imagine you work at Spotify and you want to create personalized playlists for each person. One could imagine a dataset exists whereby each row is a particular song, and the columns are features (e.g., tempo (BPM), average vocal frequency, amount of bass, sentiment of lyrics, duration in seconds, etc). Let's use clustering to group one's catalog of favorite music, which will serve as disjoint starting points for suggesting future songs. Specifically, imagine that you've 'liked' 500 songs on Spotify so far, and your recommendation algorithm needs to cluster those 500 songs. Would you first experiment with k-Means, Agglomerative, or DBScan? Why? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab03/notebook/"},{"title":"Lecture 6: Bayesian 1/3","text":"Slides This lecture is only available to registered students Lecture 6-8 Slides [PDF] Notebooks Bayes Notebook Data This data file is required for running the Bayes notebook sleepstudy.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 mc3.yml Zip This zip includes slides, notebook, data file, and the YAML cs109b_lec6-8_Bayes.zip","tags":"lectures","url":"lectures/lecture06/"},{"title":"Lab 3: Clustering","text":"Notebooks Lab 3: Clustering Solutions These solutions can be loaded directly into the Lab 3 notebook. For this to work they need to be placed in a solutions directory in the same directory as the notebook. Exercise 1 Solutions Discussion 4 Solutions","tags":"labs","url":"labs/lab03/"},{"title":"Lecture 5: Unsupervised Learning - Clustering 2","text":"Slides This lecture is only available to registered students Lecture 4-5 Slides [PDF] Notebooks Clustering Notebook Data These data files are required for running the clustering notebook faithful.csv multishapes.csv USArrests.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 cs109b.yml Zip This zip includes slides, notebook, all data files, and the YAML cs109b_lec4-5_clustering.zip","tags":"lectures","url":"lectures/lecture05/"},{"title":"Lecture 4: Unsupervised Learning - Clustering 1","text":"Slides This lecture is only available to registered students Lecture 4-5 Slides [PDF] Notebooks Clustering Notebook Data These data files are required for running the clustering notebook faithful.csv multishapes.csv USArrests.csv YAML File This file can be used to create an environment from a basic conda install that will be able to run the notebook. This file is not necessary if you have already created a local cs109b conda environment using the YAML file from Lab 1 cs109b.yml Zip This zip includes slides, notebook, all data files, and the YAML cs109b_lec4-5_clustering.zip","tags":"lectures","url":"lectures/lecture04/"},{"title":"Lab 2: Smoothers & GAMs","text":"Notebooks Lab 2: Smooths & GAMs","tags":"labs","url":"labs/lab02/"},{"title":"Lab 2: Smoothers & GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models - Model Fitting Spring 2020 Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Content: Eleni Kaxiras and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np from scipy.interpolate import interp1d import matplotlib.pyplot as plt import pandas as pd % matplotlib inline Learning Goals By the end of this lab, you should be able to: Understand how to implement GAMs with the Python package pyGAM Learn about the practical aspects of Splines and how to use them. This lab corresponds to lectures 1, 2, and 3 and maps to homework 1. Table of Contents 1 - Overview - A Top View of LMs, GLMs, and GAMs to set the stage 2 - A review of Linear Regression with statsmodels . What are those weird formulas? 3 - Splines 4 - Generative Additive Models with pyGAM 5 - Smooting Splines using pyGAM Overview Linear Models (LM), Generalized Linear Models (GLMs), Generalized Additive Models (GAMs), Splines, Natural Splines, Smoothing Splines! So many definitions. Let's try and work through an example for each of them so we can better understand them. image source: Dani Serv√©n Mar√≠n (one of the developers of pyGAM) A - Linear Models First we have the Linear Models which you know from 109a. These models are linear in the coefficients. Very interpretable but suffer from high bias because let's face it, few relationships in life are linear. Simple Linear Regression (defined as a model with one predictor) as well as Multiple Linear Regression (more than one predictors) are examples of LMs. Polynomial Regression extends the linear model by adding terms that are still linear for the coefficients but non-linear when it somes to the predictiors which are now raised in a power or multiplied between them. $$ \\begin{aligned} y = \\beta{_0} + \\beta{_1}{x_1} & \\mbox{(simple linear regression)}\\\\ y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_2} + \\beta{_3}{x_3} & \\mbox{(multiple linear regression)}\\\\ y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_1&#94;2} + \\beta{_3}{x_3&#94;3} & \\mbox{(polynomial regression)}\\\\ \\end{aligned} $$ Discussion What does it mean for a model to be interpretable ? Are linear regression models interpretable? Are random forests? What about Neural Networks such as FFNs and CNNs? Do we always want interpretability? Describe cases where we do and cases where we do not care. B - Generalized Linear Models (GLMs) $$ \\begin{aligned} y = \\beta{_0} + \\beta{_1}{x_1} + \\beta{_2}{x_2} + \\beta{_3}{x_3} \\end{aligned} $$ Generalized Linear Models is a term coined in the early 1970s by Nelder and Wedderburn for a class of models that includes both Linear Regression and Logistic Regression. A GLM fits one coefficient per feature (predictor). C - Generalized Additive Models (GAMs) Hastie and Tidshirani coined the term Generalized Additive Models in 1986 for a class of non-linear extensions to Generalized Linear Models. $$ \\begin{aligned} y = \\beta{_0} + f_1\\left(x_1\\right) + f_2\\left(x_2\\right) + f_3\\left(x_3\\right) \\\\ y = \\beta{_0} + f_1\\left(x_1\\right) + f_2\\left(x_2, x_3\\right) + f_3\\left(x_3\\right) & \\mbox{(with interaction terms)} \\end{aligned} $$ In practice we add splines and regularization via smoothing penalties to our GLMs. Decision Trees also fit in this category. image source: Dani Serv√©n Mar√≠n D - Basis Functions In our models we can use various types of functions as \"basis\". Monomials such as $x&#94;2$, $x&#94;4$ ( Polynomial Regression ) Sigmoid functions (neural networks) Fourier functions Wavelets Regression splines which we will look at shortly. Discussion Where does polynomial regression fit in all this? Answer: GLMs include Polynomial Regression so the graphic above should really include curved lines, not just straight... Implementation 1 - Linear/Polynomial Regression We will use the diabetes dataset. Variables are: subject: subject ID number age: age diagnosed with diabetes acidity: a measure of acidity called base deficit Response: y: natural log of serum C-peptide concentration Original source is Sockett et al. (1987) mentioned in Hastie and Tibshirani's book \"Generalized Additive Models\". Reading data and (some) exploring in Pandas: In [3]: diab = pd . read_csv ( \"../data/diabetes.csv\" ) diab . head () Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } subject age acidity y 0 1 5.2 -8.1 4.8 1 2 8.8 -16.1 4.1 2 3 10.5 -0.9 5.2 3 4 10.6 -7.8 5.5 4 5 10.4 -29.0 5.0 In [4]: diab . dtypes Out[4]: subject int64 age float64 acidity float64 y float64 dtype: object In [5]: diab . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } subject age acidity y count 43.000000 43.000000 43.000000 43.000000 mean 22.000000 9.032558 -8.148837 4.746512 std 12.556539 4.022539 7.123080 0.720565 min 1.000000 0.900000 -29.000000 3.000000 25% 11.500000 5.500000 -12.700000 4.450000 50% 22.000000 10.400000 -7.800000 4.900000 75% 32.500000 11.850000 -2.000000 5.100000 max 43.000000 15.600000 -0.200000 6.600000 Plotting with matplotlib: In [6]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear/Polynomial regression with statsmodels. As you remember from 109a, we have two tools for Linear Regression: statsmodels https://www.statsmodels.org/stable/regression.html , and sklearn https://scikit-learn.org/stable/index.html Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. using sklearn 's PolynomialFeatures). statsmodels allows users to fit statistical models using R-style formulas . They build the target value and design matrix for you. # our target variable is 'Lottery', while 'Region' is a categorical predictor df = dta.data[['Lottery', 'Literacy', 'Wealth', 'Region']] formula='Lottery ~ Literacy + Wealth + C(Region) + Literacy * Wealth' For more on these formulas see: https://www.statsmodels.org/stable/examples/notebooks/generated/formulas.html https://patsy.readthedocs.io/en/latest/overview.html In [7]: import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Let's build a dataframe to predict values on (sometimes this is just the test or validation set). Very useful for making pretty plots of the model predictions - predict for TONS of values, not just whatever's in the training set. In [8]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Out[8]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age 0 0.000000 1 0.161616 2 0.323232 3 0.484848 4 0.646465 Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [9]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Out[9]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean mean_se mean_ci_lower mean_ci_upper obs_ci_lower obs_ci_upper 0 3.996031 0.244590 3.502071 4.489991 2.600828 5.391235 1 4.009459 0.240929 3.522892 4.496026 2.616856 5.402063 2 4.022887 0.237280 3.543691 4.502084 2.632842 5.412932 3 4.036315 0.233642 3.564466 4.508165 2.648786 5.423845 4 4.049743 0.230016 3.585216 4.514270 2.664687 5.434800 Plot the model and error bars In [10]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars. You can either take Route1 : Build a design df with a column for each of age , age**2 , age**3 , or Route2 : Just edit the formula In [11]: # your answer here In [12]: # %load ../solutions/exercise1-1.py fit2_lm = sm . ols ( formula = \"y ~ age + np.power(age, 2) + np.power(age, 3)\" , data = diab ) . fit () poly_predictions = fit2_lm . get_prediction ( predict_df ) . summary_frame () poly_predictions . head () Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean mean_se mean_ci_lower mean_ci_upper obs_ci_lower obs_ci_upper 0 2.740481 0.508197 1.712556 3.768406 1.156238 4.324724 1 2.846265 0.472858 1.889819 3.802710 1.307439 4.385090 2 2.948751 0.439558 2.059661 3.837841 1.450860 4.446641 3 3.047990 0.408303 2.222119 3.873860 1.586737 4.509242 4 3.144031 0.379104 2.377221 3.910841 1.715328 4.572735 In [13]: # %load ../solutions/exercise1-2.py ax2 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares cubic fit\" ) ax2 . set_xlabel ( \"Age at Diagnosis\" ) ax2 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean' ], color = \"green\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); Ed exercise This example was similar with the Ed exercise. Open it in Ed and let's go though it. 2 - Piecewise Polynomials a.k.a. Splines Splines are a type of piecewise polynomial interpolant. A spline of degree k is a piecewise polynomial that is continuously differentiable k ‚àí 1 times. Splines are the basis of CAD software and vector graphics including a lot of the fonts used in your computer. The name \"spline\" comes from a tool used by ship designers to draw smooth curves. Here is the letter $epsilon$ written with splines: font idea inspired by David Knezevic (AM205) If the degree is 1 then we have a Linear Spline. If it is 3 then we have a Cubic spline. It turns out that cubic splines because they have a continous 2nd derivative at the knots are very smoothly looking to the eye. We do not need higher order than that. The Cubic Splines are usually Natural Cubic Splines which means they have the added constrain of the end points' second derivative = 0. We will use the CubicSpline and the B-Spline as well as the Linear Spline. scipy.interpolate See all the different splines that scipy.interpolate has to offer: https://docs.scipy.org/doc/scipy/reference/interpolate.html Let's use the simplest form which is interpolate on a set of points and then find the points between them. In [14]: from scipy.interpolate import splrep , splev from scipy.interpolate import BSpline , CubicSpline from scipy.interpolate import interp1d # define the range of the function a = - 1 b = 1 # define the number of knots num_knots = 10 x = np . linspace ( a , b , num_knots ) # define the function we want to approximate y = 1 / ( 1 + 25 * ( x ** 2 )) # make a linear spline linspline = interp1d ( x , y ) # sample at these points to plot xx = np . linspace ( a , b , 1000 ) yy = 1 / ( 1 + 25 * ( xx ** 2 )) plt . plot ( x , y , '*' ) plt . plot ( xx , yy , label = 'true function' ) plt . plot ( xx , linspline ( xx ), label = 'linear spline' ); plt . legend (); Exercise 2 The Linear interpolation does not look very good. Fit a Cubic Spline and plot along the Linear to compare. In [15]: # your answer here In [16]: # %load ../solutions/exercise2.py # define the range of the function a = - 1 b = 1 # define the knots num_knots = 10 x = np . linspace ( a , b , num_knots ) # define the function we want to approximate y = 1 / ( 1 + 25 * ( x ** 2 )) # make the Cubic spline cubspline = CubicSpline ( x , y ) # OR make a linear spline linspline = interp1d ( x , y ) # plot xx = np . linspace ( a , b , 1000 ) yy = 1 / ( 1 + 25 * ( xx ** 2 )) plt . plot ( xx , yy , label = 'true function' ) plt . plot ( x , y , '*' ) plt . plot ( xx , linspline ( xx ), label = 'linear' ); plt . plot ( xx , cubspline ( xx ), label = 'cubic' ); plt . legend (); Discussion Change the number of knots to 100 and see what happens. What would happen if we run a polynomial model of degree equal to the number of knots (a global one as in polynomial regression, not a spline)? What makes a spline 'Natural'? B-Splines A B-splines (Basis Splines) is defined by a set of control points and a set of basis functions that intepolate (fit) the function between these points. By choosing to have no smoothing factor we forces the final B-spline to pass though all the points. If, on the other hand, we set a smothing factor, our function is more of an approximation with the control points as \"guidance\". The latter produced a smoother curve which is prefferable for drawing software. For more on Splines see: https://en.wikipedia.org/wiki/B-spline ) We will use scipy.splrep to calulate the coefficients for the B-Spline and draw it. B-Spline with no smooting In [17]: from scipy.interpolate import splev , splrep x = np . linspace ( 0 , 10 , 10 ) y = np . sin ( x ) t , c , k = splrep ( x , y ) # (tck) is a tuple containing the vector of knots, coefficients, degree of the spline print ( t , c , k ) # define the points to plot on (x2) x2 = np . linspace ( 0 , 10 , 200 ) y2 = BSpline ( t , c , k ) plt . plot ( x , y , 'o' , x2 , y2 ( x2 )) plt . show () [ 0. 0. 0. 0. 2.22222222 3.33333333 4.44444444 5.55555556 6.66666667 7.77777778 10. 10. 10. 10. ] [-4.94881722e-18 8.96543619e-01 1.39407154e+00 -2.36640266e-01 -1.18324030e+00 -8.16301228e-01 4.57836125e-01 1.48720677e+00 1.64338775e-01 -5.44021111e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00] 3 B-Spline with smooting factor s In [18]: from scipy.interpolate import splev , splrep x = np . linspace ( 0 , 10 , 10 ) y = np . sin ( x ) s = 0.5 # add smooting factor task = 0 # task needs to be set to 0, which represents: # we are specifying a smoothing factor and thus only want # splrep() to find the optimal t and c t , c , k = splrep ( x , y , task = task , s = s ) # define the points to plot on (x2) x2 = np . linspace ( 0 , 10 , 200 ) y2 = BSpline ( t , c , k ) plt . plot ( x , y , 'o' , x2 , y2 ( x2 )) plt . show () B-Spline with given knots In [19]: x = np . linspace ( 0 , 10 , 100 ) y = np . sin ( x ) knots = np . quantile ( x , [ 0.25 , 0.5 , 0.75 ]) print ( knots ) [2.5 5. 7.5] In [20]: # calculate the B-Spline t , c , k = splrep ( x , y , t = knots ) In [21]: curve = BSpline ( t , c , k ) curve Out[21]: In [22]: plt . scatter ( x = x , y = y , c = 'grey' , alpha = 0.4 ) yknots = np . sin ( knots ) plt . scatter ( knots , yknots , c = 'r' ) plt . plot ( x , curve ( x )) plt . show () Ed exercise This example was similar with the Ed exercise. Open it in Ed and let's go though it. 3 - GAMs https://readthedocs.org/projects/pygam/downloads/pdf/latest/ A - Classification in pyGAM Let's get our (multivariate!) data, the kyphosis dataset, and the LogisticGAM model from pyGAM to do binary classification. kyphosis - wherther a particular deformation was present post-operation age - patient's age in months number - the number of vertebrae involved in the operation start - the number of the topmost vertebrae operated on In [23]: kyphosis = pd . read_csv ( \"../data/kyphosis.csv\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Kyphosis Age Number Start 0 absent 71 3 5 1 absent 158 3 14 2 present 128 4 5 3 absent 2 5 1 4 absent 1 4 15 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Kyphosis Age Number Start count 81 81.000000 81.000000 81.000000 unique 2 NaN NaN NaN top absent NaN NaN NaN freq 64 NaN NaN NaN mean NaN 83.654321 4.049383 11.493827 std NaN 58.104251 1.619423 4.883962 min NaN 1.000000 2.000000 1.000000 25% NaN 26.000000 3.000000 9.000000 50% NaN 87.000000 4.000000 13.000000 75% NaN 130.000000 5.000000 16.000000 max NaN 206.000000 10.000000 18.000000 Kyphosis object Age int64 Number int64 Start int64 dtype: object In [24]: # convert the outcome in a binary form, 1 or 0 kyphosis = pd . read_csv ( \"../data/kyphosis.csv\" ) kyphosis [ \"outcome\" ] = 1 * ( kyphosis [ \"Kyphosis\" ] == \"present\" ) kyphosis . describe () Out[24]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Number Start outcome count 81.000000 81.000000 81.000000 81.000000 mean 83.654321 4.049383 11.493827 0.209877 std 58.104251 1.619423 4.883962 0.409758 min 1.000000 2.000000 1.000000 0.000000 25% 26.000000 3.000000 9.000000 0.000000 50% 87.000000 4.000000 13.000000 0.000000 75% 130.000000 5.000000 16.000000 0.000000 max 206.000000 10.000000 18.000000 1.000000 In [25]: from pygam import LogisticGAM , s , f , l X = kyphosis [[ \"Age\" , \"Number\" , \"Start\" ]] y = kyphosis [ \"outcome\" ] kyph_gam = LogisticGAM () . fit ( X , y ) Outcome dependence on features To help us see how the outcome depends on each feature, pyGAM has the partial_dependence() function. pdep, confi = kyph_gam.partial_dependence(term=i, X=XX, width=0.95) For more on this see the : https://pygam.readthedocs.io/en/latest/api/logisticgam.html In [26]: res = kyph_gam . deviance_residuals ( X , y ) for i , term in enumerate ( kyph_gam . terms ): if term . isintercept : continue XX = kyph_gam . generate_X_grid ( term = i ) pdep , confi = kyph_gam . partial_dependence ( term = i , X = XX , width = 0.95 ) pdep2 , _ = kyph_gam . partial_dependence ( term = i , X = X , width = 0.95 ) plt . figure () plt . scatter ( X . iloc [:, term . feature ], pdep2 + res ) plt . plot ( XX [:, term . feature ], pdep ) plt . plot ( XX [:, term . feature ], confi , c = 'r' , ls = '--' ) plt . title ( X . columns . values [ term . feature ]) plt . show () Notice that we did not specify the basis functions in the .fit(). Cool. pyGAM figures them out for us by using $s()$ (splines) for numerical variables and $f()$ for categorical features. If this is not what we want we can manually specify the basis functions, as follows: In [27]: kyph_gam = LogisticGAM ( s ( 0 ) + s ( 1 ) + s ( 2 )) . fit ( X , y ) In [28]: res = kyph_gam . deviance_residuals ( X , y ) for i , term in enumerate ( kyph_gam . terms ): if term . isintercept : continue XX = kyph_gam . generate_X_grid ( term = i ) pdep , confi = kyph_gam . partial_dependence ( term = i , X = XX , width = 0.95 ) pdep2 , _ = kyph_gam . partial_dependence ( term = i , X = X , width = 0.95 ) plt . figure () plt . scatter ( X . iloc [:, term . feature ], pdep2 + res ) plt . plot ( XX [:, term . feature ], pdep ) plt . plot ( XX [:, term . feature ], confi , c = 'r' , ls = '--' ) plt . title ( X . columns . values [ term . feature ]) plt . show () B - Regression in pyGAM For regression problems, we can use a linearGAM model. For this part we will use the wages dataset. https://pygam.readthedocs.io/en/latest/api/lineargam.html The wages dataset Let's inspect another dataset that is included in pyGAM that notes the wages of people based on their age, year of employment and education. In [29]: # from the pyGAM documentation from pygam import LinearGAM , s , f from pygam.datasets import wage X , y = wage ( return_X_y = True ) ## model gam = LinearGAM ( s ( 0 ) + s ( 1 ) + f ( 2 )) gam . gridsearch ( X , y ) ## plotting plt . figure (); fig , axs = plt . subplots ( 1 , 3 ); titles = [ 'year' , 'age' , 'education' ] for i , ax in enumerate ( axs ): XX = gam . generate_X_grid ( term = i ) ax . plot ( XX [:, i ], gam . partial_dependence ( term = i , X = XX )) ax . plot ( XX [:, i ], gam . partial_dependence ( term = i , X = XX , width =. 95 )[ 1 ], c = 'r' , ls = '--' ) if i == 0 : ax . set_ylim ( - 30 , 30 ) ax . set_title ( titles [ i ]); 100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time: 0:00:00 Discussion What are your observations from the plots above? 4 - Smoothing Splines using pyGAM For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point. Let's see how this smoothing works in pyGAM . We start by creating some arbitrary data and fitting them with a GAM. In [30]: X = np . linspace ( 0 , 10 , 500 ) y = np . sin ( X * 2 * np . pi ) * X + np . random . randn ( len ( X )) plt . scatter ( X , y ); In [31]: # let's try a large lambda first and lots of splines gam = LinearGAM ( lam = 1e6 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); We see that the large $\\lambda$ forces a straight line, no flexibility. Let's see now what happens if we make it smaller. In [32]: # let's try a smaller lambda gam = LinearGAM ( lam = 1e2 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); There is some curvature there but still not a good fit. Let's try no penalty. That should have the line fit exactly. In [33]: # no penalty, let's try a 0 lambda gam = LinearGAM ( lam = 0 , n_splines = 50 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ) plt . plot ( XX , gam . predict ( XX )) Out[33]: [ ] Yes, that is good. Now let's see what happens if we lessen the number of splines. The fit should not be as good. In [34]: # no penalty, let's try a 0 lambda gam = LinearGAM ( lam = 0 , n_splines = 10 ) . fit ( X , y ) XX = gam . generate_X_grid ( term = 0 ) plt . scatter ( X , y , alpha = 0.3 ); plt . plot ( XX , gam . predict ( XX )); Indeed. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab02/notebook/"},{"title":"Lecture 3: Smoothers and Additive 3/3","text":"Slides This lecture is only available to registered students Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture03/"},{"title":"Lecture 2: Smoothers and Additive 2/3","text":"Slides This lecture is only available to registered students Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture02/"},{"title":"Lecture 1: Introduction + Smoothers and Additive 1/3","text":"Slides This lecture is only available to registered students Introduction [PPTX] Lecture 1-3 Slides [PDF] Notebooks Smoothing Notebook Data These data files are required for running the smoothing notebook diabetes.csv GAGurine.csv kyphosis.csv Zip This zip includes slides, notebook, and all data files cs109b_lec1-3_smoothing.zip","tags":"lectures","url":"lectures/lecture01/"},{"title":"Lab 1: Getting Started","text":"Notebooks Lab 1: Getting Started Additional Files YAML file to create local Conda environment Forking a Repo Guide","tags":"labs","url":"labs/lab01/"},{"title":"Lab 1: Getting Started","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ CS109B Data Science 2: Advanced Topics in Data Science Lab 1 - Introduction and Setup Harvard University Spring 2020 Instructors: Mark Glickman, Pavlos Protopapas, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Contributors: Will Claybaugh and Eleni Kaxiras In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np #import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Learning Goals The purpose of this lab is to get you up to speed with what you will need to run the code for CS109b. 1. Getting Class Material Option 1A: Cloning the class repo and then copying the contents in a different directory so you can make changes. Open the Terminal in your computer and go to the Directory where you want to clone the repo. Then run git clone https://github.com/Harvard-IACS/2020-CS109B.git If you have already cloned the repo, go inside the '/2020-CS109B/' directory and run git pull If you change the notebooks and then run git pull your changes will be overwritten. So create a playground folder and copy the folder with the notebook with which you want to work there. Option 1B: Forking the class repo To get access to the code used in class you will need to clone the class repo: https://github.com/Harvard-IACS/2020-CS109B In order not to lose any changes you have made when updating the content (pulling) from the main repo, a good practice is to fork the repo locally. For more on this see Maddy Nakada's notes: How to Fork a Repo . NOTE: While Fork is a proper way to handle local changes, it doesn't magically solve everything -- if you edit a file that originated from our course repo (e.g., a HW notebook), and later pull from our 'upstream' repo again, any changes you make will require resolving merge conflict(s) . Thus, if you want to safetly and easily preserve any of your changes, we recommend renaming your files and/or copying them into an independent directory within your repo. You will need this year's repo: https://github.com/Harvard-IACS/2020-CS109B.git 2. Running code: Option 2A: Managing Local Resources (supported by cs109b) Use Virtual Environments: I cannot stress this enough! Isolating your projects inside specific environments helps you manage dependencies and therefore keep your sanity. You can recover from mess-ups by simply deleting an environment. Sometimes certain installation of libraries conflict with one another. In order of isolation here is what you can do: a) set up a virtual environment, b) set up a virtual machine. The two most popular tools for setting up environments are: conda (a package and environment manager) pip (a Python package manager) with virtualenv (a tool for creating environments) We recommend using conda package installation and environments. conda installs packages from the Anaconda Repository and Anaconda Cloud, whereas pip installs packages from PyPI. Even if you are using conda as your primary package installer and are inside a conda environment, you can still use pip install for those rare packages that are not included in the conda ecosystem. See here for more details on how to manage Conda Environments . Exercise 1: Clone of Fork the CS109b git repository. Use the cs109b.yml file to create an environment: $ cd /2020-CS109B/content/labs/lab01/ $ conda env create -f cs109b.yml $ conda activate cs109b We have included the packages that you will need in the cs109b.yml file. It should be in the same directory as this notebook. Option 2B: Using Cloud Resources (optional) Using SEAS JupyterHub (supported by cs109b) Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class, accessible via the 'JupyterHub' menu link in Canvas. Between now and March 1, each student will have their own t2.medium AWS ec2 instance with 4GB CPU RAM, and 2 vCPUs. After March 1st the instances will be upgraded to p2.xlarge AWS ec2 instances with a GPU, 61GB CPU RAM, 12GB GPU RAM, 10gB disk space, and 4 vCPUs. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are to use it with prudence; also it is not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Using Google Colab (on your own) Google's Colab platform https://colab.research.google.com/ offers a GPU enviromnent to test your ideas, it's fast, free, with the only caveat that your files persist only for 12 hours. The solution is to keep your files in a repository and just clone it each time you use Colab. Using AWS in the Cloud (on your own) For those of you who want to have your own machines in the Cloud to run whatever you want, Amazon Web Services is a (paid) solution. For more see: https://docs.aws.amazon.com/polly/latest/dg/setting-up.html Remember, AWS is a paid service so if you let your machine run for days you will get charged! source: maybe Stanford's cs231n via Medium 3. Ensuring everything is installed correctly Packages we will need for this class Clustering : Sklearn - https://scikit-learn.org/stable/ scipy - https://www.scipy.org gap_statistic (by Miles Granger) - https://anaconda.org/milesgranger/gap-statistic/notebook Smoothing : statsmodels - https://www.statsmodels.org/ statsmodels examples: https://www.statsmodels.org/stable/examples/index.html#regression scipy pyGAM - https://pygam.readthedocs.io/en/latest/ Bayes : pymc3 - https://docs.pymc.io Neural Networks : keras - https://www.tensorflow.org/guide/keras We will test that these packages load correctly in our environment. In [12]: from sklearn import datasets iris = datasets . load_iris () digits = datasets . load_digits () digits . target # you should see [0, 1, 2, ..., 8, 9, 8] Out[12]: array([0, 1, 2, ..., 8, 9, 8]) In [13]: from scipy import misc import matplotlib.pyplot as plt face = misc . face () plt . imshow ( face ) plt . show () # you should see a racoon In [14]: import statsmodels.api as sm import statsmodels.formula.api as smf # Load data dat = sm . datasets . get_rdataset ( \"Guerry\" , \"HistData\" ) . data dat . head () Out[14]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dept Region Department Crime_pers Crime_prop Literacy Donations Infants Suicides MainCity ... Crime_parents Infanticide Donation_clergy Lottery Desertion Instruction Prostitutes Distance Area Pop1831 0 1 E Ain 28870 15890 37 5098 33120 35039 2:Med ... 71 60 69 41 55 46 13 218.372 5762 346.03 1 2 N Aisne 26226 5521 51 8901 14572 12831 2:Med ... 4 82 36 38 82 24 327 65.945 7369 513.00 2 3 C Allier 26747 7925 13 10973 17044 114121 2:Med ... 46 42 76 66 16 85 34 161.927 7340 298.26 3 4 E Basses-Alpes 12935 7289 46 2733 23018 14238 1:Sm ... 70 12 37 80 32 29 2 351.399 6925 155.90 4 5 E Hautes-Alpes 17488 8174 69 6962 23076 16171 1:Sm ... 22 23 64 79 35 7 1 320.280 5549 129.10 5 rows √ó 23 columns In [6]: from pygam import PoissonGAM , s , te from pygam.datasets import chicago from mpl_toolkits.mplot3d import Axes3D X , y = chicago ( return_X_y = True ) gam = PoissonGAM ( s ( 0 , n_splines = 200 ) + te ( 3 , 1 ) + s ( 2 )) . fit ( X , y ) In [7]: XX = gam . generate_X_grid ( term = 1 , meshgrid = True ) Z = gam . partial_dependence ( term = 1 , X = XX , meshgrid = True ) ax = plt . axes ( projection = '3d' ) ax . plot_surface ( XX [ 0 ], XX [ 1 ], Z , cmap = 'viridis' ) Out[7]: In [ ]: import pymc3 as pm print ( 'Running PyMC3 v {} ' . format ( pm . __version__ )) # you should see 'Running on PyMC3 v3.8' Plotting matplotlib and seaborn matplotlib seaborn: statistical data visualization . seaborn works great with pandas . It can also be customized easily. Here is the basic seaborn tutorial: Seaborn tutorial . Plotting a function of 2 variables using contours In optimization, our objective function will often be a function of two or more variables. While it's hard to visualize a function of more than 3 variables, it's very informative to plot one of 2 variables. To do this we use contours. First we define the $x1$ and $x2$ variables and then construct their pairs using meshgrid . In [21]: import seaborn as sn In [11]: x1 = np . linspace ( - 0.1 , 0.1 , 50 ) x2 = np . linspace ( - 0.1 , 0.1 , 100 ) xx , yy = np . meshgrid ( x1 , x2 ) z = np . sqrt ( xx ** 2 + yy ** 2 ) plt . contour ( x1 , x2 , z ); We will be using tensorflow and keras TensorFlow is a framework for representing complicated ML algorithms and executing them in any platform, from a phone to a distributed system using GPUs. Developed by Google Brain, TensorFlow is used very broadly today. Keras , is a high-level API used for fast prototyping, advanced research, and production. We will use tf.keras which is TensorFlow's implementation of the keras API. Exercise 2: Run the following cells to make sure you have the basic libraries to do deep learning In [3]: from __future__ import absolute_import , division , print_function , unicode_literals # TensorFlow and tf.keras import tensorflow as tf from tensorflow.keras import layers from tensorflow.keras import models from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential from tensorflow.keras.regularizers import l2 tf . keras . backend . clear_session () # For easy reset of notebook state. print ( tf . __version__ ) # You should see a >2.0.0 here! print ( tf . keras . __version__ ) 2.0.0 2.2.4-tf In [8]: # Checking if our machine has NVIDIA GPUs. Mine does not.. hasGPU = tf . config . experimental_list_devices () print ( f 'My computer has the following GPUs: {hasGPU} ' ) My computer has the following GPUs: ['/job:localhost/replica:0/task:0/device:CPU:0'] DELIVERABLES Submit this notebook to Canvas with the output produced . Describe below the environment in which you will be working, e.g. I have installed the environment needed locally and have tested all the code in this notebook OR/and I am using JupyterHub ---------------- your answer here if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab01/notebook/"}]}